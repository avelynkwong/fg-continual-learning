{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeff534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FGVCAircraft\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# remove copyright banner\n",
    "class RemoveCopyrightBanner(object):\n",
    "    def __call__(self, img):\n",
    "        width, height = img.size\n",
    "        return img.crop((0, 0, width, height - 20))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    RemoveCopyrightBanner(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the FGVC Aircraft dataset instance\n",
    "train_dataset = FGVCAircraft(\n",
    "    root='./data', \n",
    "    split='train',              # Options: 'train', 'val', 'trainval', 'test'\n",
    "    annotation_level='variant',    # Options: 'variant', 'family', 'manufacturer'\n",
    "    transform=transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_dataset = FGVCAircraft(\n",
    "    root='./data', \n",
    "    split='val',           \n",
    "    annotation_level='variant', \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = FGVCAircraft(\n",
    "    root='./data', \n",
    "    split='test',             \n",
    "    annotation_level='variant',  \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show images\n",
    "def show_images(train_dataset, num_images=5):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        image, label = train_dataset[i]\n",
    "        image = image.permute(1, 2, 0)  # convert from CxHxW to HxWxC\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_dataset, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def group_task_indices(dataset):\n",
    "    \"\"\"\n",
    "    Task 0: 0-9, Task 1: 10-19, ..., Task 9: 90-99\n",
    "    Output a dictionary where keys are task indices and values are lists of image indices.\n",
    "    For example, task_dict[0] will contain indices of images with labels 0-9.\n",
    "    \"\"\"\n",
    "    task_dict = defaultdict(list)\n",
    "    for idx, (_, label) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        for i in range((label // 10), 10):\n",
    "            task_dict[i].append(idx)\n",
    "    return task_dict\n",
    "    \n",
    "train_task_idxs = group_task_indices(train_dataset)\n",
    "val_task_idxs = group_task_indices(val_dataset)\n",
    "test__idxs = group_task_indices(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Subset\n",
    "# train_subset = Subset(train_dataset, train_task_idxs[0])\n",
    "\n",
    "# # initialize dataloaders with task 0\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_subset, batch_size=32, shuffle=True, num_workers=4\n",
    "# )\n",
    "# # initalize val_loader with task 0\n",
    "# val_subset = Subset(val_dataset, val_task_idxs[0])\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_subset, batch_size=32, shuffle=False, num_workers=4\n",
    "# )\n",
    "# # initalize test_loader with task 0\n",
    "# test_subset = Subset(test_dataset, test__idxs[0])\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_subset, batch_size=32, shuffle=False, num_workers=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_net(net_to_val, val_loader):\n",
    "    net_to_val.eval()\n",
    "    loss = 0\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm.tqdm(val_loader, desc=\"Validating\"):\n",
    "\n",
    "            # Get the input images and their corresponding labels\n",
    "            img, label = img.cuda(), label.cuda()\n",
    "\n",
    "            # Forward pass: Get predictions from the model\n",
    "            outputs = net_to_val(img)\n",
    "\n",
    "            # compute SmoothL1Losss\n",
    "            loss += criterion(outputs, label)\n",
    "\n",
    "        return loss / len(val_loader)\n",
    "\n",
    "def train_net(max_epochs, net_to_train, opt, train_loader, val_loader, save_path=None):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # prepare the net for training\n",
    "    net_to_train.cuda()\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(max_epochs):\n",
    "        net_to_train.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # train on batches of data\n",
    "        for imgs, labels in tqdm.tqdm(train_loader, unit='batch'):\n",
    "            \n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # prediction\n",
    "            outputs = net_to_train(imgs)\n",
    "\n",
    "            # compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        val_losses.append(val_net(net_to_train, val_loader))\n",
    "\n",
    "        # save checkpoint\n",
    "        if save_path:\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': net_to_train.state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, save_path)\n",
    "            print(f\"Checkpoint saved to {save_path}\")\n",
    "        \n",
    "        # early stopping\n",
    "        if len(val_losses) > 1 and val_losses[-1] > val_losses[-2]:\n",
    "            break\n",
    "    \n",
    "    print(\"finished training\")\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc054005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def modify_resnet_head(model, num_classes):\n",
    "    \"\"\"\n",
    "    Modify the last fully connected layer of the ResNet model to match the number of classes.\n",
    "    \"\"\"\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61220f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_test_accuracy(model, test_loader, num_classes):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total = 0\n",
    "    correct_per_class = [0] * num_classes\n",
    "    total_per_class = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            output = model(imgs)\n",
    "            preds = output.argmax(dim=1)\n",
    "\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Per-class stats\n",
    "            for c in range(num_classes):\n",
    "                correct_per_class[c] += ((preds == c) & (labels == c)).sum().item()\n",
    "                total_per_class[c] += (labels == c).sum().item()\n",
    "\n",
    "    overall_acc = correct_preds / total\n",
    "    per_class_acc = [correct_per_class[c] / total_per_class[c] if total_per_class[c] > 0 else 0.0\n",
    "                     for c in range(num_classes)]\n",
    "    return overall_acc, per_class_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for task in range(10):\n",
    "    print(f\"Training on task {task}...\")\n",
    "\n",
    "    model = modify_resnet_head(model, (task+1) * 10)\n",
    "    model = model.cuda()\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        Subset(train_dataset, train_task_idxs[task]), batch_size=32, shuffle=True, num_workers=4\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        Subset(val_dataset, val_task_idxs[task]), batch_size=32, shuffle=False, num_workers=4\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Subset(test_dataset, test__idxs[task]), batch_size=32, shuffle=False, num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Train the model on the current task\n",
    "    train_losses, val_losses = train_net(10, model, optimizer, train_loader, val_loader)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    overall_acc, per_class_acc = get_test_accuracy(model, test_loader, (task+1) * 10)\n",
    "    print(f\"Overall accuracy for task {task}: {overall_acc:.4f}\")\n",
    "    print(f\"Per-class accuracy for task {task}: {per_class_acc}\")\n",
    "\n",
    "    # save to text file\n",
    "    with open(f\"accuracies.txt\", \"w\") as f:\n",
    "        f.write(f\"Task {task} - overall accuracy: {overall_acc:.4f}\\n\")\n",
    "        f.write(f\"Task {task} - perclass accuracy: {per_class_acc}\\n\")\n",
    "\n",
    "    # Save the model after training on each task\n",
    "    torch.save(model.state_dict(), f\"model_task_{task}.pth\")\n",
    "    print(f\"Model for task {task} saved as model_task_{task}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ContinualLearningMetrics:\n",
    "#     def __init__(self, num_tasks):\n",
    "#         \"\"\"\n",
    "#         Initialize the metrics tracker for continual learning evaluation.\n",
    "        \n",
    "#         Args:\n",
    "#             num_tasks: The total number of sequential tasks to be learned\n",
    "#         \"\"\"\n",
    "#         self.num_tasks = num_tasks\n",
    "#         # Track the best accuracy observed for each task\n",
    "#         self.best_accuracies = [0.0] * num_tasks\n",
    "#         # Current accuracy for each task after most recent training\n",
    "#         self.current_accuracies = [0.0] * num_tasks\n",
    "#         # History of accuracies after training on each task\n",
    "#         # Each entry is a list of accuracies for all tasks after training on a specific task\n",
    "#         self.accuracy_history = []\n",
    "\n",
    "#     def update_accuracies(self, accuracies_after_task):\n",
    "#         \"\"\"\n",
    "#         Update the current accuracies after training on a new task.\n",
    "        \n",
    "#         Args:\n",
    "#             accuracies_after_task: List or array of accuracies for all tasks \n",
    "#                                    after training on the current task\n",
    "#         \"\"\"\n",
    "#         # Update current accuracies\n",
    "#         self.current_accuracies = accuracies_after_task\n",
    "#         # Store the accuracy snapshot in history\n",
    "#         self.accuracy_history.append(accuracies_after_task.copy())\n",
    "\n",
    "#         # Update best accuracies for each task if current is better\n",
    "#         for i in range(self.num_tasks):\n",
    "#             if accuracies_after_task[i] > self.best_accuracies[i]:\n",
    "#                 self.best_accuracies[i] = accuracies_after_task[i]\n",
    "\n",
    "#     def average_accuracy(self):\n",
    "#         \"\"\"\n",
    "#         Compute average accuracy across all tasks at the current time.\n",
    "        \n",
    "#         Returns:\n",
    "#             Float: The average of current accuracies across all tasks\n",
    "#         \"\"\"\n",
    "#         return sum(self.current_accuracies) / self.num_tasks\n",
    "\n",
    "#     def forgetting(self):\n",
    "#         \"\"\"\n",
    "#         Compute forgetting measure for each task.\n",
    "        \n",
    "#         Forgetting for task i = best accuracy on task i - current accuracy on task i\n",
    "        \n",
    "#         Returns:\n",
    "#             Float: Average forgetting across all tasks except the last one \n",
    "#                   (since the last task can't be forgotten yet)\n",
    "#         \"\"\"\n",
    "#         forgetting_per_task = []\n",
    "#         # Calculate forgetting for all tasks except the most recent one\n",
    "#         for i in range(self.num_tasks - 1):\n",
    "#             # Forgetting is the drop from best to current accuracy (minimum 0)\n",
    "#             forgetting_per_task.append(max(0, self.best_accuracies[i] - self.current_accuracies[i]))\n",
    "        \n",
    "#         # Handle the case where there's only one task\n",
    "#         if len(forgetting_per_task) == 0:\n",
    "#             return 0.0\n",
    "            \n",
    "#         # Return average forgetting\n",
    "#         return sum(forgetting_per_task) / len(forgetting_per_task)\n",
    "\n",
    "#     def backward_transfer(self):\n",
    "#         \"\"\"\n",
    "#         Compute backward transfer (BWT).\n",
    "        \n",
    "#         BWT = average of (accuracy after learning last task - accuracy after learning task i) \n",
    "#               for all tasks i < last task\n",
    "              \n",
    "#         Positive BWT indicates learning new tasks improves performance on old tasks.\n",
    "#         Negative BWT indicates forgetting.\n",
    "        \n",
    "#         Returns:\n",
    "#             Float or None: Average backward transfer value, or None if not enough data\n",
    "#         \"\"\"\n",
    "#         # Check if we have enough data to compute BWT\n",
    "#         if len(self.accuracy_history) < self.num_tasks:\n",
    "#             return None\n",
    "\n",
    "#         # Get accuracies after training on the final task\n",
    "#         last_task_accuracies = self.accuracy_history[-1]\n",
    "#         bwt_values = []\n",
    "        \n",
    "#         # For each previous task, calculate the difference between:\n",
    "#         # - its accuracy after training on all tasks, and\n",
    "#         # - its accuracy immediately after it was trained\n",
    "#         for i in range(self.num_tasks - 1):\n",
    "#             # Compare current performance to performance right after learning task i\n",
    "#             bwt_values.append(last_task_accuracies[i] - self.accuracy_history[i][i])\n",
    "\n",
    "#         # Return average backward transfer\n",
    "#         return sum(bwt_values) / len(bwt_values)\n",
    "    \n",
    "#     def detailed_metrics(self):\n",
    "#         \"\"\"\n",
    "#         Return a dictionary with all metrics for easier reporting.\n",
    "        \n",
    "#         Returns:\n",
    "#             dict: Dictionary containing all computed metrics\n",
    "#         \"\"\"\n",
    "#         return {\n",
    "#             \"average_accuracy\": self.average_accuracy(),\n",
    "#             \"forgetting\": self.forgetting(),\n",
    "#             \"backward_transfer\": self.backward_transfer(),\n",
    "#             \"current_accuracies\": self.current_accuracies.copy(),\n",
    "#             \"best_accuracies\": self.best_accuracies.copy()\n",
    "#         }\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize with 3 sequential tasks\n",
    "#     num_tasks = 3\n",
    "#     metrics = ContinualLearningMetrics(num_tasks)\n",
    "\n",
    "#     # Simulate training and evaluation after each task\n",
    "#     # Format: [accuracy_task1, accuracy_task2, accuracy_task3]\n",
    "    \n",
    "#     # After training on task 1, only task 1 has been seen\n",
    "#     metrics.update_accuracies([80.0, 0.0, 0.0])\n",
    "#     print(\"After Task 1:\")\n",
    "#     print(f\"Average Accuracy: {metrics.average_accuracy():.2f}%\")\n",
    "#     print(f\"Forgetting: {metrics.forgetting():.2f}%\")\n",
    "#     print(f\"BWT: {metrics.backward_transfer()}\")\n",
    "    \n",
    "#     # After training on task 2, task 1's accuracy dropped slightly\n",
    "#     metrics.update_accuracies([75.0, 85.0, 0.0])\n",
    "#     print(\"\\nAfter Task 2:\")\n",
    "#     print(f\"Average Accuracy: {metrics.average_accuracy():.2f}%\")\n",
    "#     print(f\"Forgetting: {metrics.forgetting():.2f}%\")\n",
    "#     print(f\"BWT: {metrics.backward_transfer()}\")\n",
    "    \n",
    "#     # After training on task 3, both previous tasks show some forgetting\n",
    "#     metrics.update_accuracies([70.0, 80.0, 90.0])\n",
    "#     print(\"\\nAfter Task 3:\")\n",
    "#     print(f\"Average Accuracy: {metrics.average_accuracy():.2f}%\")\n",
    "#     print(f\"Forgetting: {metrics.forgetting():.2f}%\")\n",
    "#     print(f\"BWT: {metrics.backward_transfer():.2f}%\")\n",
    "    \n",
    "#     # Get all metrics as a dictionary\n",
    "#     all_metrics = metrics.detailed_metrics()\n",
    "#     print(\"\\nDetailed Metrics:\")\n",
    "#     for key, value in all_metrics.items():\n",
    "#         print(f\"{key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
