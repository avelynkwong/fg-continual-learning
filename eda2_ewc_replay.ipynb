{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ZIq16KN2hQw",
      "metadata": {
        "id": "4ZIq16KN2hQw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8caPCMc81HvQ",
      "metadata": {
        "id": "8caPCMc81HvQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# seeds\n",
        "seed = 88\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "cudnn.deterministic = True\n",
        "cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(seed)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbeff534",
      "metadata": {
        "id": "dbeff534",
        "outputId": "bcd2c9a2-20bc-415d-e1e9-12f30ad22fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz to ./data/fgvc-aircraft-2013b.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.75G/2.75G [02:18<00:00, 19.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/fgvc-aircraft-2013b.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "# remove copyright banner\n",
        "class RemoveCopyrightBanner(object):\n",
        "    def __call__(self, img):\n",
        "        width, height = img.size\n",
        "        return img.crop((0, 0, width, height - 20))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    RemoveCopyrightBanner(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "granularity = 'variant'\n",
        "\n",
        "# # Create the FGVC Aircraft dataset instance\n",
        "# train_dataset = FGVCAircraft(\n",
        "#     root='./data',\n",
        "#     split='trainval',              # Options: 'train', 'val', 'trainval', 'test'\n",
        "#     annotation_level=granularity,    # Options: 'variant', 'family', 'manufacturer'\n",
        "#     transform=transform,\n",
        "#     download=True\n",
        "# )\n",
        "\n",
        "data_root = './data'\n",
        "\n",
        "train_dataset = datasets.FGVCAircraft(\n",
        "    root=data_root,\n",
        "    split='train',\n",
        "    annotation_level=granularity,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = datasets.FGVCAircraft(\n",
        "    root=data_root,\n",
        "    split='val',\n",
        "    annotation_level=granularity,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "test_dataset = datasets.FGVCAircraft(\n",
        "    root=data_root,\n",
        "    split='test',\n",
        "    annotation_level=granularity,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "trainval_dataset = ConcatDataset([train_dataset, val_dataset])\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [0.8, 0.2], generator=g)\n",
        "\n",
        "# val_dataset = FGVCAircraft(\n",
        "#     root='./data',\n",
        "#     split='val',\n",
        "#     annotation_level='variant',\n",
        "#     transform=transform,\n",
        "#     download=True\n",
        "# )\n",
        "\n",
        "# test_dataset = FGVCAircraft(\n",
        "#     root='./data',\n",
        "#     split='test',\n",
        "#     annotation_level=granularity,\n",
        "#     transform=transform,\n",
        "#     download=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8dd6b2b",
      "metadata": {
        "id": "a8dd6b2b"
      },
      "outputs": [],
      "source": [
        "# function to show images\n",
        "def show_images(train_dataset, num_images=5):\n",
        "  #shuffle the dataset\n",
        "  train_dataset = torch.utils.data.Subset(train_dataset, torch.randperm(len(train_dataset)))\n",
        "  fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "  for i in range(num_images):\n",
        "      image, label = train_dataset[i]\n",
        "      image = image.permute(1, 2, 0)  # convert from CxHxW to HxWxC\n",
        "      axes[i].imshow(image)\n",
        "      axes[i].set_title(f'Label: {label}')\n",
        "      axes[i].axis('off')\n",
        "  plt.show()\n",
        "\n",
        "show_images(train_dataset, num_images=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7TG9oD76Q6G",
      "metadata": {
        "id": "f7TG9oD76Q6G"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a397327",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a397327",
        "outputId": "43d2e7ae-f27a-4da5-bfa9-2871336cff0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3008/3008 [00:16<00:00, 186.72it/s]\n",
            "100%|██████████| 752/752 [00:03<00:00, 202.70it/s]\n",
            "100%|██████████| 1880/1880 [00:09<00:00, 203.68it/s]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def group_task_indices(dataset, cumulative=False, max_per_class=1000, classes_per_task=10):\n",
        "    \"\"\"\n",
        "    Task 0: 0-9, Task 1: 10-19, ..., Task 9: 90-99\n",
        "    Output a dictionary where keys are task indices and values are lists of image indices.\n",
        "    For example, task_dict[0] will contain indices of images with labels 0-9.\n",
        "    \"\"\"\n",
        "    per_class_counts = defaultdict(int)\n",
        "    task_dict = defaultdict(list)\n",
        "    for idx, (_, label) in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        # for test and val, should have cumulative indices (all classes seen so far)\n",
        "        if per_class_counts[label] >= max_per_class:\n",
        "          continue\n",
        "        per_class_counts[label] += 1\n",
        "        if cumulative:\n",
        "          for i in range((label // classes_per_task), classes_per_task):\n",
        "            task_dict[i].append(idx)\n",
        "        else:\n",
        "          task_dict[label // classes_per_task].append(idx)\n",
        "    return task_dict\n",
        "\n",
        "train_task_idxs = group_task_indices(train_dataset, cumulative=False, max_per_class=60)\n",
        "val_task_idxs = group_task_indices(val_dataset, cumulative=True)\n",
        "test_task_idxs = group_task_indices(test_dataset, cumulative=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "infsWUtUupE4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "infsWUtUupE4",
        "outputId": "a6f26811-6d10-4e92-a82a-7742c93d04bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "599it [00:02, 216.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {0: 60, 5: 60, 3: 60, 2: 60, 7: 60, 4: 60, 1: 60, 6: 59, 8: 60, 9: 60})\n",
            "Total number of tasks: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "labels_dict = defaultdict(int)\n",
        "for i in tqdm(train_task_idxs[0], total=len(train_task_idxs)):\n",
        "    _, label = train_dataset[i]\n",
        "    labels_dict[label] += 1\n",
        "print(labels_dict)\n",
        "\n",
        "print(f'Total number of tasks: {len(train_task_idxs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cub55VRd6Q6J",
      "metadata": {
        "id": "cub55VRd6Q6J"
      },
      "source": [
        "## Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1J34wLym6Q6J",
      "metadata": {
        "id": "1J34wLym6Q6J"
      },
      "outputs": [],
      "source": [
        "def val_net(net_to_val, val_loader):\n",
        "    net_to_val.eval()\n",
        "    loss = 0\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, label in tqdm(val_loader, desc=\"Validating\"):\n",
        "\n",
        "            # Get the input images and their corresponding labels\n",
        "            img, label = img.cuda(), label.cuda()\n",
        "\n",
        "            # Forward pass: Get predictions from the model\n",
        "            outputs = net_to_val(img)\n",
        "\n",
        "            # compute SmoothL1Losss\n",
        "            loss += criterion(outputs, label)\n",
        "\n",
        "        return loss / len(val_loader)\n",
        "\n",
        "def train_net(max_epochs, freeze_epochs, patience, net_to_train, opt, train_loader, val_loader, task, save_file=None, save_path=None):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    # prepare the net for training\n",
        "    net_to_train.cuda()\n",
        "\n",
        "    # freeze backbone\n",
        "    for param in net_to_train.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in net_to_train.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # loop over the dataset multiple times\n",
        "    for epoch in range(max_epochs):\n",
        "        net_to_train.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # unfreeze all layers\n",
        "        if epoch == freeze_epochs:\n",
        "          for param in net_to_train.parameters():\n",
        "              param.requires_grad = True\n",
        "              # change optimizer learning rate\n",
        "              opt.param_groups[0]['lr'] = 1e-4\n",
        "\n",
        "        # train on batches of data\n",
        "        for imgs, labels in tqdm(train_loader, unit='batch'):\n",
        "\n",
        "            imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # prediction\n",
        "            outputs = net_to_train(imgs)\n",
        "\n",
        "            # compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            # print loss statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        val_losses.append(val_net(net_to_train, val_loader))\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.3f}, Validation Loss: {val_losses[-1]:.3f}\")\n",
        "\n",
        "        # save to checkpoint\n",
        "        if save_path:\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': net_to_train.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, save_path)\n",
        "            print(f\"Checkpoint saved to {save_path}\")\n",
        "\n",
        "        # save task, trainloss, valloss to file\n",
        "        if save_file:\n",
        "            with open(save_file, 'a') as f:\n",
        "                f.write(f\"{task},{epoch + 1},{avg_loss},{val_losses[-1]}\\n\")\n",
        "\n",
        "        # early stopping based on patience\n",
        "        if len(val_losses) > patience and val_losses[-1] >= min(val_losses[:-patience]):\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    print(\"finished training\")\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fc054005",
      "metadata": {
        "id": "fc054005"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "def modify_resnet_head(model, num_classes):\n",
        "  \"\"\"\n",
        "  Modify the last fully connected layer of the ResNet model to match the number of classes.\n",
        "  \"\"\"\n",
        "\n",
        "  old_fc = model.fc\n",
        "  old_num_classes = old_fc.out_features\n",
        "  num_ftrs = old_fc.in_features\n",
        "\n",
        "  # Create the new head\n",
        "  new_fc = nn.Linear(num_ftrs, num_classes).cuda()\n",
        "\n",
        "  # Copy weights and biases from the old head\n",
        "  if old_num_classes < num_classes:\n",
        "    new_fc.weight.data[:old_num_classes, :] = old_fc.weight.data.clone().cuda()\n",
        "    new_fc.bias.data[:old_num_classes] = old_fc.bias.data.clone().cuda()\n",
        "\n",
        "  model.fc = new_fc\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "61220f9a",
      "metadata": {
        "id": "61220f9a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_test_accuracy(model, test_loader, num_classes):\n",
        "    model.eval()\n",
        "    correct_preds = 0\n",
        "    total = 0\n",
        "    correct_per_class = [0] * num_classes\n",
        "    total_per_class = [0] * num_classes\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
        "            imgs, labels = imgs.cuda(), labels.cuda()\n",
        "            output = model(imgs)\n",
        "            preds = output.argmax(dim=1)\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Per-class stats\n",
        "            for c in range(num_classes):\n",
        "                correct_per_class[c] += ((preds == c) & (labels == c)).sum().item()\n",
        "                total_per_class[c] += (labels == c).sum().item()\n",
        "\n",
        "    overall_acc = correct_preds / total\n",
        "    per_class_acc = [correct_per_class[c] / total_per_class[c] if total_per_class[c] > 0 else 0.0\n",
        "                     for c in range(num_classes)]\n",
        "    return overall_acc, per_class_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93b1d5b",
      "metadata": {
        "id": "c93b1d5b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# freeze all parameters except the last fc layer\n",
        "for name, param in model.named_parameters():\n",
        "    if name != 'fc.weight' and name != 'fc.bias':\n",
        "        param.requires_grad = False\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     test_dataset, batch_size=32, shuffle=False, num_workers=4, worker_init_fn=seed_worker, generator=g\n",
        "# )\n",
        "\n",
        "# create output file for train and val losses\n",
        "\n",
        "save_dir = 'naive'\n",
        "\n",
        "for task in range(10):\n",
        "\n",
        "    print(f\"Training on task {task}...\")\n",
        "\n",
        "    model = modify_resnet_head(model, (task+1) * 10)\n",
        "    model = model.cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        Subset(train_dataset, train_task_idxs[task]), batch_size=64, shuffle=True, num_workers=4, worker_init_fn=seed_worker, generator=g\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        Subset(val_dataset, val_task_idxs[task]), batch_size=64, shuffle=False, num_workers=4, worker_init_fn=seed_worker, generator=g\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        Subset(test_dataset, test_task_idxs[task]), batch_size=64, shuffle=False, num_workers=4, worker_init_fn=seed_worker, generator=g\n",
        "    )\n",
        "\n",
        "    # create output file for train and val losses\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Train the model on the current task\n",
        "    train_losses, val_losses = train_net(15, 5, 8, model, optimizer, train_loader, val_loader, task, save_file=os.path.join(save_dir, 'train_val_losses.txt'))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    overall_acc, per_class_acc = get_test_accuracy(model, test_loader, (task+1) * 10)\n",
        "    print(f\"Overall accuracy for task {task}: {overall_acc:.4f}\")\n",
        "    print(f\"Per-class accuracy for task {task}: {per_class_acc}\")\n",
        "\n",
        "    # save to text file in save dir\n",
        "    if not os.path.exists(os.path.join(save_dir, 'accuracies.txt')):\n",
        "        with open(os.path.join(save_dir, 'accuracies.txt'), 'w') as f:\n",
        "            f.write(\"Task,Overall Accuracy,Per-Class Accuracy\\n\")\n",
        "    with open(os.path.join(save_dir, 'accuracies.txt'), 'a') as f:\n",
        "        f.write(f\"{task},{overall_acc:.4f},{per_class_acc}\\n\")\n",
        "\n",
        "    # Save the model after training on each task in save dir\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, f\"model_task_{task}.pth\"))\n",
        "    print(f\"Model for task {task} saved as model_task_{task}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HwbezrmjWwIA",
      "metadata": {
        "id": "HwbezrmjWwIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cde0f4c-2717-44f8-9bce-2d81a1ae38f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/naive.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# zip the naive folder\n",
        "import shutil\n",
        "shutil.make_archive('naive', 'zip', 'naive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replay Code"
      ],
      "metadata": {
        "id": "SXRAKbeHyXKj"
      },
      "id": "SXRAKbeHyXKj"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(max_epochs, freeze_epochs, patience, net_to_train, opt, train_loader, val_loader, task, save_file=None, save_path=None):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    net_to_train.cuda()\n",
        "\n",
        "    initial_freeze = (task == 0) # Only freeze initially for the very first task\n",
        "\n",
        "    for name, param in net_to_train.named_parameters():\n",
        "        # do not train non-fc layers\n",
        "        if initial_freeze and 'fc' not in name:\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    optimizer = opt\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    print(f\"Starting training for Task {task}. Trainable parameters:\")\n",
        "    for name, param in net_to_train.named_parameters():\n",
        "        if param.requires_grad:\n",
        "             print(f\"  - {name}\")\n",
        "\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        net_to_train.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Unfreeze logic (if desired for staged training within a task)\n",
        "        if epoch == freeze_epochs and task > 0: # Only unfreeze/adjust LR if NOT task 0 and freeze_epochs > 0\n",
        "            print(f\"Unfreezing backbone at epoch {epoch} for task {task}\")\n",
        "            for param in net_to_train.parameters():\n",
        "                param.requires_grad = True\n",
        "            # Adjust LR for the existing optimizer\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            new_lr = 1e-4 # Or some other value\n",
        "            if current_lr != new_lr:\n",
        "                 print(f\"Setting LR to {new_lr}\")\n",
        "                 for g in optimizer.param_groups:\n",
        "                     g['lr'] = new_lr\n",
        "\n",
        "\n",
        "        for imgs, labels in tqdm(train_loader, unit='batch', desc=f\"Task {task} Epoch {epoch+1}\"):\n",
        "            imgs, labels = imgs.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net_to_train(imgs)\n",
        "            loss = criterion(outputs, labels) # Loss calculated on combined batch\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # --- Validation (Use Cumulative Loader!) ---\n",
        "        current_val_loss = val_net(net_to_train, val_loader) # val_loader MUST be cumulative\n",
        "        val_losses.append(current_val_loss)\n",
        "\n",
        "        print(f\"Task {task}, Epoch {epoch + 1}, Train Loss: {avg_loss:.4f}, Val Loss (Cumulative): {current_val_loss:.4f}\")\n",
        "\n",
        "        # --- Logging to file ---\n",
        "        if save_file:\n",
        "             with open(save_file, 'a') as f:\n",
        "                  f.write(f\"{task},{epoch + 1},{avg_loss},{current_val_loss}\\n\") # Log cumulative val loss\n",
        "\n",
        "        # --- Early Stopping (Based on CUMULATIVE validation loss) ---\n",
        "        if current_val_loss < best_val_loss:\n",
        "            best_val_loss = current_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            if save_path: # Optional: save best model state\n",
        "               torch.save(net_to_train.state_dict(), os.path.join(save_path, f\"model_task{task}_best.pth\"))\n",
        "               print(f\"  New best validation loss: {best_val_loss:.4f}. Saved best model.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            # print(f\"  Validation loss did not improve for {epochs_no_improve} epoch(s). Best: {best_val_loss:.4f}\") # Optional verbose print\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch + 1} for task {task}. Best Val Loss: {best_val_loss:.4f}\")\n",
        "            if save_path and os.path.exists(os.path.join(save_path, f\"model_task{task}_best.pth\")):\n",
        "               print(\"Loading best model weights before exiting.\")\n",
        "               net_to_train.load_state_dict(torch.load(os.path.join(save_path, f\"model_task{task}_best.pth\")))\n",
        "            break\n",
        "\n",
        "    print(f\"Finished training task {task}\")\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "Ke2aqvBaynhG"
      },
      "id": "Ke2aqvBaynhG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# freeze all parameters except the last fc layer\n",
        "for name, param in model.named_parameters():\n",
        "    if name != 'fc.weight' and name != 'fc.bias':\n",
        "        param.requires_grad = False\n",
        "\n",
        "# --- Add outside the loop ---\n",
        "memory_buffer = [] # Simple list to store (image_tensor, label) tuples\n",
        "memory_size = 1000 # Max number of samples in buffer (hyperparameter)\n",
        "samples_per_task_in_memory = 20 # How many samples to add from each task (hyperparameter)\n",
        "\n",
        "def update_memory_buffer(buffer, max_size, new_samples):\n",
        "    \"\"\"Adds new samples to the buffer and trims it if it exceeds max_size.\"\"\"\n",
        "    buffer.extend(new_samples)\n",
        "    # If buffer exceeds max size, remove samples randomly (or use FIFO)\n",
        "    overflow = len(buffer) - max_size\n",
        "    if overflow > 0:\n",
        "        # Randomly remove 'overflow' samples\n",
        "        indices_to_remove = random.sample(range(len(buffer)), overflow)\n",
        "        # Remove in reverse sorted order to avoid index shifting issues\n",
        "        for index in sorted(indices_to_remove, reverse=True):\n",
        "            del buffer[index]\n",
        "        # Alternatively, for FIFO: del buffer[:overflow]\n",
        "    print(f\"Memory buffer size: {len(buffer)} / {max_size}\")\n",
        "\n",
        "class MemoryDataset(Dataset):\n",
        "    \"\"\"A simple Dataset wrapper for the list-based memory buffer.\"\"\"\n",
        "    def __init__(self, buffer_list):\n",
        "        self.buffer = buffer_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # buffer contains (image_tensor, label)\n",
        "        return self.buffer[idx]\n",
        "\n",
        "# --- Modify your main loop ---\n",
        "save_dir = 'replay-coarse-grained' # Changed directory name\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "# Clear or initialize log files\n",
        "open(os.path.join(save_dir, 'train_val_losses.txt'), 'w').close()\n",
        "open(os.path.join(save_dir, 'accuracies.txt'), 'w').write(\"Task,Overall Accuracy,Per-Class Accuracy\\n\")\n",
        "\n",
        "\n",
        "for task in range(5):\n",
        "    print(f\"Training on task {task}...\")\n",
        "\n",
        "    model = modify_resnet_head(model, (task+1) * 10)\n",
        "    model = model.cuda()\n",
        "\n",
        "    # --- Prepare Current Task Dataset ---\n",
        "    current_task_train_subset = Subset(train_dataset, train_task_idxs[task])\n",
        "\n",
        "    # --- Prepare Combined Training Loader ---\n",
        "    if task > 0 and len(memory_buffer) > 0:\n",
        "        # Create a dataset from the memory buffer\n",
        "        replay_dataset = MemoryDataset(memory_buffer)\n",
        "        # Combine current task data and replay data\n",
        "        combined_train_dataset = ConcatDataset([current_task_train_subset, replay_dataset])\n",
        "        print(f\"Task {task}: Training with {len(current_task_train_subset)} current samples and {len(replay_dataset)} replay samples.\")\n",
        "    else:\n",
        "        # Task 0 or empty buffer: train only on current task data\n",
        "        combined_train_dataset = current_task_train_subset\n",
        "        print(f\"Task {task}: Training only with {len(current_task_train_subset)} current samples.\")\n",
        "\n",
        "    # Create DataLoader for the combined dataset\n",
        "    # Adjust batch size if needed, maybe smaller if memory is large\n",
        "    train_loader_combined = DataLoader(\n",
        "        combined_train_dataset,\n",
        "        batch_size=128, # Or adjust dynamically\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    # --- Validation and Test Loaders (Should still be CUMULATIVE!) ---\n",
        "    val_loader_cumulative = torch.utils.data.DataLoader(\n",
        "        Subset(val_dataset, val_task_idxs[task]),\n",
        "        batch_size=256,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    test_loader_cumulative = torch.utils.data.DataLoader(\n",
        "        Subset(test_dataset, test_task_idxs[task]),\n",
        "        batch_size=256,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    # --- Optimizer ---\n",
        "    # Consider re-initializing or adjusting LR, especially after task 0\n",
        "    if task == 0:\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0015)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4) # Lower LR for full network\n",
        "\n",
        "\n",
        "    # --- Train the model ---\n",
        "    # train_net now uses the combined loader\n",
        "    # No need for EWC parameters here\n",
        "    train_losses, val_losses = train_net(\n",
        "        max_epochs=15,\n",
        "        freeze_epochs=5, # Still relevant if you want staged training\n",
        "        patience=5,\n",
        "        net_to_train=model,\n",
        "        opt=optimizer,\n",
        "        train_loader=train_loader_combined, # Use the combined loader\n",
        "        val_loader=val_loader_cumulative, # Use the CUMULATIVE validation loader\n",
        "        task=task,\n",
        "        save_file=os.path.join(save_dir, 'train_val_losses.txt')\n",
        "    )\n",
        "\n",
        "    # --- Update Memory Buffer AFTER training ---\n",
        "    # Select samples from the task just finished\n",
        "    num_to_sample = min(samples_per_task_in_memory, len(current_task_train_subset))\n",
        "    if num_to_sample > 0:\n",
        "        indices_to_sample = random.sample(range(len(current_task_train_subset)), num_to_sample)\n",
        "        new_memory_samples = []\n",
        "        print(f\"Sampling {num_to_sample} examples from task {task} for memory buffer...\")\n",
        "        for idx in indices_to_sample:\n",
        "            # Get the actual data point (image tensor, label) from the subset\n",
        "            img_tensor, label = current_task_train_subset[idx]\n",
        "            new_memory_samples.append((img_tensor, label)) # Append as tuple\n",
        "\n",
        "        # Add to buffer and manage size\n",
        "        update_memory_buffer(memory_buffer, memory_size, new_memory_samples)\n",
        "    else:\n",
        "        print(f\"Not enough samples in task {task} subset to add to memory.\")\n",
        "\n",
        "\n",
        "    # --- Evaluate and Save ---\n",
        "    overall_acc, per_class_acc = get_test_accuracy(model, test_loader_cumulative, (task+1) * 10)\n",
        "    print(f\"Overall accuracy for task {task} (on classes 0-{(task+1)*10 - 1}): {overall_acc:.4f}\")\n",
        "\n",
        "    with open(os.path.join(save_dir, 'accuracies.txt'), 'a') as f:\n",
        "        f.write(f\"{task},{overall_acc:.4f},{per_class_acc}\\n\")\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, f\"model_task_{task}.pth\"))\n",
        "    print(f\"Model for task {task} saved as model_task_{task}.pth\")"
      ],
      "metadata": {
        "id": "o7yuCLojysxx"
      },
      "id": "o7yuCLojysxx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('replay-coarse-grained', 'zip', 'replay-coarse-grained')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L1MIgUIEzAX6",
        "outputId": "6e3e632f-4602-4a41-f89e-db49c87e91e4"
      },
      "id": "L1MIgUIEzAX6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/replay-coardse-grained.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EWC + Replay Code"
      ],
      "metadata": {
        "id": "7kDzzGHR4zUJ"
      },
      "id": "7kDzzGHR4zUJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "class EWC:\n",
        "    def __init__(self, model, device='cuda', lambda_ewc=5000):\n",
        "        \"\"\"\n",
        "        Initialize the Robust EWC class with a model and hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            model: The neural network model\n",
        "            device: Device to perform computations on ('cuda' or 'cpu')\n",
        "            lambda_ewc: Regularization strength for EWC penalty\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.lambda_ewc = lambda_ewc\n",
        "\n",
        "        # Dictionary to store Fisher information for each task\n",
        "        self.fisher_dict = {}\n",
        "        # Dictionary to store optimal parameters for each task\n",
        "        self.optpar_dict = {}\n",
        "        # Dictionary to store output layer sizes for each task\n",
        "        self.output_sizes = {}\n",
        "        # Dictionary to track important parameters\n",
        "        self.important_params = {}\n",
        "\n",
        "    def compute_fisher(self, data_loader, samples=500):\n",
        "        \"\"\"\n",
        "        Compute the diagonal Fisher Information Matrix with proper sampling and verification.\n",
        "\n",
        "        Args:\n",
        "            data_loader: DataLoader containing the task's data\n",
        "            samples: Number of samples to use for Fisher computation\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with parameter names as keys and Fisher values as values\n",
        "        \"\"\"\n",
        "        fisher = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}\n",
        "        self.model.eval()\n",
        "\n",
        "        sample_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.Subset(data_loader.dataset,\n",
        "                                  torch.randperm(len(data_loader.dataset))[:samples].tolist()),\n",
        "            batch_size=1, shuffle=True\n",
        "        )\n",
        "\n",
        "        for input_data, _ in sample_loader:\n",
        "            input_data = input_data.to(self.device)\n",
        "            output = self.model(input_data)\n",
        "            probs = F.softmax(output, dim=1)\n",
        "\n",
        "            num_classes = probs.size(1)\n",
        "            for c in range(num_classes):\n",
        "                self.model.zero_grad()\n",
        "                class_prob = probs[0, c]\n",
        "                log_class_prob = torch.log(class_prob)\n",
        "                log_class_prob.backward(retain_graph=(c < num_classes-1))\n",
        "\n",
        "                prob_value = class_prob.item()\n",
        "                for n, p in self.model.named_parameters():\n",
        "                    if p.grad is not None and p.requires_grad:\n",
        "                        fisher[n] += prob_value * p.grad.data.pow(2) / samples\n",
        "\n",
        "        return fisher\n",
        "\n",
        "    def store_task_parameters(self, task_id, data_loader):\n",
        "        \"\"\"\n",
        "        Store the optimal parameters and compute Fisher after training on a task.\n",
        "\n",
        "        Args:\n",
        "            task_id: ID of the current task\n",
        "            data_loader: DataLoader for the current task\n",
        "        \"\"\"\n",
        "        print(f\"Storing parameters for task {task_id}...\")\n",
        "\n",
        "        # Store current parameter values\n",
        "        self.optpar_dict[task_id] = {}\n",
        "        for n, p in self.model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.optpar_dict[task_id][n] = p.data.clone()\n",
        "                # Debug: Print parameter statistics for key layers\n",
        "                if 'fc' in n or 'layer4' in n:\n",
        "                    print(f\"Stored parameter {n}: min={p.min().item():.6f}, max={p.max().item():.6f}, mean={p.mean().item():.6f}\")\n",
        "\n",
        "        # Compute and store Fisher Information Matrix\n",
        "        self.fisher_dict[task_id] = self.compute_fisher(data_loader)\n",
        "\n",
        "        # Store output layer size for this task\n",
        "        if hasattr(self.model, 'fc'):\n",
        "            self.output_sizes[task_id] = self.model.fc.weight.size(0)\n",
        "            print(f\"Stored output size for task {task_id}: {self.output_sizes[task_id]}\")\n",
        "        elif hasattr(self.model, 'classifier'):\n",
        "            self.output_sizes[task_id] = self.model.classifier.weight.size(0)\n",
        "            print(f\"Stored output size for task {task_id}: {self.output_sizes[task_id]}\")\n",
        "\n",
        "    def ewc_loss(self, current_task_id):\n",
        "        \"\"\"\n",
        "        Calculate the EWC penalty with importance scaling and verification.\n",
        "\n",
        "        Args:\n",
        "            current_task_id: ID of the current task\n",
        "\n",
        "        Returns:\n",
        "            EWC penalty loss\n",
        "        \"\"\"\n",
        "        if current_task_id == 0:\n",
        "            return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        total_loss = 0\n",
        "        param_count = 0\n",
        "\n",
        "        # Calculate EWC loss for all previous tasks\n",
        "        for task_id in range(current_task_id):\n",
        "            task_loss = 0\n",
        "\n",
        "            for n, p in self.model.named_parameters():\n",
        "                if p.requires_grad and n in self.fisher_dict[task_id] and n in self.optpar_dict[task_id]:\n",
        "                    # Handle expanding output layer\n",
        "                    if \"fc.weight\" in n:\n",
        "                        prev_size = self.output_sizes[task_id]\n",
        "                        fisher_term = self.fisher_dict[task_id][n][:prev_size, :]\n",
        "                        param_diff = (p[:prev_size, :] - self.optpar_dict[task_id][n][:prev_size, :]).pow(2)\n",
        "                        task_loss += (fisher_term * param_diff).sum()\n",
        "                        param_count += fisher_term.numel()\n",
        "                    elif \"fc.bias\" in n:\n",
        "                        prev_size = self.output_sizes[task_id]\n",
        "                        fisher_term = self.fisher_dict[task_id][n][:prev_size]\n",
        "                        param_diff = (p[:prev_size] - self.optpar_dict[task_id][n][:prev_size]).pow(2)\n",
        "                        task_loss += (fisher_term * param_diff).sum()\n",
        "                        param_count += fisher_term.numel()\n",
        "                    else:\n",
        "                        fisher_term = self.fisher_dict[task_id][n]\n",
        "                        param_diff = (p - self.optpar_dict[task_id][n]).pow(2)\n",
        "                        task_loss += (fisher_term * param_diff).sum()\n",
        "                        param_count += fisher_term.numel()\n",
        "\n",
        "            total_loss += task_loss\n",
        "\n",
        "        # Apply lambda scaling\n",
        "        ewc_penalty = self.lambda_ewc * total_loss / 2\n",
        "\n",
        "        # Verify EWC penalty is significant enough (only in training mode to avoid spam)\n",
        "        if self.model.training:\n",
        "            with torch.no_grad():\n",
        "                avg_penalty = ewc_penalty.item() / param_count if param_count > 0 else 0\n",
        "                if avg_penalty < 1e-4:\n",
        "                    print(f\"WARNING: Average EWC penalty per parameter is very small: {avg_penalty:.8f}\")\n",
        "\n",
        "        return ewc_penalty\n",
        "\n",
        "    def freeze_important_parameters(self, current_task_id, importance_threshold=0.1):\n",
        "        \"\"\"\n",
        "        Freeze parameters that are most important for previous tasks.\n",
        "\n",
        "        Args:\n",
        "            current_task_id: ID of the current task\n",
        "            importance_threshold: Threshold for determining important parameters\n",
        "        \"\"\"\n",
        "        if current_task_id == 0:\n",
        "            return\n",
        "\n",
        "        # Calculate importance for each parameter based on Fisher\n",
        "        importance = {}\n",
        "        for n, p in self.model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                importance[n] = 0\n",
        "                for task_id in range(current_task_id):\n",
        "                    if n in self.fisher_dict[task_id]:\n",
        "                        # For expanding layers, only consider the relevant part\n",
        "                        if \"fc.weight\" in n or \"fc.bias\" in n:\n",
        "                            prev_size = self.output_sizes[task_id]\n",
        "                            if \"fc.weight\" in n:\n",
        "                                importance[n] += self.fisher_dict[task_id][n][:prev_size, :].mean().item()\n",
        "                            else:  # fc.bias\n",
        "                                importance[n] += self.fisher_dict[task_id][n][:prev_size].mean().item()\n",
        "                        else:\n",
        "                            importance[n] += self.fisher_dict[task_id][n].mean().item()\n",
        "\n",
        "                # Average across tasks\n",
        "                importance[n] /= current_task_id\n",
        "\n",
        "        # Sort parameters by importance\n",
        "        sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Determine threshold value\n",
        "        if importance_threshold < 1:  # Interpreted as a fraction\n",
        "            threshold_idx = int(len(sorted_importance) * importance_threshold)\n",
        "            threshold_value = sorted_importance[threshold_idx][1] if threshold_idx < len(sorted_importance) else 0\n",
        "        else:  # Interpreted as an absolute value\n",
        "            threshold_value = importance_threshold\n",
        "\n",
        "        # Freeze important parameters\n",
        "        frozen_count = 0\n",
        "        self.important_params = {}\n",
        "        for n, imp in sorted_importance:\n",
        "            if imp > threshold_value:\n",
        "                for name, param in self.model.named_parameters():\n",
        "                    if name == n:\n",
        "                        param.requires_grad = False\n",
        "                        self.important_params[name] = imp\n",
        "                        frozen_count += 1\n",
        "                        break\n",
        "\n",
        "        print(f\"Froze {frozen_count} important parameters with importance > {threshold_value:.6f}\")\n",
        "\n",
        "    def consolidate_weights(self):\n",
        "        \"\"\"\n",
        "        Consolidate weights after training on a task by averaging with previous optimal weights\n",
        "        weighted by their importance.\n",
        "        \"\"\"\n",
        "        if not self.optpar_dict:  # No previous tasks\n",
        "            return\n",
        "\n",
        "        print(\"Consolidating weights based on importance...\")\n",
        "\n",
        "        # Get the most recent task_id\n",
        "        last_task_id = max(self.optpar_dict.keys())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for n, p in self.model.named_parameters():\n",
        "                if n in self.important_params and n in self.optpar_dict[last_task_id]:\n",
        "                    # Calculate importance-weighted average of current weights and previous optimal weights\n",
        "                    importance = self.important_params[n]\n",
        "                    if importance > 0.1:  # Only consolidate highly important parameters\n",
        "                        weight_factor = min(0.8, importance)  # Cap at 0.8 to allow some adaptation\n",
        "                        consolidated_weight = (\n",
        "                            weight_factor * self.optpar_dict[last_task_id][n] +\n",
        "                            (1 - weight_factor) * p.data\n",
        "                        )\n",
        "                        p.data.copy_(consolidated_weight)\n",
        "                        print(f\"Consolidated parameter {n} with weight factor {weight_factor:.4f}\")"
      ],
      "metadata": {
        "id": "spOBQduj5jgi"
      },
      "id": "spOBQduj5jgi",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net_ewc_replay(max_epochs, freeze_epochs, patience, ewc, net_to_train, opt, train_loader, val_loader, task, save_file=None, save_path=None):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    net_to_train.cuda()\n",
        "\n",
        "    initial_freeze = (task == 0) # Only freeze initially for the very first task\n",
        "\n",
        "    if task > 0:\n",
        "        ewc.freeze_important_parameters(task, importance_threshold=0.05)\n",
        "\n",
        "    for name, param in net_to_train.named_parameters():\n",
        "        # do not train non-fc layers\n",
        "        if initial_freeze and 'fc' not in name:\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    optimizer = opt\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    print(f\"Starting training for Task {task}. Trainable parameters:\")\n",
        "    for name, param in net_to_train.named_parameters():\n",
        "        if param.requires_grad:\n",
        "             print(f\"  - {name}\")\n",
        "\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        net_to_train.train()\n",
        "        running_loss = 0.0\n",
        "        running_ewc = 0.0\n",
        "\n",
        "        # Unfreeze logic (if desired for staged training within a task)\n",
        "        if epoch == freeze_epochs and task > 0: # Only unfreeze/adjust LR if NOT task 0 and freeze_epochs > 0\n",
        "            print(f\"Unfreezing backbone at epoch {epoch} for task {task}\")\n",
        "            for name, param in net_to_train.named_parameters():\n",
        "                if not param.requires_grad and 'fc' not in name:\n",
        "                    # Check if this parameter was frozen by importance\n",
        "                    was_frozen_by_importance = False\n",
        "                    for n, imp in getattr(ewc, 'important_params', {}).items():\n",
        "                        if n == name:\n",
        "                            was_frozen_by_importance = True\n",
        "                            break\n",
        "\n",
        "                    if not was_frozen_by_importance:\n",
        "                        param.requires_grad = True\n",
        "\n",
        "            # Adjust LR for the existing optimizer\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            new_lr = 1e-4 # Or some other value\n",
        "            if current_lr != new_lr:\n",
        "                 print(f\"Setting LR to {new_lr}\")\n",
        "                 for g in optimizer.param_groups:\n",
        "                     g['lr'] = new_lr\n",
        "\n",
        "\n",
        "        for imgs, labels in tqdm(train_loader, unit='batch', desc=f\"Task {task} Epoch {epoch+1}\"):\n",
        "            imgs, labels = imgs.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net_to_train(imgs)\n",
        "            loss = criterion(outputs, labels) # Loss calculated on combined batch\n",
        "            ewc_loss = ewc.ewc_loss(task)\n",
        "            running_ewc += ewc_loss.item()\n",
        "            loss += ewc_loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(net_to_train.parameters(), max_norm=1.0) # Gradient clipping\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        avg_ewc_loss = running_ewc / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # --- Validation (Use Cumulative Loader!) ---\n",
        "        current_val_loss = val_net(net_to_train, val_loader) # val_loader MUST be cumulative\n",
        "        val_losses.append(current_val_loss)\n",
        "\n",
        "        print(f\"Task {task}, Epoch {epoch + 1}, EWC Loss: {avg_ewc_loss:.4f}, Total Loss: {avg_loss:.4f}, Val Loss (Cumulative): {current_val_loss:.4f}\")\n",
        "\n",
        "        # --- Logging to file ---\n",
        "        if save_file:\n",
        "             with open(save_file, 'a') as f:\n",
        "                  f.write(f\"{task},{epoch + 1},{avg_loss},{current_val_loss}\\n\") # Log cumulative val loss\n",
        "\n",
        "        # --- Early Stopping (Based on CUMULATIVE validation loss) ---\n",
        "        if current_val_loss < best_val_loss:\n",
        "            best_val_loss = current_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            if save_path: # Optional: save best model state\n",
        "               torch.save(net_to_train.state_dict(), os.path.join(save_path, f\"model_task{task}_best.pth\"))\n",
        "               print(f\"  New best validation loss: {best_val_loss:.4f}. Saved best model.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            # print(f\"  Validation loss did not improve for {epochs_no_improve} epoch(s). Best: {best_val_loss:.4f}\") # Optional verbose print\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch + 1} for task {task}. Best Val Loss: {best_val_loss:.4f}\")\n",
        "            if save_path and os.path.exists(os.path.join(save_path, f\"model_task{task}_best.pth\")):\n",
        "               print(\"Loading best model weights before exiting.\")\n",
        "               net_to_train.load_state_dict(torch.load(os.path.join(save_path, f\"model_task{task}_best.pth\")))\n",
        "            break\n",
        "\n",
        "    print(f\"Finished training task {task}\")\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "mfz2G2XV42EH"
      },
      "id": "mfz2G2XV42EH",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = models.resnet18(pretrained=True)\n",
        "ewc = EWC(model, device='cuda', lambda_ewc=10e7)\n",
        "\n",
        "# freeze all parameters except the last fc layer\n",
        "for name, param in model.named_parameters():\n",
        "    if name != 'fc.weight' and name != 'fc.bias':\n",
        "        param.requires_grad = False\n",
        "\n",
        "# --- Add outside the loop ---\n",
        "memory_buffer = [] # Simple list to store (image_tensor, label) tuples\n",
        "memory_size = 1000 # Max number of samples in buffer (hyperparameter)\n",
        "samples_per_task_in_memory = 20 # How many samples to add from each task (hyperparameter)\n",
        "\n",
        "def update_memory_buffer(buffer, max_size, new_samples):\n",
        "    \"\"\"Adds new samples to the buffer and trims it if it exceeds max_size.\"\"\"\n",
        "    buffer.extend(new_samples)\n",
        "    # If buffer exceeds max size, remove samples randomly (or use FIFO)\n",
        "    overflow = len(buffer) - max_size\n",
        "    if overflow > 0:\n",
        "        # Randomly remove 'overflow' samples\n",
        "        indices_to_remove = random.sample(range(len(buffer)), overflow)\n",
        "        # Remove in reverse sorted order to avoid index shifting issues\n",
        "        for index in sorted(indices_to_remove, reverse=True):\n",
        "            del buffer[index]\n",
        "        # Alternatively, for FIFO: del buffer[:overflow]\n",
        "    print(f\"Memory buffer size: {len(buffer)} / {max_size}\")\n",
        "\n",
        "class MemoryDataset(Dataset):\n",
        "    \"\"\"A simple Dataset wrapper for the list-based memory buffer.\"\"\"\n",
        "    def __init__(self, buffer_list):\n",
        "        self.buffer = buffer_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # buffer contains (image_tensor, label)\n",
        "        return self.buffer[idx]\n",
        "\n",
        "# --- Modify your main loop ---\n",
        "save_dir = 'replay-ewc-coarse-grained' # Changed directory name\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "# Clear or initialize log files\n",
        "open(os.path.join(save_dir, 'train_val_losses.txt'), 'w').close()\n",
        "open(os.path.join(save_dir, 'accuracies.txt'), 'w').write(\"Task,Overall Accuracy,Per-Class Accuracy\\n\")\n",
        "\n",
        "\n",
        "for task in range(5):\n",
        "    print(f\"Training on task {task}...\")\n",
        "\n",
        "    model = modify_resnet_head(model, (task+1) * 10)\n",
        "    model = model.cuda()\n",
        "\n",
        "    # --- Prepare Current Task Dataset ---\n",
        "    current_task_train_subset = Subset(train_dataset, train_task_idxs[task])\n",
        "\n",
        "    # --- Prepare Combined Training Loader ---\n",
        "    if task > 0 and len(memory_buffer) > 0:\n",
        "        # Create a dataset from the memory buffer\n",
        "        replay_dataset = MemoryDataset(memory_buffer)\n",
        "        # Combine current task data and replay data\n",
        "        combined_train_dataset = ConcatDataset([current_task_train_subset, replay_dataset])\n",
        "        print(f\"Task {task}: Training with {len(current_task_train_subset)} current samples and {len(replay_dataset)} replay samples.\")\n",
        "    else:\n",
        "        # Task 0 or empty buffer: train only on current task data\n",
        "        combined_train_dataset = current_task_train_subset\n",
        "        print(f\"Task {task}: Training only with {len(current_task_train_subset)} current samples.\")\n",
        "\n",
        "    # Create DataLoader for the combined dataset\n",
        "    # Adjust batch size if needed, maybe smaller if memory is large\n",
        "    train_loader_combined = DataLoader(\n",
        "        combined_train_dataset,\n",
        "        batch_size=128, # Or adjust dynamically\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    # --- Validation and Test Loaders (Should still be CUMULATIVE!) ---\n",
        "    val_loader_cumulative = torch.utils.data.DataLoader(\n",
        "        Subset(val_dataset, val_task_idxs[task]),\n",
        "        batch_size=256,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    test_loader_cumulative = torch.utils.data.DataLoader(\n",
        "        Subset(test_dataset, test_task_idxs[task]),\n",
        "        batch_size=256,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    # --- Optimizer ---\n",
        "    # Consider re-initializing or adjusting LR, especially after task 0\n",
        "    if task == 0:\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0015)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4) # Lower LR for full network\n",
        "\n",
        "\n",
        "    # --- Train the model ---\n",
        "    # train_net now uses the combined loader\n",
        "    # No need for EWC parameters here\n",
        "    train_losses, val_losses = train_net_ewc_replay(\n",
        "        max_epochs=15,\n",
        "        freeze_epochs=5, # Still relevant if you want staged training\n",
        "        patience=5,\n",
        "        ewc=ewc,\n",
        "        net_to_train=model,\n",
        "        opt=optimizer,\n",
        "        train_loader=train_loader_combined, # Use the combined loader\n",
        "        val_loader=val_loader_cumulative, # Use the CUMULATIVE validation loader\n",
        "        task=task,\n",
        "        save_file=os.path.join(save_dir, 'train_val_losses.txt')\n",
        "    )\n",
        "\n",
        "    # --- Update EWC after training ---\n",
        "    ewc.store_task_parameters(task, train_loader_combined)\n",
        "    ewc.consolidate_weights()\n",
        "\n",
        "    # --- Update Memory Buffer AFTER training ---\n",
        "    # Select samples from the task just finished\n",
        "    num_to_sample = min(samples_per_task_in_memory, len(current_task_train_subset))\n",
        "    if num_to_sample > 0:\n",
        "        indices_to_sample = random.sample(range(len(current_task_train_subset)), num_to_sample)\n",
        "        new_memory_samples = []\n",
        "        print(f\"Sampling {num_to_sample} examples from task {task} for memory buffer...\")\n",
        "        for idx in indices_to_sample:\n",
        "            # Get the actual data point (image tensor, label) from the subset\n",
        "            img_tensor, label = current_task_train_subset[idx]\n",
        "            new_memory_samples.append((img_tensor, label)) # Append as tuple\n",
        "\n",
        "        # Add to buffer and manage size\n",
        "        update_memory_buffer(memory_buffer, memory_size, new_memory_samples)\n",
        "    else:\n",
        "        print(f\"Not enough samples in task {task} subset to add to memory.\")\n",
        "\n",
        "\n",
        "    # --- Evaluate and Save ---\n",
        "    overall_acc, per_class_acc = get_test_accuracy(model, test_loader_cumulative, (task+1) * 10)\n",
        "    print(f\"Overall accuracy for task {task} (on classes 0-{(task+1)*10 - 1}): {overall_acc:.4f}\")\n",
        "\n",
        "    with open(os.path.join(save_dir, 'accuracies.txt'), 'a') as f:\n",
        "        f.write(f\"{task},{overall_acc:.4f},{per_class_acc}\\n\")\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, f\"model_task_{task}.pth\"))\n",
        "    print(f\"Model for task {task} saved as model_task_{task}.pth\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ELJye_8m5iEp",
        "outputId": "33d584b1-aa75-4cb0-b08c-f820a31538d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ELJye_8m5iEp",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on task 0...\n",
            "Task 0: Training only with 599 current samples.\n",
            "Starting training for Task 0. Trainable parameters:\n",
            "  - fc.weight\n",
            "  - fc.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 1: 100%|██████████| 5/5 [00:04<00:00,  1.13batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 1, EWC Loss: 0.0000, Total Loss: 2.3803, Val Loss (Cumulative): 2.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 2: 100%|██████████| 5/5 [00:03<00:00,  1.59batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 2, EWC Loss: 0.0000, Total Loss: 1.7852, Val Loss (Cumulative): 1.6639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 3: 100%|██████████| 5/5 [00:03<00:00,  1.37batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 3, EWC Loss: 0.0000, Total Loss: 1.3890, Val Loss (Cumulative): 1.3474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 4: 100%|██████████| 5/5 [00:03<00:00,  1.60batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 4, EWC Loss: 0.0000, Total Loss: 1.1109, Val Loss (Cumulative): 1.1345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 5: 100%|██████████| 5/5 [00:03<00:00,  1.59batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 5, EWC Loss: 0.0000, Total Loss: 0.8849, Val Loss (Cumulative): 0.9859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 6: 100%|██████████| 5/5 [00:04<00:00,  1.10batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 6, EWC Loss: 0.0000, Total Loss: 0.7376, Val Loss (Cumulative): 0.8777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 7: 100%|██████████| 5/5 [00:03<00:00,  1.59batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 7, EWC Loss: 0.0000, Total Loss: 0.6351, Val Loss (Cumulative): 0.7882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 8: 100%|██████████| 5/5 [00:03<00:00,  1.59batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 8, EWC Loss: 0.0000, Total Loss: 0.5426, Val Loss (Cumulative): 0.7582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 9: 100%|██████████| 5/5 [00:03<00:00,  1.39batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 9, EWC Loss: 0.0000, Total Loss: 0.4795, Val Loss (Cumulative): 0.6865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 10: 100%|██████████| 5/5 [00:03<00:00,  1.57batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 10, EWC Loss: 0.0000, Total Loss: 0.4318, Val Loss (Cumulative): 0.6639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 11: 100%|██████████| 5/5 [00:03<00:00,  1.37batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 11, EWC Loss: 0.0000, Total Loss: 0.3771, Val Loss (Cumulative): 0.6492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 12: 100%|██████████| 5/5 [00:03<00:00,  1.58batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 12, EWC Loss: 0.0000, Total Loss: 0.3570, Val Loss (Cumulative): 0.6238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 13: 100%|██████████| 5/5 [00:03<00:00,  1.58batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 13, EWC Loss: 0.0000, Total Loss: 0.3158, Val Loss (Cumulative): 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 14: 100%|██████████| 5/5 [00:04<00:00,  1.18batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 14, EWC Loss: 0.0000, Total Loss: 0.2975, Val Loss (Cumulative): 0.6180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 0 Epoch 15: 100%|██████████| 5/5 [00:03<00:00,  1.57batch/s]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 0, Epoch 15, EWC Loss: 0.0000, Total Loss: 0.2738, Val Loss (Cumulative): 0.5709\n",
            "Finished training task 0\n",
            "Storing parameters for task 0...\n",
            "Stored parameter fc.weight: min=-0.119342, max=0.112156, mean=-0.005719\n",
            "Stored parameter fc.bias: min=-0.051298, max=0.046737, mean=0.007633\n",
            "Stored output size for task 0: 10\n",
            "Consolidating weights based on importance...\n",
            "Sampling 20 examples from task 0 for memory buffer...\n",
            "Memory buffer size: 20 / 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy for task 0 (on classes 0-9): 0.8300\n",
            "Model for task 0 saved as model_task_0.pth\n",
            "Training on task 1...\n",
            "Task 1: Training with 591 current samples and 20 replay samples.\n",
            "Froze 0 important parameters with importance > 0.037191\n",
            "Starting training for Task 1. Trainable parameters:\n",
            "  - conv1.weight\n",
            "  - bn1.weight\n",
            "  - bn1.bias\n",
            "  - layer1.0.conv1.weight\n",
            "  - layer1.0.bn1.weight\n",
            "  - layer1.0.bn1.bias\n",
            "  - layer1.0.conv2.weight\n",
            "  - layer1.0.bn2.weight\n",
            "  - layer1.0.bn2.bias\n",
            "  - layer1.1.conv1.weight\n",
            "  - layer1.1.bn1.weight\n",
            "  - layer1.1.bn1.bias\n",
            "  - layer1.1.conv2.weight\n",
            "  - layer1.1.bn2.weight\n",
            "  - layer1.1.bn2.bias\n",
            "  - layer2.0.conv1.weight\n",
            "  - layer2.0.bn1.weight\n",
            "  - layer2.0.bn1.bias\n",
            "  - layer2.0.conv2.weight\n",
            "  - layer2.0.bn2.weight\n",
            "  - layer2.0.bn2.bias\n",
            "  - layer2.0.downsample.0.weight\n",
            "  - layer2.0.downsample.1.weight\n",
            "  - layer2.0.downsample.1.bias\n",
            "  - layer2.1.conv1.weight\n",
            "  - layer2.1.bn1.weight\n",
            "  - layer2.1.bn1.bias\n",
            "  - layer2.1.conv2.weight\n",
            "  - layer2.1.bn2.weight\n",
            "  - layer2.1.bn2.bias\n",
            "  - layer3.0.conv1.weight\n",
            "  - layer3.0.bn1.weight\n",
            "  - layer3.0.bn1.bias\n",
            "  - layer3.0.conv2.weight\n",
            "  - layer3.0.bn2.weight\n",
            "  - layer3.0.bn2.bias\n",
            "  - layer3.0.downsample.0.weight\n",
            "  - layer3.0.downsample.1.weight\n",
            "  - layer3.0.downsample.1.bias\n",
            "  - layer3.1.conv1.weight\n",
            "  - layer3.1.bn1.weight\n",
            "  - layer3.1.bn1.bias\n",
            "  - layer3.1.conv2.weight\n",
            "  - layer3.1.bn2.weight\n",
            "  - layer3.1.bn2.bias\n",
            "  - layer4.0.conv1.weight\n",
            "  - layer4.0.bn1.weight\n",
            "  - layer4.0.bn1.bias\n",
            "  - layer4.0.conv2.weight\n",
            "  - layer4.0.bn2.weight\n",
            "  - layer4.0.bn2.bias\n",
            "  - layer4.0.downsample.0.weight\n",
            "  - layer4.0.downsample.1.weight\n",
            "  - layer4.0.downsample.1.bias\n",
            "  - layer4.1.conv1.weight\n",
            "  - layer4.1.bn1.weight\n",
            "  - layer4.1.bn1.bias\n",
            "  - layer4.1.conv2.weight\n",
            "  - layer4.1.bn2.weight\n",
            "  - layer4.1.bn2.bias\n",
            "  - fc.weight\n",
            "  - fc.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 1:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 1: 100%|██████████| 5/5 [00:04<00:00,  1.10batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 1, EWC Loss: 31.6160, Total Loss: 34.0099, Val Loss (Cumulative): 2.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 2: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 2, EWC Loss: 13.5389, Total Loss: 15.1845, Val Loss (Cumulative): 2.0538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 3: 100%|██████████| 5/5 [00:04<00:00,  1.01batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 3, EWC Loss: 6.0242, Total Loss: 7.4648, Val Loss (Cumulative): 2.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 4: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 4, EWC Loss: 3.1720, Total Loss: 4.5344, Val Loss (Cumulative): 2.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 5: 100%|██████████| 5/5 [00:05<00:00,  1.15s/batch]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 5, EWC Loss: 1.6544, Total Loss: 2.9400, Val Loss (Cumulative): 1.9785\n",
            "Unfreezing backbone at epoch 5 for task 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 6: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 6, EWC Loss: 0.8813, Total Loss: 2.1257, Val Loss (Cumulative): 1.9502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 7:  60%|██████    | 3/5 [00:03<00:02,  1.00s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00007767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 7:  80%|████████  | 4/5 [00:04<00:00,  1.27batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00007641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 7: 100%|██████████| 5/5 [00:04<00:00,  1.07batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 7, EWC Loss: 0.4859, Total Loss: 1.6644, Val Loss (Cumulative): 1.9220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 8:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00007385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 8:  20%|██        | 1/5 [00:02<00:11,  2.88s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 8:  40%|████      | 2/5 [00:03<00:04,  1.46s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 8:  60%|██████    | 3/5 [00:03<00:02,  1.00s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 8:  80%|████████  | 4/5 [00:04<00:00,  1.27batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 8: 100%|██████████| 5/5 [00:04<00:00,  1.05batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 8, EWC Loss: 0.2933, Total Loss: 1.4109, Val Loss (Cumulative): 1.8898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 9:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 9:  20%|██        | 1/5 [00:02<00:11,  2.88s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 9:  40%|████      | 2/5 [00:03<00:04,  1.46s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 9:  60%|██████    | 3/5 [00:03<00:01,  1.00batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 9:  80%|████████  | 4/5 [00:04<00:00,  1.28batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 9: 100%|██████████| 5/5 [00:04<00:00,  1.07batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 9, EWC Loss: 0.1956, Total Loss: 1.2541, Val Loss (Cumulative): 1.8542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 10:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 10:  20%|██        | 1/5 [00:02<00:11,  2.96s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 10:  40%|████      | 2/5 [00:03<00:04,  1.56s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 10:  60%|██████    | 3/5 [00:04<00:02,  1.08s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 10:  80%|████████  | 4/5 [00:04<00:00,  1.17batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 10: 100%|██████████| 5/5 [00:04<00:00,  1.00batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 10, EWC Loss: 0.1500, Total Loss: 1.1212, Val Loss (Cumulative): 1.8152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 11:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 11:  20%|██        | 1/5 [00:02<00:11,  2.85s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 11:  40%|████      | 2/5 [00:03<00:04,  1.45s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 11:  60%|██████    | 3/5 [00:03<00:01,  1.01batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 11:  80%|████████  | 4/5 [00:04<00:00,  1.28batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 11: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 11, EWC Loss: 0.1197, Total Loss: 1.0009, Val Loss (Cumulative): 1.7773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 12:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 12:  20%|██        | 1/5 [00:03<00:15,  3.99s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 12:  40%|████      | 2/5 [00:04<00:05,  1.92s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 12:  60%|██████    | 3/5 [00:04<00:02,  1.25s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 12:  80%|████████  | 4/5 [00:05<00:00,  1.07batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 12: 100%|██████████| 5/5 [00:05<00:00,  1.15s/batch]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 12, EWC Loss: 0.1013, Total Loss: 0.8880, Val Loss (Cumulative): 1.7416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 13:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 13:  20%|██        | 1/5 [00:02<00:11,  2.93s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 13:  40%|████      | 2/5 [00:03<00:04,  1.48s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 13:  60%|██████    | 3/5 [00:03<00:02,  1.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 13:  80%|████████  | 4/5 [00:04<00:00,  1.26batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 13: 100%|██████████| 5/5 [00:04<00:00,  1.06batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 13, EWC Loss: 0.0895, Total Loss: 0.8289, Val Loss (Cumulative): 1.7050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 14:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 14:  20%|██        | 1/5 [00:03<00:12,  3.04s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 14:  40%|████      | 2/5 [00:03<00:04,  1.53s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 14:  60%|██████    | 3/5 [00:03<00:02,  1.04s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 14:  80%|████████  | 4/5 [00:04<00:00,  1.24batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 14: 100%|██████████| 5/5 [00:04<00:00,  1.03batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 14, EWC Loss: 0.1729, Total Loss: 0.8172, Val Loss (Cumulative): 1.6711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 15:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 15:  20%|██        | 1/5 [00:02<00:11,  2.78s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 15:  40%|████      | 2/5 [00:03<00:04,  1.42s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 15:  60%|██████    | 3/5 [00:03<00:01,  1.02batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 1 Epoch 15:  80%|████████  | 4/5 [00:04<00:00,  1.28batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 1 Epoch 15: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1, Epoch 15, EWC Loss: 0.1921, Total Loss: 0.7774, Val Loss (Cumulative): 1.6487\n",
            "Finished training task 1\n",
            "Storing parameters for task 1...\n",
            "Stored parameter layer4.0.conv1.weight: min=-0.264371, max=0.383067, mean=-0.001575\n",
            "Stored parameter layer4.0.bn1.weight: min=0.136661, max=0.428629, mean=0.264354\n",
            "Stored parameter layer4.0.bn1.bias: min=-0.477037, max=0.145683, mean=-0.225701\n",
            "Stored parameter layer4.0.conv2.weight: min=-0.282774, max=0.348377, mean=-0.001305\n",
            "Stored parameter layer4.0.bn2.weight: min=0.140037, max=0.732721, mean=0.424390\n",
            "Stored parameter layer4.0.bn2.bias: min=-0.400334, max=0.117097, mean=-0.197624\n",
            "Stored parameter layer4.0.downsample.0.weight: min=-0.628815, max=0.746463, mean=-0.000855\n",
            "Stored parameter layer4.0.downsample.1.weight: min=-0.053271, max=0.509675, mean=0.250608\n",
            "Stored parameter layer4.0.downsample.1.bias: min=-0.400334, max=0.117097, mean=-0.197624\n",
            "Stored parameter layer4.1.conv1.weight: min=-0.194928, max=0.265121, mean=-0.002261\n",
            "Stored parameter layer4.1.bn1.weight: min=0.097248, max=0.465722, mean=0.288570\n",
            "Stored parameter layer4.1.bn1.bias: min=-0.594482, max=0.053118, mean=-0.241736\n",
            "Stored parameter layer4.1.conv2.weight: min=-0.173942, max=0.272460, mean=-0.000118\n",
            "Stored parameter layer4.1.bn2.weight: min=1.578238, max=2.409823, mean=1.853904\n",
            "Stored parameter layer4.1.bn2.bias: min=0.072867, max=0.651685, mean=0.273993\n",
            "Stored parameter fc.weight: min=-0.119344, max=0.112157, mean=-0.002944\n",
            "Stored parameter fc.bias: min=-0.051300, max=0.046734, mean=0.003548\n",
            "Stored output size for task 1: 20\n",
            "Consolidating weights based on importance...\n",
            "Sampling 20 examples from task 1 for memory buffer...\n",
            "Memory buffer size: 40 / 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 4/4 [00:04<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy for task 1 (on classes 0-19): 0.5787\n",
            "Model for task 1 saved as model_task_1.pth\n",
            "Training on task 2...\n",
            "Task 2: Training with 599 current samples and 40 replay samples.\n",
            "Froze 3 important parameters with importance > 0.061667\n",
            "Starting training for Task 2. Trainable parameters:\n",
            "  - conv1.weight\n",
            "  - bn1.weight\n",
            "  - bn1.bias\n",
            "  - layer1.0.conv1.weight\n",
            "  - layer1.0.bn1.weight\n",
            "  - layer1.0.bn1.bias\n",
            "  - layer1.0.conv2.weight\n",
            "  - layer1.0.bn2.weight\n",
            "  - layer1.0.bn2.bias\n",
            "  - layer1.1.conv1.weight\n",
            "  - layer1.1.bn1.weight\n",
            "  - layer1.1.bn1.bias\n",
            "  - layer1.1.conv2.weight\n",
            "  - layer1.1.bn2.weight\n",
            "  - layer1.1.bn2.bias\n",
            "  - layer2.0.conv1.weight\n",
            "  - layer2.0.bn1.weight\n",
            "  - layer2.0.bn1.bias\n",
            "  - layer2.0.conv2.weight\n",
            "  - layer2.0.bn2.weight\n",
            "  - layer2.0.bn2.bias\n",
            "  - layer2.0.downsample.0.weight\n",
            "  - layer2.0.downsample.1.weight\n",
            "  - layer2.0.downsample.1.bias\n",
            "  - layer2.1.conv1.weight\n",
            "  - layer2.1.bn1.weight\n",
            "  - layer2.1.bn1.bias\n",
            "  - layer2.1.conv2.weight\n",
            "  - layer2.1.bn2.weight\n",
            "  - layer2.1.bn2.bias\n",
            "  - layer3.0.conv1.weight\n",
            "  - layer3.0.bn1.weight\n",
            "  - layer3.0.bn1.bias\n",
            "  - layer3.0.conv2.weight\n",
            "  - layer3.0.bn2.weight\n",
            "  - layer3.0.bn2.bias\n",
            "  - layer3.0.downsample.0.weight\n",
            "  - layer3.0.downsample.1.weight\n",
            "  - layer3.0.downsample.1.bias\n",
            "  - layer3.1.conv1.weight\n",
            "  - layer3.1.bn1.weight\n",
            "  - layer3.1.bn1.bias\n",
            "  - layer3.1.conv2.weight\n",
            "  - layer3.1.bn2.weight\n",
            "  - layer3.1.bn2.bias\n",
            "  - layer4.0.conv1.weight\n",
            "  - layer4.0.bn1.weight\n",
            "  - layer4.0.bn1.bias\n",
            "  - layer4.0.conv2.weight\n",
            "  - layer4.0.bn2.weight\n",
            "  - layer4.0.bn2.bias\n",
            "  - layer4.0.downsample.0.weight\n",
            "  - layer4.0.downsample.1.weight\n",
            "  - layer4.0.downsample.1.bias\n",
            "  - layer4.1.conv1.weight\n",
            "  - layer4.1.bn1.weight\n",
            "  - layer4.1.bn1.bias\n",
            "  - layer4.1.conv2.weight\n",
            "  - layer4.1.bn2.weight\n",
            "  - layer4.1.bn2.bias\n",
            "  - fc.weight\n",
            "  - fc.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 1:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 1:  40%|████      | 2/5 [00:03<00:04,  1.43s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 1:  60%|██████    | 3/5 [00:03<00:01,  1.00batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 1:  80%|████████  | 4/5 [00:04<00:00,  1.27batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00008618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 1: 100%|██████████| 5/5 [00:04<00:00,  1.06batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 1, EWC Loss: 756.0660, Total Loss: 759.5506, Val Loss (Cumulative): 2.5900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 2:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 2:  20%|██        | 1/5 [00:03<00:13,  3.42s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 2:  40%|████      | 2/5 [00:03<00:05,  1.69s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 2:  60%|██████    | 3/5 [00:04<00:02,  1.13s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 2:  80%|████████  | 4/5 [00:04<00:00,  1.15batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 2: 100%|██████████| 5/5 [00:05<00:00,  1.07s/batch]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 2, EWC Loss: 340.0959, Total Loss: 343.5072, Val Loss (Cumulative): 2.4764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 3:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 3:  20%|██        | 1/5 [00:02<00:10,  2.74s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 3:  40%|████      | 2/5 [00:03<00:04,  1.41s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 3:  60%|██████    | 3/5 [00:03<00:01,  1.02batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 3:  80%|████████  | 4/5 [00:04<00:00,  1.28batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 3: 100%|██████████| 5/5 [00:04<00:00,  1.05batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 3, EWC Loss: 126.2072, Total Loss: 129.6641, Val Loss (Cumulative): 2.5447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 4:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 4:  20%|██        | 1/5 [00:02<00:10,  2.67s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 4:  40%|████      | 2/5 [00:03<00:04,  1.39s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 4:  60%|██████    | 3/5 [00:03<00:01,  1.03batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 4:  80%|████████  | 4/5 [00:04<00:00,  1.30batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 4: 100%|██████████| 5/5 [00:04<00:00,  1.08batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 4, EWC Loss: 61.7312, Total Loss: 65.0517, Val Loss (Cumulative): 2.5462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 5:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 5:  20%|██        | 1/5 [00:04<00:16,  4.05s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 5:  40%|████      | 2/5 [00:04<00:05,  1.95s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 5:  60%|██████    | 3/5 [00:05<00:02,  1.28s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 5:  80%|████████  | 4/5 [00:05<00:00,  1.04batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 5: 100%|██████████| 5/5 [00:06<00:00,  1.20s/batch]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 5, EWC Loss: 47.2039, Total Loss: 50.5723, Val Loss (Cumulative): 2.5275\n",
            "Unfreezing backbone at epoch 5 for task 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 6:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 6:  20%|██        | 1/5 [00:02<00:11,  2.84s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 6:  40%|████      | 2/5 [00:03<00:04,  1.45s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 6:  60%|██████    | 3/5 [00:03<00:02,  1.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 6:  80%|████████  | 4/5 [00:04<00:00,  1.26batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 6: 100%|██████████| 5/5 [00:04<00:00,  1.04batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 6, EWC Loss: 22.5861, Total Loss: 25.8731, Val Loss (Cumulative): 2.5529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 7:   0%|          | 0/5 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 7:  20%|██        | 1/5 [00:02<00:11,  2.81s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 7:  40%|████      | 2/5 [00:03<00:04,  1.45s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 7:  60%|██████    | 3/5 [00:03<00:02,  1.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 2 Epoch 7:  80%|████████  | 4/5 [00:04<00:00,  1.25batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 2 Epoch 7: 100%|██████████| 5/5 [00:04<00:00,  1.04batch/s]\n",
            "Validating: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2, Epoch 7, EWC Loss: 14.0189, Total Loss: 17.2451, Val Loss (Cumulative): 2.5609\n",
            "Early stopping triggered at epoch 7 for task 2. Best Val Loss: 2.4764\n",
            "Finished training task 2\n",
            "Storing parameters for task 2...\n",
            "Stored parameter layer4.0.conv1.weight: min=-0.264367, max=0.383074, mean=-0.001576\n",
            "Stored parameter layer4.0.bn1.weight: min=0.136670, max=0.428622, mean=0.264354\n",
            "Stored parameter layer4.0.bn1.bias: min=-0.477031, max=0.145689, mean=-0.225701\n",
            "Stored parameter layer4.0.conv2.weight: min=-0.282766, max=0.348384, mean=-0.001305\n",
            "Stored parameter layer4.0.bn2.weight: min=0.140032, max=0.732727, mean=0.424391\n",
            "Stored parameter layer4.0.bn2.bias: min=-0.400330, max=0.117100, mean=-0.197623\n",
            "Stored parameter layer4.0.downsample.0.weight: min=-0.628806, max=0.746463, mean=-0.000855\n",
            "Stored parameter layer4.0.downsample.1.weight: min=-0.053268, max=0.509674, mean=0.250608\n",
            "Stored parameter layer4.0.downsample.1.bias: min=-0.400330, max=0.117100, mean=-0.197623\n",
            "Stored parameter layer4.1.conv1.weight: min=-0.194919, max=0.265121, mean=-0.002261\n",
            "Stored parameter layer4.1.bn1.weight: min=0.097244, max=0.465707, mean=0.288569\n",
            "Stored parameter layer4.1.bn1.bias: min=-0.594479, max=0.053111, mean=-0.241736\n",
            "Stored parameter layer4.1.conv2.weight: min=-0.173955, max=0.272458, mean=-0.000118\n",
            "Stored parameter layer4.1.bn2.weight: min=1.578236, max=2.409802, mean=1.853905\n",
            "Stored parameter layer4.1.bn2.bias: min=0.072881, max=0.651686, mean=0.273993\n",
            "Stored parameter fc.weight: min=-0.119341, max=0.112167, mean=-0.001712\n",
            "Stored parameter fc.bias: min=-0.051309, max=0.046747, mean=0.001014\n",
            "Stored output size for task 2: 30\n",
            "Consolidating weights based on importance...\n",
            "Consolidated parameter bn1.weight with weight factor 0.1010\n",
            "Consolidated parameter bn1.bias with weight factor 0.1668\n",
            "Consolidated parameter layer1.0.bn1.bias with weight factor 0.1189\n",
            "Sampling 20 examples from task 2 for memory buffer...\n",
            "Memory buffer size: 60 / 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy for task 2 (on classes 0-29): 0.3517\n",
            "Model for task 2 saved as model_task_2.pth\n",
            "Training on task 3...\n",
            "Task 3: Training with 596 current samples and 60 replay samples.\n",
            "Froze 3 important parameters with importance > 0.123007\n",
            "Starting training for Task 3. Trainable parameters:\n",
            "  - conv1.weight\n",
            "  - bn1.weight\n",
            "  - bn1.bias\n",
            "  - layer1.0.conv1.weight\n",
            "  - layer1.0.bn1.weight\n",
            "  - layer1.0.bn1.bias\n",
            "  - layer1.0.conv2.weight\n",
            "  - layer1.0.bn2.weight\n",
            "  - layer1.0.bn2.bias\n",
            "  - layer1.1.conv1.weight\n",
            "  - layer1.1.bn1.weight\n",
            "  - layer1.1.bn1.bias\n",
            "  - layer1.1.conv2.weight\n",
            "  - layer1.1.bn2.weight\n",
            "  - layer1.1.bn2.bias\n",
            "  - layer2.0.conv1.weight\n",
            "  - layer2.0.bn1.weight\n",
            "  - layer2.0.bn1.bias\n",
            "  - layer2.0.conv2.weight\n",
            "  - layer2.0.bn2.weight\n",
            "  - layer2.0.bn2.bias\n",
            "  - layer2.0.downsample.0.weight\n",
            "  - layer2.0.downsample.1.weight\n",
            "  - layer2.0.downsample.1.bias\n",
            "  - layer2.1.conv1.weight\n",
            "  - layer2.1.bn1.weight\n",
            "  - layer2.1.bn1.bias\n",
            "  - layer2.1.conv2.weight\n",
            "  - layer2.1.bn2.weight\n",
            "  - layer2.1.bn2.bias\n",
            "  - layer3.0.conv1.weight\n",
            "  - layer3.0.bn1.weight\n",
            "  - layer3.0.bn1.bias\n",
            "  - layer3.0.conv2.weight\n",
            "  - layer3.0.bn2.weight\n",
            "  - layer3.0.bn2.bias\n",
            "  - layer3.0.downsample.0.weight\n",
            "  - layer3.0.downsample.1.weight\n",
            "  - layer3.0.downsample.1.bias\n",
            "  - layer3.1.conv1.weight\n",
            "  - layer3.1.bn1.weight\n",
            "  - layer3.1.bn1.bias\n",
            "  - layer3.1.conv2.weight\n",
            "  - layer3.1.bn2.weight\n",
            "  - layer3.1.bn2.bias\n",
            "  - layer4.0.conv1.weight\n",
            "  - layer4.0.bn1.weight\n",
            "  - layer4.0.bn1.bias\n",
            "  - layer4.0.conv2.weight\n",
            "  - layer4.0.bn2.weight\n",
            "  - layer4.0.bn2.bias\n",
            "  - layer4.0.downsample.0.weight\n",
            "  - layer4.0.downsample.1.weight\n",
            "  - layer4.0.downsample.1.bias\n",
            "  - layer4.1.conv1.weight\n",
            "  - layer4.1.bn1.weight\n",
            "  - layer4.1.bn1.bias\n",
            "  - layer4.1.conv2.weight\n",
            "  - layer4.1.bn2.weight\n",
            "  - layer4.1.bn2.bias\n",
            "  - fc.weight\n",
            "  - fc.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 1:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 1:  50%|█████     | 3/6 [00:04<00:03,  1.20s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00008847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 1:  67%|██████▋   | 4/6 [00:05<00:01,  1.10batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 1: 100%|██████████| 6/6 [00:05<00:00,  1.04batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00004588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 1, EWC Loss: 2233.3681, Total Loss: 2236.9778, Val Loss (Cumulative): 3.1381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 2:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 2:  17%|█▋        | 1/6 [00:02<00:12,  2.53s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 2:  33%|███▎      | 2/6 [00:03<00:05,  1.33s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 2:  50%|█████     | 3/6 [00:03<00:02,  1.05batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 2:  67%|██████▋   | 4/6 [00:04<00:01,  1.31batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 2: 100%|██████████| 6/6 [00:04<00:00,  1.28batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 2, EWC Loss: 785.4734, Total Loss: 788.9553, Val Loss (Cumulative): 3.1211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 3:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 3:  17%|█▋        | 1/6 [00:02<00:13,  2.63s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 3:  33%|███▎      | 2/6 [00:03<00:05,  1.37s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 3:  50%|█████     | 3/6 [00:03<00:02,  1.04batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 3:  67%|██████▋   | 4/6 [00:04<00:01,  1.30batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 3: 100%|██████████| 6/6 [00:04<00:00,  1.27batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 3, EWC Loss: 295.4787, Total Loss: 298.9569, Val Loss (Cumulative): 3.1285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 4:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 4:  17%|█▋        | 1/6 [00:03<00:17,  3.58s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 4:  33%|███▎      | 2/6 [00:04<00:07,  1.76s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 4:  50%|█████     | 3/6 [00:04<00:03,  1.17s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 4:  67%|██████▋   | 4/6 [00:05<00:01,  1.11batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 4: 100%|██████████| 6/6 [00:05<00:00,  1.06batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 4, EWC Loss: 143.2358, Total Loss: 146.6575, Val Loss (Cumulative): 3.1338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 5:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 5:  17%|█▋        | 1/6 [00:02<00:13,  2.70s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 5:  33%|███▎      | 2/6 [00:03<00:05,  1.39s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 5:  50%|█████     | 3/6 [00:03<00:02,  1.02batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 5:  67%|██████▋   | 4/6 [00:04<00:01,  1.27batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 5: 100%|██████████| 6/6 [00:04<00:00,  1.23batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 5, EWC Loss: 68.8414, Total Loss: 72.1509, Val Loss (Cumulative): 3.1412\n",
            "Unfreezing backbone at epoch 5 for task 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 6:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 6:  17%|█▋        | 1/6 [00:02<00:13,  2.75s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 6:  33%|███▎      | 2/6 [00:03<00:05,  1.43s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 6:  50%|█████     | 3/6 [00:03<00:02,  1.01batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 6:  67%|██████▋   | 4/6 [00:04<00:01,  1.26batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 6: 100%|██████████| 6/6 [00:04<00:00,  1.24batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 6, EWC Loss: 37.8978, Total Loss: 41.0533, Val Loss (Cumulative): 3.1532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 7:   0%|          | 0/6 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 7:  17%|█▋        | 1/6 [00:03<00:15,  3.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 7:  33%|███▎      | 2/6 [00:03<00:06,  1.54s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 7:  50%|█████     | 3/6 [00:03<00:03,  1.06s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 3 Epoch 7:  67%|██████▋   | 4/6 [00:04<00:01,  1.20batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 3 Epoch 7: 100%|██████████| 6/6 [00:05<00:00,  1.17batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3, Epoch 7, EWC Loss: 23.3572, Total Loss: 26.4283, Val Loss (Cumulative): 3.1628\n",
            "Early stopping triggered at epoch 7 for task 3. Best Val Loss: 3.1211\n",
            "Finished training task 3\n",
            "Storing parameters for task 3...\n",
            "Stored parameter layer4.0.conv1.weight: min=-0.264365, max=0.383065, mean=-0.001576\n",
            "Stored parameter layer4.0.bn1.weight: min=0.136659, max=0.428622, mean=0.264354\n",
            "Stored parameter layer4.0.bn1.bias: min=-0.477037, max=0.145693, mean=-0.225701\n",
            "Stored parameter layer4.0.conv2.weight: min=-0.282775, max=0.348381, mean=-0.001305\n",
            "Stored parameter layer4.0.bn2.weight: min=0.140041, max=0.732726, mean=0.424390\n",
            "Stored parameter layer4.0.bn2.bias: min=-0.400338, max=0.117094, mean=-0.197624\n",
            "Stored parameter layer4.0.downsample.0.weight: min=-0.628815, max=0.746460, mean=-0.000855\n",
            "Stored parameter layer4.0.downsample.1.weight: min=-0.053276, max=0.509670, mean=0.250608\n",
            "Stored parameter layer4.0.downsample.1.bias: min=-0.400338, max=0.117094, mean=-0.197624\n",
            "Stored parameter layer4.1.conv1.weight: min=-0.194927, max=0.265118, mean=-0.002261\n",
            "Stored parameter layer4.1.bn1.weight: min=0.097249, max=0.465706, mean=0.288570\n",
            "Stored parameter layer4.1.bn1.bias: min=-0.594475, max=0.053120, mean=-0.241736\n",
            "Stored parameter layer4.1.conv2.weight: min=-0.173939, max=0.272456, mean=-0.000118\n",
            "Stored parameter layer4.1.bn2.weight: min=1.578233, max=2.409818, mean=1.853905\n",
            "Stored parameter layer4.1.bn2.bias: min=0.072876, max=0.651691, mean=0.273993\n",
            "Stored parameter fc.weight: min=-0.119346, max=0.112154, mean=-0.000759\n",
            "Stored parameter fc.bias: min=-0.051302, max=0.046741, mean=0.006642\n",
            "Stored output size for task 3: 40\n",
            "Consolidating weights based on importance...\n",
            "Consolidated parameter bn1.weight with weight factor 0.1891\n",
            "Consolidated parameter bn1.bias with weight factor 0.3027\n",
            "Consolidated parameter layer1.0.bn1.bias with weight factor 0.2288\n",
            "Sampling 20 examples from task 3 for memory buffer...\n",
            "Memory buffer size: 80 / 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 7/7 [00:07<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy for task 3 (on classes 0-39): 0.2575\n",
            "Model for task 3 saved as model_task_3.pth\n",
            "Training on task 4...\n",
            "Task 4: Training with 419 current samples and 80 replay samples.\n",
            "Froze 3 important parameters with importance > 0.129899\n",
            "Starting training for Task 4. Trainable parameters:\n",
            "  - conv1.weight\n",
            "  - bn1.weight\n",
            "  - bn1.bias\n",
            "  - layer1.0.conv1.weight\n",
            "  - layer1.0.bn1.weight\n",
            "  - layer1.0.bn1.bias\n",
            "  - layer1.0.conv2.weight\n",
            "  - layer1.0.bn2.weight\n",
            "  - layer1.0.bn2.bias\n",
            "  - layer1.1.conv1.weight\n",
            "  - layer1.1.bn1.weight\n",
            "  - layer1.1.bn1.bias\n",
            "  - layer1.1.conv2.weight\n",
            "  - layer1.1.bn2.weight\n",
            "  - layer1.1.bn2.bias\n",
            "  - layer2.0.conv1.weight\n",
            "  - layer2.0.bn1.weight\n",
            "  - layer2.0.bn1.bias\n",
            "  - layer2.0.conv2.weight\n",
            "  - layer2.0.bn2.weight\n",
            "  - layer2.0.bn2.bias\n",
            "  - layer2.0.downsample.0.weight\n",
            "  - layer2.0.downsample.1.weight\n",
            "  - layer2.0.downsample.1.bias\n",
            "  - layer2.1.conv1.weight\n",
            "  - layer2.1.bn1.weight\n",
            "  - layer2.1.bn1.bias\n",
            "  - layer2.1.conv2.weight\n",
            "  - layer2.1.bn2.weight\n",
            "  - layer2.1.bn2.bias\n",
            "  - layer3.0.conv1.weight\n",
            "  - layer3.0.bn1.weight\n",
            "  - layer3.0.bn1.bias\n",
            "  - layer3.0.conv2.weight\n",
            "  - layer3.0.bn2.weight\n",
            "  - layer3.0.bn2.bias\n",
            "  - layer3.0.downsample.0.weight\n",
            "  - layer3.0.downsample.1.weight\n",
            "  - layer3.0.downsample.1.bias\n",
            "  - layer3.1.conv1.weight\n",
            "  - layer3.1.bn1.weight\n",
            "  - layer3.1.bn1.bias\n",
            "  - layer3.1.conv2.weight\n",
            "  - layer3.1.bn2.weight\n",
            "  - layer3.1.bn2.bias\n",
            "  - layer4.0.conv1.weight\n",
            "  - layer4.0.bn1.weight\n",
            "  - layer4.0.bn1.bias\n",
            "  - layer4.0.conv2.weight\n",
            "  - layer4.0.bn2.weight\n",
            "  - layer4.0.bn2.bias\n",
            "  - layer4.0.downsample.0.weight\n",
            "  - layer4.0.downsample.1.weight\n",
            "  - layer4.0.downsample.1.bias\n",
            "  - layer4.1.conv1.weight\n",
            "  - layer4.1.bn1.weight\n",
            "  - layer4.1.bn1.bias\n",
            "  - layer4.1.conv2.weight\n",
            "  - layer4.1.bn2.weight\n",
            "  - layer4.1.bn2.bias\n",
            "  - fc.weight\n",
            "  - fc.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 1:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 1:  75%|███████▌  | 3/4 [00:03<00:00,  1.04batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00007209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 1: 100%|██████████| 4/4 [00:04<00:00,  1.03s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 1, EWC Loss: 4056.5673, Total Loss: 4060.6362, Val Loss (Cumulative): 3.4455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 2:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 2:  25%|██▌       | 1/4 [00:02<00:07,  2.53s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 2:  50%|█████     | 2/4 [00:03<00:02,  1.33s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 2:  75%|███████▌  | 3/4 [00:03<00:00,  1.06batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00005267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 2: 100%|██████████| 4/4 [00:03<00:00,  1.00batch/s]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 2, EWC Loss: 1467.5140, Total Loss: 1471.4928, Val Loss (Cumulative): 3.4294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 3:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00003304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 3:  25%|██▌       | 1/4 [00:02<00:08,  2.75s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 3:  50%|█████     | 2/4 [00:03<00:02,  1.41s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 3:  75%|███████▌  | 3/4 [00:03<00:00,  1.01batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 3: 100%|██████████| 4/4 [00:04<00:00,  1.06s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 3, EWC Loss: 707.5478, Total Loss: 711.4703, Val Loss (Cumulative): 3.4387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 4:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00002281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 4:  25%|██▌       | 1/4 [00:02<00:07,  2.59s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 4:  50%|█████     | 2/4 [00:03<00:02,  1.36s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 4:  75%|███████▌  | 3/4 [00:03<00:00,  1.03batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 4: 100%|██████████| 4/4 [00:04<00:00,  1.04s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 4, EWC Loss: 464.1192, Total Loss: 467.9869, Val Loss (Cumulative): 3.4336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 5:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00001119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 5:  25%|██▌       | 1/4 [00:02<00:07,  2.58s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 5:  50%|█████     | 2/4 [00:03<00:02,  1.35s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 5:  75%|███████▌  | 3/4 [00:03<00:00,  1.04batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 5: 100%|██████████| 4/4 [00:04<00:00,  1.02s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 5, EWC Loss: 280.7107, Total Loss: 284.4960, Val Loss (Cumulative): 3.4383\n",
            "Unfreezing backbone at epoch 5 for task 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 6:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 6:  25%|██▌       | 1/4 [00:02<00:07,  2.55s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 6:  50%|█████     | 2/4 [00:03<00:02,  1.34s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 6:  75%|███████▌  | 3/4 [00:03<00:00,  1.05batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 6: 100%|██████████| 4/4 [00:04<00:00,  1.01s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 6, EWC Loss: 162.0703, Total Loss: 165.7887, Val Loss (Cumulative): 3.4394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 7:   0%|          | 0/4 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 7:  25%|██▌       | 1/4 [00:03<00:09,  3.30s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 7:  50%|█████     | 2/4 [00:03<00:03,  1.65s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTask 4 Epoch 7:  75%|███████▌  | 3/4 [00:04<00:01,  1.12s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Average EWC penalty per parameter is very small: 0.00000264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Task 4 Epoch 7: 100%|██████████| 4/4 [00:04<00:00,  1.20s/batch]\n",
            "Validating: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4, Epoch 7, EWC Loss: 100.8631, Total Loss: 104.4964, Val Loss (Cumulative): 3.4405\n",
            "Early stopping triggered at epoch 7 for task 4. Best Val Loss: 3.4294\n",
            "Finished training task 4\n",
            "Storing parameters for task 4...\n",
            "Stored parameter layer4.0.conv1.weight: min=-0.264380, max=0.383059, mean=-0.001576\n",
            "Stored parameter layer4.0.bn1.weight: min=0.136654, max=0.428623, mean=0.264354\n",
            "Stored parameter layer4.0.bn1.bias: min=-0.477031, max=0.145676, mean=-0.225701\n",
            "Stored parameter layer4.0.conv2.weight: min=-0.282776, max=0.348375, mean=-0.001305\n",
            "Stored parameter layer4.0.bn2.weight: min=0.140046, max=0.732724, mean=0.424390\n",
            "Stored parameter layer4.0.bn2.bias: min=-0.400330, max=0.117106, mean=-0.197623\n",
            "Stored parameter layer4.0.downsample.0.weight: min=-0.628817, max=0.746461, mean=-0.000855\n",
            "Stored parameter layer4.0.downsample.1.weight: min=-0.053270, max=0.509679, mean=0.250608\n",
            "Stored parameter layer4.0.downsample.1.bias: min=-0.400330, max=0.117106, mean=-0.197623\n",
            "Stored parameter layer4.1.conv1.weight: min=-0.194920, max=0.265119, mean=-0.002261\n",
            "Stored parameter layer4.1.bn1.weight: min=0.097247, max=0.465721, mean=0.288570\n",
            "Stored parameter layer4.1.bn1.bias: min=-0.594490, max=0.053120, mean=-0.241736\n",
            "Stored parameter layer4.1.conv2.weight: min=-0.173925, max=0.272460, mean=-0.000118\n",
            "Stored parameter layer4.1.bn2.weight: min=1.578239, max=2.409793, mean=1.853904\n",
            "Stored parameter layer4.1.bn2.bias: min=0.072871, max=0.651680, mean=0.273992\n",
            "Stored parameter fc.weight: min=-0.119340, max=0.112178, mean=-0.000544\n",
            "Stored parameter fc.bias: min=-0.051299, max=0.046732, mean=0.007130\n",
            "Stored output size for task 4: 50\n",
            "Consolidating weights based on importance...\n",
            "Consolidated parameter bn1.weight with weight factor 0.2154\n",
            "Consolidated parameter bn1.bias with weight factor 0.3365\n",
            "Consolidated parameter layer1.0.bn1.bias with weight factor 0.2373\n",
            "Sampling 20 examples from task 4 for memory buffer...\n",
            "Memory buffer size: 100 / 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 8/8 [00:10<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy for task 4 (on classes 0-49): 0.1931\n",
            "Model for task 4 saved as model_task_4.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('replay-ewc-coarse-grained', 'zip', 'replay-ewc-coarse-grained')"
      ],
      "metadata": {
        "id": "z6gQ0keu9OCN",
        "outputId": "092ded74-8b19-4d46-afb2-489c1800b401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "z6gQ0keu9OCN",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/replay-ewc-coarse-grained.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Code"
      ],
      "metadata": {
        "id": "unSzyOy64w1G"
      },
      "id": "unSzyOy64w1G"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import ast # To safely evaluate the string list literal\n",
        "import os # To check if file exists\n",
        "\n",
        "def visualize_forgetting(accuracy_file_path, num_total_classes, num_classes_per_task):\n",
        "  # --- Data Loading and Manual Parsing ---\n",
        "  parsed_data = {}\n",
        "\n",
        "  # Check if the file exists before trying to read\n",
        "  if not os.path.exists(accuracy_file_path):\n",
        "      print(f\"Error: Accuracy file not found at '{accuracy_file_path}'\")\n",
        "      print(\"Please make sure you have saved the data into a file named 'accuracies.txt' in the correct directory.\")\n",
        "      exit()\n",
        "\n",
        "  try:\n",
        "      with open(accuracy_file_path, 'r') as f:\n",
        "          header = f.readline().strip() # Read and ignore the header line\n",
        "          if not header.startswith(\"Task,Overall Accuracy,Per-Class Accuracy\"):\n",
        "              print(\"Warning: Header doesn't exactly match expected format, but proceeding.\")\n",
        "\n",
        "          for line_num, line in enumerate(f, start=2): # Start line count from 2 for error messages\n",
        "              line = line.strip()\n",
        "              if not line: # Skip empty lines\n",
        "                  continue\n",
        "\n",
        "              try:\n",
        "                  # Find the first comma to isolate Task ID\n",
        "                  first_comma_idx = line.find(',')\n",
        "                  if first_comma_idx == -1:\n",
        "                      raise ValueError(\"Missing first comma separating Task ID\")\n",
        "                  task_id_str = line[:first_comma_idx]\n",
        "                  task_id = int(task_id_str)\n",
        "\n",
        "                  # Find the second comma to isolate Overall Accuracy (and the start of the list)\n",
        "                  # Start searching *after* the first comma\n",
        "                  second_comma_idx = line.find(',', first_comma_idx + 1)\n",
        "                  if second_comma_idx == -1:\n",
        "                      raise ValueError(\"Missing second comma separating Overall Accuracy\")\n",
        "\n",
        "                  # The rest of the line, starting after the second comma, is the list string\n",
        "                  list_str = line[second_comma_idx + 1:]\n",
        "\n",
        "                  # Safely evaluate the string list using ast.literal_eval\n",
        "                  per_class_acc_list = ast.literal_eval(list_str)\n",
        "\n",
        "                  # Validate that it's actually a list\n",
        "                  if not isinstance(per_class_acc_list, list):\n",
        "                      raise TypeError(f\"Parsed data for 'Per-Class Accuracy' is not a list (type: {type(per_class_acc_list)}).\")\n",
        "\n",
        "                  # Convert elements to float just in case\n",
        "                  per_class_acc_list = [float(acc) for acc in per_class_acc_list]\n",
        "                  parsed_data[task_id] = per_class_acc_list\n",
        "                  # print(f\"Parsed Task {task_id}, found {len(per_class_acc_list)} accuracies.\") # Optional print\n",
        "\n",
        "              except (ValueError, SyntaxError, TypeError, IndexError) as e:\n",
        "                  print(f\"Warning: Could not parse line {line_num}. Error: {e}. Line content: '{line}'\")\n",
        "              except Exception as e:\n",
        "                  # Catch any other unexpected errors during parsing of a specific line\n",
        "                  print(f\"An unexpected error occurred parsing line {line_num}: {e}\")\n",
        "\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      # This case is handled by the os.path.exists check above, but kept for safety\n",
        "      print(f\"Error: Accuracy file not found at '{accuracy_file_path}'\")\n",
        "      exit()\n",
        "  except Exception as e:\n",
        "      # Catch errors related to opening or reading the file itself\n",
        "      print(f\"Error reading file '{accuracy_file_path}': {e}\")\n",
        "      exit()\n",
        "\n",
        "  # --- Prepare Data Matrix for Heatmap (Code remains the same) ---\n",
        "  num_tasks_found = len(parsed_data)\n",
        "  if num_tasks_found == 0:\n",
        "      print(\"No valid task data parsed. Exiting.\")\n",
        "      exit()\n",
        "\n",
        "  # Create a matrix: rows = tasks, cols = classes\n",
        "  # Initialize with NaN for classes not yet seen/evaluated\n",
        "  acc_matrix = np.full((num_tasks_found, num_total_classes), np.nan)\n",
        "\n",
        "  sorted_task_ids = sorted(parsed_data.keys())\n",
        "\n",
        "  for task_idx, task_id in enumerate(sorted_task_ids):\n",
        "      accuracies = parsed_data[task_id]\n",
        "      num_classes_in_task_eval = len(accuracies)\n",
        "      if num_classes_in_task_eval > num_total_classes:\n",
        "          print(f\"Warning: Task {task_id} reported {num_classes_in_task_eval} accuracies, exceeding total classes {num_total_classes}. Truncating.\")\n",
        "          num_classes_in_task_eval = num_total_classes\n",
        "          accuracies = accuracies[:num_total_classes]\n",
        "\n",
        "      # Fill the matrix row for this task up to the number of classes evaluated\n",
        "      acc_matrix[task_idx, :num_classes_in_task_eval] = accuracies\n",
        "\n",
        "  # --- Plotting the Heatmap (Code remains the same) ---\n",
        "  plt.figure(figsize=(20, max(5, num_tasks_found * 0.7))) # Adjusted size\n",
        "\n",
        "  heatmap = sns.heatmap(\n",
        "      acc_matrix,\n",
        "      annot=False,\n",
        "      fmt=\".2f\",\n",
        "      cmap=\"viridis\",\n",
        "      linewidths=0.2,\n",
        "      linecolor='lightgrey',\n",
        "      cbar_kws={'label': 'Per-Class Accuracy'},\n",
        "      vmin=0.0,\n",
        "      vmax=1.0\n",
        "  )\n",
        "\n",
        "  plt.xlabel(\"Class ID\")\n",
        "  plt.ylabel(\"Evaluation Point (After Task X Completed)\")\n",
        "  plt.title(\"Per-Class Accuracy After Each Task\", fontsize=16)\n",
        "  plt.xticks(ticks=np.arange(0, num_total_classes, 5) + 0.5, labels=np.arange(0, num_total_classes, 5), rotation=90, fontsize=8)\n",
        "  plt.yticks(ticks=np.arange(num_tasks_found) + 0.5, labels=[f\"After Task {t}\" for t in sorted_task_ids], rotation=0)\n",
        "\n",
        "  for i in range(num_classes_per_task, num_total_classes, num_classes_per_task):\n",
        "      plt.axvline(x=i, color='white', linestyle='--', linewidth=1.0)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "r9Mnt_TlE0RS"
      },
      "id": "r9Mnt_TlE0RS",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# texture dataset\n",
        "accuracy_file_path = 'replay-ewc-coarse-grained/accuracies.txt' # Make sure this file exists\n",
        "num_total_classes = 50\n",
        "num_classes_per_task = 10\n",
        "\n",
        "visualize_forgetting(accuracy_file_path, num_total_classes, num_classes_per_task)"
      ],
      "metadata": {
        "id": "OXSaW29YzqTV",
        "outputId": "8f8884a0-8172-4b95-d10b-f9fa8718e8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "id": "OXSaW29YzqTV",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the aircraft families\n",
        "accuracy_file_path = 'accuracies.txt'\n",
        "num_total_classes = 50\n",
        "num_classes_per_task = 10\n",
        "\n",
        "visualize_forgetting(accuracy_file_path, num_total_classes, num_classes_per_task)"
      ],
      "metadata": {
        "id": "pS0ii61_0Qzj",
        "outputId": "1f12f72d-5ad9-4356-84de-616f85901a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "id": "pS0ii61_0Qzj",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Accuracy file not found at 'accuracies.txt'\n",
            "Please make sure you have saved the data into a file named 'accuracies.txt' in the correct directory.\n",
            "Error: Accuracy file not found at 'accuracies.txt'\n",
            "No valid task data parsed. Exiting.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seaborn/matrix.py:309: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  ax.set(xlim=(0, self.data.shape[1]), ylim=(0, self.data.shape[0]))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABugAAAHqCAYAAADmo8iEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdfxJREFUeJzs3Xd0VOXWx/HfJKTRSyAIBBIE6SX0JghEoyhdRJAuCFyaRKWJRrlSRC9FQbm0ACJSpFykCkhVBCH0KhAIAiG00Ekgc94/XJnXMQFnJpNkknw/a511meecs88+M2e4kZ39PCbDMAwBAAAAAAAAAAAASBNu6Z0AAAAAAAAAAAAAkJVQoAMAAAAAAAAAAADSEAU6AAAAAAAAAAAAIA1RoAMAAAAAAAAAAADSEAU6AAAAAAAAAAAAIA1RoAMAAAAAAAAAAADSEAU6AAAAAAAAAAAAIA1RoAMAAAAAAAAAAADSEAU6AAAAAAAAAAAAIA1RoAMAAHBRAQEBMplMVpuXl5eKFy+u9u3ba/v27emdYhLHjh1TaGiogoKCVKBAAXl4eKhAgQKqW7euhg8frmPHjlkdf/bsWZlMJgUEBKRPwqmoSpUqls/s2rVr6Z0O/kF8fLwKFiwok8mkwoUL69GjR088/sKFC+rcubOKFCmibNmyyWQyqVu3bmmTrIO2bNmS5O+Ux23p4aOPPpLJZNJHH32U4lj23OtfN2dc+0kS/14/e/Zsql4HAAAAgOvLlt4JAAAA4Mnq16+vUqVKSZJiY2O1Z88eLV68WEuWLNHnn3+u0NDQdM5QevTokd577z198cUXMpvNyp8/v2rWrKkCBQooNjZWe/fu1a+//qrx48dr8uTJ6t+/f3qnnKp+++03HTx4UNKfhZ/58+dr0KBB6ZwVnuR///ufrl69Kkm6fPmyVq9erZYtWyZ7rGEYatOmjXbv3q3y5curcePG8vDwUIMGDSTJUuAyDCNtkndA165d0zuFVFW4cOFk73H//v06cOCA/Pz89OKLLybZX7Vq1TTIDgAAAAAo0AEAALi8nj17WnXmPHjwQL1799a8efM0ZMgQvfLKK3rmmWfSL0FJnTp10qJFi5Q7d25NnjxZnTt3lru7u2W/YRjasGGDhg8frlOnTqVjpmlj1qxZkqSiRYvqwoULmjVrFgU6F5fcZ/a4At25c+e0e/duFS9eXAcOHFC2bBnvP6vmzJmT3imkqrJlyyZ7jx999JEOHDjw2P0AAAAAkFaY4hIAACCD8fb21tSpU5UjRw4lJCRo2bJl6ZrP7NmztWjRInl4eOjHH39Ut27drIpz0p8dRS+88IJ+/fVXtW/fPp0yTRv37t3Td999J0n65ptvlDNnTh06dEi//fZbOmeGxzl//rw2bNggd3d3LV68WCaTSWvWrNGlS5eSPT4qKkqSFBgYmCGLcwAAAACA9EeBDgAAIAPKmTOnypQpI0lJ1jI6efKkevfuraefflre3t7KkyePGjZsqPnz5ycb67nnnpPJZNKWLVu0fft2NW/eXAULFpSbm9s/dpgYhqHRo0dLkvr27avatWs/8XgPDw/VrVvXpnvcvXu3hgwZolq1aqlw4cLy9PSUn5+fmjdvro0bNz72vCVLlig4ONhqDbzy5curV69elmknE928eVMjR45UpUqVlCNHDnl5ealIkSKqX7++PvzwQz18+NCmXP9+/Vu3bqlixYpq3LixpSCZ2KH1ODdu3NCoUaNUo0YN5cmTRz4+PipZsqRee+01rV27Nsnxjx490uzZsxUcHCxfX195eXmpWLFiCg4O1pdffml17F8/4+Q8bu2vv45HRUXpzTfflL+/vzw8PKy6OpctW6aePXuqYsWKypcvn7y9vRUYGKgePXroxIkTT7zvn376Se3atVOxYsXk5eWlggULqmbNmgoLC7Os3RcWFiaTyaTevXs/Ns7u3btlMplUtGjRf1w/7u9mz54ts9msl156SfXq1VOTJk2UkJCguXPnWh2XuGZio0aNJElbt261Wr+sW7duVuu3/X19s/T8rqbEw4cPNX/+fL3xxhsqW7ascufOLR8fH5UpU0YDBw7UxYsXH3uuYRhatmyZXnnlFcv3uHDhwmrQoIE+/fRT3b9/P9nzrly5on79+snf31+enp7y9/fXgAEDFBsbm0p3KW3cuFEDBgxQ1apVrb5T7du3f2yB3Ww2a/r06apfv77y5s0rDw8PFSpUSFWqVNGAAQPsWmvuk08+kclkkr+/vw4dOuSkuwIAAADgqvh1TwAAgAzq1q1bkiQvLy/L2JIlS9SlSxc9ePBAZcuWVbNmzXTz5k3t2rVLnTt31k8//aTZs2cnG2/JkiWaNm2aypYtq+DgYF2/ft0qdnIOHTqkM2fOSHL+mlYjRozQ5s2bVaFCBVWvXl05cuTQ6dOntWrVKq1atUqTJk1KMm3kqFGjFBYWpmzZsqlevXoqWrSobt68qaioKM2aNUsVKlRQ5cqVJf3Z6dagQQMdPnxYBQsWVNOmTZUjRw5FR0fr+PHj+uWXXxQaGqq8efPalXdiIa5Hjx6W/501a5YWLlyoiRMnysfHJ8k5Bw4c0Msvv6wLFy4oT548atCggXLlyqWoqCitWrVKMTExeumllyzH37x5U6+88op27NghDw8P1atXT0WKFFF0dLQOHjyoTZs2acCAAXbl/SS///67goKC5Onpqfr168swDPn6+lr2v/baa/Ly8lL58uXVpEkTPXr0SIcPH1Z4eLgWL16sH3/8UfXq1UsSd+DAgZZiYtWqVfXss8/q5s2bOnHihEaNGqXGjRvrueeeU9++fTVu3Dh9++23+vTTT5P9TKZOnSpJ6t27t11dbYZhKDw8XJL1Z7Zp0yaFh4dr2LBhlmNz5syprl27Kjo6WuvXr0+yjtkrr7wiSZbC3t+/Ezlz5rT8Oa2/qylx+fJlde7cWXny5FG5cuVUuXJl3b17V/v379eXX36phQsX6pdffrGslZno4cOHev3117Vs2TK5ubmpVq1aatKkia5evaqjR49q2LBhat++vQICAqzOO3/+vKpVq6aHDx+qfv36evDggX7++WdNmTJFu3bt0s8//ywPDw+n32efPn10/vx5VahQQfXr11e2bNl0/PhxLV68WMuWLdPChQvVtm1bq3N69uyp8PBweXt7q0GDBipYsKCuX7+uM2fOaMqUKWratGmS+/u7hw8fqnfv3goPD1fVqlW1evVqFSlSxOn3BwAAAMDFGAAAAHBJJUqUMCQZ4eHhSfYdOHDAcHNzMyQZs2fPNgzDMA4ePGh4eXkZ3t7extKlS62OP3v2rFGpUiVDkjF37lyrfY0aNTIkGZKMqVOn2pXjrFmzDEmGp6en8fDhQ/tu0DCMyMhIQ5JRokSJJPvWrFljXLx4Mcn4L7/8YuTOndvw8PAw/vjjD8v4gwcPDB8fHyNnzpzG8ePHk5x39uxZ49ixY5bXc+fONSQZL730khEfH291bEJCgrFlyxYjLi7Orvs5ceKEIcnw8PAwYmJiLONly5Y1JBnz5s1Lcs6dO3cMf39/Q5LRpUsX4/bt21b7Y2NjjQ0bNliNtWnTxpBkBAUFGZGRkVb7Hj58aKxYscJqLPEz3rx5c7J5h4WFGZKMsLCwZMclGZ06dTIePHiQ7PkLFy407ty5YzVmNpuNqVOnGpKMChUqGGaz2Wr/F198YUgyChQoYPz0009JYu7atcuIioqyvH7jjTcMScaECROSHHvlyhXDy8vL8PDwMC5dupRsjo/z448/GpKMQoUKWZ6D+/fvG3nz5jUkGdu2bUtyzubNmw1JRqNGjZKNmfiePU56fFf/mre9/xl469Yt43//+1+S70N8fLwxfPhwQ5LRrFmzJOeFhoYakoyAgABj//79VvvMZrOxceNGIzY21jL21+etW7duVs9bVFSUUbRoUUOSsWDBArvy/6vEayT32S1fvty4fv16suPZsmUzChQoYNy7d88yfu7cOUOSUaxYsWSfu6NHjxrnzp2zGkv8ez3xexsbG2sEBwdb/i76+/cfAAAAQObFFJcAAAAZyM2bN7VmzRq1adNGZrNZRYoU0WuvvSZJGj16tOLi4vTJJ5+oTZs2VueVKFHC0tn1xRdfJBu7SZMm+te//mVXPleuXJEk5c+f3+lrcb300kt66qmnkozXrVtX/fr108OHD/W///3PMn7r1i3dv39fJUuWtEz/+VclSpRQ2bJlLa8vX74sSXr++eeTdOO4ubmpUaNG8vT0tCvnxI6nFi1aqGDBgpbxxM6s5Ka5nDlzps6fP6+qVatq9uzZVl1WkpQnTx4FBwdbXh84cEDLli2Tt7e3fvjhhyTdOdmyZVPLli3tyvuf5M+fX1OmTHlsl1b79u2VI0cOqzGTyaR//etfqlu3ro4cOaJjx45Z9j169Ej//ve/JUnTp09X48aNk8SsVauW/P39La8TuyW//vprGYZhdezMmTMVFxenV199VYULF7br3hI/k86dO1ueA29vb3Xs2NFqvzOlx3f17/4+/eZft1atWlkdmytXLrVo0SLJ98HDw0NjxoxRkSJFtG7dOt2+fduyLyYmRlOmTJEkff/996pSpUqS6zdt2lR58uRJkluxYsU0depUq+ctcYpLSU+c4jYlWrVqpXz58iU73q5dO127dk2bN2+2jCf+HVKtWrVkn7ty5cqpePHij71eVFSUGjRooI0bN6p379764Ycfknz/AQAAAGReTHEJAADg4rp3767u3bsnGX/66ae1dOlS5ciRQ2az2bJOWeKaZ39Xo0YN5cyZU/v27dODBw/k7e1ttf/VV191fvIpdO3aNa1evVqHDx/WjRs3LGvC/f7775Jktb5ZwYIFFRAQoIMHD+qdd97Rm2++qfLlyz82ds2aNSVJ48ePV4ECBfTKK68of/78Duf66NEjy9SGiQW5RF26dNGIESO0bds2nT59Wk8//bRl37p16yRJb775ptzd3f/xOonHv/zyyypatKjD+dojODg42ULKX506dUrr1q3TqVOndPv2bSUkJEj6/yLGiRMnLJ/H3r17deXKFfn6+qp169Y25VCzZk3VrVtXO3fu1Pr16y1TS5rNZk2bNk2S1L9/f7vu69q1a1qxYoWkpJ9Zjx499NVXX2nJkiX68ssvlStXLrtiP46rfFefNCVttWrVkh0/cOCANm3apMjISN29e1dms1nSn8++2WzWqVOnFBQUJEnavHmz4uPjVb16dVWvXt2u3Jo2bars2bMnGS9Xrpwk6cKFC3bFs8fFixe1evVqHT9+XDdv3rSsZ3jkyBFJfz7HzZo1kySVLVtWuXLl0po1azR69Gh17NhRgYGBNl0nIiJC/fv3V3R0tMaNG6ehQ4emzg0BAAAAcFkU6AAAAFxc/fr1LWs7eXp6qlChQqpTp45efPFFS9fatWvXLGvS/bXr6HGuXbuWpLiT3DpJ48aN0/Hjx5OMf/755/L19bV0iV2/fl0JCQk2FZhsNWPGDA0ePFh379597DGJ95xo3rx5evXVVzVhwgRNmDBB+fPnV+3atfX888+rc+fOVuumPffccxo6dKg+++wzde3aVSaTSaVLl1b9+vXVsmVLNW/eXG5utk84sXr1akVHR6to0aIKCQmx2ufn56dmzZpp5cqVmj17tkaPHm3Zd+7cOUmy6u57EnuPd4YnraGVkJCg/v3767///W+Szra/+utnlXgPZcqUkclksjmPgQMHaufOnZoyZYqlQLdq1SqdO3dOQUFBya5z9yTz589XXFycateunaSYW716dVWuXFkHDx7UwoUL1atXL7tiP05qfVftNWfOHJuPvXv3rjp37qzly5c/8bjkPmNHntPHdZ3lzp1bkvTgwQO7Y9ri448/1ujRoy2/CJCcv95jrly5FB4eru7du2vkyJEaOXKknnrqKcvfzx07dnxsR1z79u316NEjffLJJxTnAAAAgCyKAh0AAICL69mzp7p16/bEYxI7WaQnd8YkSm6qQh8fnyRj69at09atW5OMf/TRR/L19bV0xsTHx+vAgQOP7byx1969e9W7d2+5u7vr008/VfPmzVW8eHFlz55dJpNJ06dPV+/evZMUhJ599lmdPXtWq1ev1tatW/XLL79o/fr1Wrt2rcLCwrR8+XI1bdrUcvy4cePUp08f/fDDD9qxY4d+/vlnhYeHKzw8XDVr1tTmzZuTTN34OInTEj548ECNGjVKsj+x62fOnDkaNWqUU4uZKfXX5yc5yT0biSZPnqxp06apcOHCmjBhgurVqyc/Pz9L11fHjh313XffPbF4Z6tXX31V7777rtauXavIyEgFBgZq6tSpkuzvnpP+/zP7448/1KBBgyT7E6dwnTVrltMKdKn1XU1Nw4cP1/Lly1W2bFmNGzdONWvWlK+vr2XKy3r16mnnzp1O+Ywl2VUYd5Zly5bpo48+Us6cOTVlyhQ1adJERYoUkY+Pj0wmk0aMGKGxY8cmuce2bdsqODhYK1eu1Pbt2/Xzzz9r+fLlWr58uT788ENt2LBBlSpVSnK9rl27atasWZo4caJefPFFu7sMAQAAAGR8FOgAAAAyAV9fX/n4+Oj+/fuW7jZn2LJlyxP3V65cWYGBgYqMjNTcuXOdVqBbsmSJDMPQgAEDNGTIkCT7E6e4TI6Pj49effVVyzSAV65c0ciRIzV9+nT16NHD0tmTKCAgQAMGDLCsb/Xbb7+pU6dO+u233zR+/Hh9/PHH/5jvpUuXtGbNGkl/djz9/PPPjz324sWLWrdunV5++WVJf3YLHTt2TMePH7daa+5xEruLkutsfJzEQspf1wj7q7+/J/ZYvHixJOm///2vWrRokWR/cp9V4j2cPHlShmHY3EWXLVs29e3bVyNHjtRXX32lXr16acOGDcqfP786dOhgV96//fabDh06JOnP4umTpk3ctWuXjhw5ogoVKth1jeSk1nc1NSV+xosWLVLlypWT7H/SZ2zPc5qeEu9x9OjReuutt5Lsf9LfOXny5FHnzp3VuXNnSdL58+c1YMAA/e9//1P//v2T/SWHkSNHqnz58nrnnXfUpEkTrV69OtkiMQAAAIDMK+1/NREAAABO5+7urueff17S//9Dc1pI7CyRpK+//lq7d+9+4vGPHj3Sr7/++o9xr1+/LkkqUaJEkn0PHjzQ0qVLbc6xYMGCGj9+vCQpKipKN27ceOLxNWvW1L/+9S9J0v79+226xpw5c5SQkKDatWvLMIzHbonFxsTOLUmWqRpnz55tWbftSRKPX7NmjS5evGhTfolTJB47dizJvnv37mnz5s02xUnOkz6rI0eOJPse1qhRQ76+vrpy5YplDThb9e7dW97e3po9e7b+85//yDAMvfnmm3Z3lc2cOVPSn1MNPukze+211yRZf2b/xMPDQ5Is65f9VXp9V1PiSZ/x+vXrdfXq1STjTZo0kaenp/bu3auIiIhUzzGlnnSPMTEx2rBhg82x/P39LYX9J/0dEhoaqunTp+vOnTsKCQmx6xoAAAAAMj4KdAAAAJlEWFiYPD099d5772nu3LnJTlt4+PBhLVu2zKnX7dmzp1599VU9fPhQzz//vObOnZuk0GQYhn766SfVq1dPCxcu/MeY5cqVkyTNnTvXquvrwYMH+te//qXIyMgk55w7d04zZ85Msi6dJP3www+SpHz58lnWsVq+fLm2bduW5H16+PCh1q1bJyn5f6xPzuzZsyX985SFXbp0kfTnummJ0yf27NlTxYoV0759+9SrV68ka+7dunVLGzdutLyuWrWqWrZsqfv376tly5aKioqyOv7Ro0dauXKl1VhiZ97UqVOtOsXu3r2rt956S+fPn7fpPpOT+FlNnTrV6r28dOmSunTpkmyRKlu2bHr//fclSW+99Za2bduW5JjffvtNf/zxR5JxX19fdezYUdevX9f06dPl5uZmKaja6t69e5bn0NbPbP78+U9cm+yvihUrJunPAmVy0uu76qjEz/jLL7+0Gj9x4oT69OmT7DmFChVS3759JUnt2rXT4cOHrfYn/p1w8+bNVMjYfon3OH36dMXHx1vGb968qa5duyab5759+7Ro0SLdv38/yb7Ev3P+6e+QXr16af78+YqPj1fz5s3tLlgDAAAAyLiY4hIAACCTqFatmubPn69u3bqpW7dulinUChYsqOvXr+vQoUP6448/1L59e7Vp08ap116wYIEKFy6sqVOnqlu3bnrnnXdUs2ZN5c+fXzdv3lRERIQuXbokd3f3f1xPT5K6d++uyZMna9++fQoMDNSzzz4rd3d3bd++Xffv39egQYM0efJkq3Nu3LihXr166V//+peqVq2qwMBASX9OTbdv3z6ZTCZ99tlnlrXftm7dqsmTJ8vX11dBQUEqVKiQbt++rV9//VUxMTEqWrRostNr/t3WrVt16tQpeXl56fXXX3/isRUqVFC1atUUERGhefPm6Z133lHOnDm1cuVKNWvWTOHh4Vq+fLnq16+vnDlz6vz589q3b59q1aplNf1leHi4mjVrpl9//VWlS5dWvXr1VKRIEUVHR+vQoUO6cuWK1VpZr732miZNmqQ9e/aoQoUKatCggcxms/bs2SNPT0/16NHDUmS014gRI7Ru3TrNmDFDmzdvVrVq1XTr1i1t3bpVJUuWVOvWrbV8+fIk5w0aNEgnTpzQtGnT1KhRIwUFBalMmTK6deuWjh8/rjNnzmjz5s2WYtdfDRw40JLvyy+/rICAALtyXrJkiW7duqXChQvrhRdeeOKxISEh8vPz0+XLl7Vy5Uq1bdv2H+O3bdtWn3/+uYKDg9WkSRPlypVLkvTpp5+qQIEC6fpdTfRP38NRo0ZZpqkMCwvTq6++qg8++ECLFy9WhQoVFBMTo+3bt+vZZ59VkSJF9MsvvySJMX78eEVGRmrlypWqUqWKateurcDAQF29elVHjhzRhQsXFBkZqTx58qTGLdrl7bff1rx587RmzRqVLFlSderU0cOHD7V161Zlz5492e/IuXPn9Prrr8vHx0fVqlWTv7+/Hj16pEOHDunEiRPy9PS0dO8+SYcOHZQjRw699tprateunebMmaM33ngjtW4VAAAAgIuggw4AACATadeunY4cOaLBgwcrb968+vnnn7V06VIdPXpUpUqV0rhx4zR69GinX9fDw0NffvmlDh8+rEGDBqlYsWL69ddftXjxYv3yyy8qXry4RowYoWPHjtnU7ZQ3b17t2bNH//rXv5Q3b16tXbtWO3fu1AsvvKCIiAhVrVo1yTlPP/20Jk2apFdeeUWxsbFas2aNVq9erbt376pLly767bff9Oabb1qO79atm4YNG6ayZcvq6NGjWrJkiXbu3Cl/f3+NGTNGBw4cSLY49HeJUx82b95c+fLl+8fjEzuy/jplYlBQkA4dOqSRI0fK399fW7Zs0cqVKxUdHa0WLVpo+PDhVjHy5cunrVu36uuvv1bt2rW1f/9+ff/99zp58qSqVq2qqVOnWh3v4eGhDRs2qH///sqVK5d+/PFHHTx4UK1bt1ZERIT8/f3/Me/HqV27tvbs2aMWLVro7t27WrlypU6fPq0BAwZo586dlo7FvzOZTPr666+1du1atWzZUhcvXtTSpUv122+/ydfXVx9//HGy651JUpUqVVS4cGFJUv/+/e3OOfG979Spk6Vg+zjZsmWzrG9n6zSX//73vzVkyBDlzZtXK1as0KxZszRr1iyrbtD0+q4mmjt37hO3xCkfJalNmzbaunWrmjZtqkuXLmnlypWKiYnRRx99pLVr11qm9Pw7T09PrVixQgsWLFBwcLBOnjypJUuW6ODBgypZsqQ+++wzy+eY3gIDA7Vv3z698cYbcnd316pVq3TgwAF16NBB+/btS/Y7UqdOHY0bN06NGzfWxYsXtXLlSv34449yd3dXv379dPDgQcuUtP+kRYsWWr16tby8vNSlSxdNnz7d2bcIAAAAwMWYjL/+ai0AAAAAuLiNGzfq+eefV5kyZXTs2DGZTKb0TgkAAAAAALvQQQcAAAAgw0hISFBYWJgkKTQ0lOIcAAAAACBDooMOAAAAgMsLDw/Xtm3btGfPHh0+fFiVKlVSRESEsmVjWW0AAAAAQMZDBx0AAAAAl7d161bNmTNHf/zxh1q3bq1Vq1ZRnAMAAAAAZFgU6AAAAAC4vDlz5sgwDN24cUPLli1T8eLF0zslAAAAAEA62bZtm5o3b64iRYrIZDJpxYoV/3jOli1bVK1aNXl5ealUqVKaM2dOquf5JBToAAAAAAAAAAAAkGHcvXtXVapU0dSpU206PjIyUi+//LIaN26s/fv36+2331bPnj21fv36VM708ViDDgAAAAAAAAAAABmSyWTS8uXL1apVq8ceM3ToUK1evVqHDx+2jL3++uuKjY3VunXr0iDLpOigAwAAAAAAAAAAQLqKi4vTrVu3rLa4uDinxN65c6eCg4OtxkJCQrRz506nxHcEq6oDAAAAAAAAAADAZuboZ5wec+y0jvr444+txsLCwvTRRx+lOHZ0dLT8/Pysxvz8/HTr1i3dv39fPj4+Kb6GvSjQAQAAAAAAAAAAIF0NHz5coaGhVmNeXl7plE3qo0AHAAAAAAAAAAAAm5lldnpMLy+vVCvIFS5cWJcvX7Yau3z5snLnzp0u3XMSBToAAAAAAAAAAADYIcFwfoEuNQtWdevW1Zo1a6zGNmzYoLp166biVZ/MLd2uDAAAAAAAAAAAANjpzp072r9/v/bv3y9JioyM1P79+xUVFSXpz+kyu3TpYjm+T58+OnPmjIYMGaLjx4/rq6++0uLFizV48OD0SF8SHXQAAAAAAAAAAACwg1lGul5/z549aty4seV14tp1Xbt21Zw5c3Tp0iVLsU6SAgMDtXr1ag0ePFiTJ09WsWLFNHPmTIWEhKR57olMhmGk77sIAAAAAAAAAACADOP+pUCnx/R5KtLpMV0ZHXQAAAAAAAAAAACwmVnOX4Muq6FABwAAAAAAAAAAAJslMDljirmldwIAAAAAAAAAAABAVkIHHQAAAAAAAAAAAGxmFh10KUWBDgAAAAAAAAAAADZLoECXYkxxCQAAAAAAAAAAAKQhOugAAAAAAAAAAABgM6a4TDkKdAAAAAAAAAAAALBZgkGBLqWY4hIAAAAAAAAAAABIQ3TQAQAAAAAAAAAAwGbm9E4gE6CDDgAAAAAAAAAAAEhDdNABAAAAAAAAAADAZgliDbqUokAHAAAAAAAAAAAAmyVQn0sxprgEAAAAAAAAAAAA0hAddAAAAAAAAAAAALCZOb0TyAQo0AEAAAAAAAAAAMBmCTKldwoZHlNcAgAAAAAAAAAAAGmIDjoAAAAAAAAAAADYzGykdwYZHwU6AAAAAAAAAAAA2IwpLlOOKS4BAAAAAAAAAACANEQHHQAAAAAAAAAAAGxGB13K0UEHAAAAAAAAAAAApCE66AAAAAAAAAAAAGAzs0EHXUpRoAMAAAAAAAAAAIDNmOIy5ZjiEgAAAAAAAAAAAEhDdNABAAAAAAAAAADAZgn0f6UYBToAAAAAAAAAAADYjDXoUo4SJwAAAAAAAAAAAJCG6KADAAAAAAAAAACAzRJEB11KUaADAAAAAAAAAACAzRIMJmhMKd5BAAAAAAAAAAAAIA3RQQcAAAAAAAAAAACbmen/SjHeQQAAAAAAAAAAACAN0UEHAAAAAAAAAAAAmyXIlN4pZHgU6AAAAAAAAAAAAGCzBIMJGlOKdxAAAAAAAAAAAABIQ3TQAQAAAAAAAAAAwGZmprhMMQp0AAAAAAAAAAAAsFkCEzSmGO8gAAAAAAAAAAAAkIbooAMAAAAAAAAAAIDNEgz6v1KKAh0AAAAAAAAAAABsZmaCxhTjHQQAAAAAAAAAAADSEB10AAAAAAAAAAAAsFmCYUrvFDI8OugAAAAAAAAAAACANEQHHQAAAAAAAAAAAGyWQP9XilGgAwAAAAAAAAAAgM3MBgW6lOIdBAAAAAAAAAAAANIQHXQAAAAAAAAAAACwGVNcphwFOgAAAAAAAAAAANgswTCldwoZHiVOAAAAAAAAAAAAIA3RQQcAAAAAAAAAAACbmen/SjG7C3SRkZHavn27zp07p3v37qlgwYIKCgpS3bp15e3tnRo5AgAAAAAAAAAAwEUkGBToUsrmAt23336ryZMna8+ePfLz81ORIkXk4+Oj69ev6/Tp0/L29tYbb7yhoUOHqkSJEqmZMwAAAAAAAAAAAJBh2VSgCwoKkqenp7p166alS5fK39/fan9cXJx27typhQsXqkaNGvrqq6/Url27VEkYAAAAAAAAAAAA6ccsU3qnkOGZDMMw/umg9evXKyQkxKaA165d09mzZ1W9evUUJwcAAAAAAAAAAADXMvPks06P2fOZ7U6P6cps6qCztTgnSQUKFFCBAgUcTggAAAAAAAAAAACuizXoUs6mAt2tW7dsDpg7d26HkwEAAAAAAAAAAIBrSxAFupSyqUCXN29emUy2zSeakJCQooQAAAAAAAAAAACAzMymAt3mzZstfz579qyGDRumbt26qW7dupKknTt3au7cuRo7dmzqZAkAAAAAAAAAAACXYDZsa+rC45kMwzDsOaFp06bq2bOnOnToYDW+YMECTZ8+XVu2bHFmfgAAAAAAAAAAAHAhk48HOz3moLIbnR7Tldk9SejOnTtVo0aNJOM1atTQ7t27nZIUAAAAAAAAAAAAkFnZXaDz9/fXjBkzkozPnDlT/v7+TkkKAAAAAAAAAAAArslsuDl9y2psWoPuryZOnKi2bdtq7dq1ql27tiRp9+7d+v3337V06VKnJwgAAAAAAAAAAADXkSDWoEspu0uSzZo108mTJ9W8eXNdv35d169fV/PmzXXy5Ek1a9YsNXIEAAAAAAAAAAAAMg27O+ikP6e5HDNmjLNzAQAAAAAAAAAAgIvLilNSOptD7+D27dvVqVMn1atXTxcuXJAkffPNN9qxY4dTkwMAAAAAAAAAAAAyG7sLdEuXLlVISIh8fHwUERGhuLg4SdLNmzfpqgMAAAAAAAAAAMjkEmRy+pbV2F2g++STTzRt2jTNmDFDHh4elvH69esrIiLCqckBAAAAAAAAAADAtZgNN6dvWY3dd3zixAk1bNgwyXiePHkUGxvrjJwAAAAAAAAAAACATMvuAl3hwoV16tSpJOM7duxQyZIlnZIUAAAAAAAAAAAAXFOC4eb0zV5Tp05VQECAvL29Vbt2be3evfuJx0+aNEllypSRj4+P/P39NXjwYD148MDRtyDF7L7jXr16adCgQdq1a5dMJpMuXryob7/9Vu+++6769u2bGjkCAAAAAAAAAADARZhlcvpmj0WLFik0NFRhYWGKiIhQlSpVFBISopiYmGSPX7BggYYNG6awsDAdO3ZMs2bN0qJFizRixAhnvB0OyWbvCcOGDZPZbFbTpk117949NWzYUF5eXnr33Xc1YMCA1MgRAAAAAAAAAAAAkCRNmDBBvXr1Uvfu3SVJ06ZN0+rVqzV79mwNGzYsyfG//PKL6tevr44dO0qSAgIC1KFDB+3atStN8/4ruzvoTCaT3n//fV2/fl2HDx/Wr7/+qitXrujf//53auQHAAAAAAAAAAAAF5KeU1zGx8dr7969Cg4Otoy5ubkpODhYO3fuTPacevXqae/evZZpMM+cOaM1a9aoWbNmKXsjUsDuDroePXpo8uTJypUrl8qXL28Zv3v3rgYMGKDZs2c7NUEAAAAAAAAAAAC4DrNh35SUtoiLi1NcXJzVmJeXl7y8vKzGrl69qoSEBPn5+VmN+/n56fjx48nG7tixo65evaoGDRrIMAw9evRIffr0SdcpLu3uoJs7d67u37+fZPz+/fuaN2+eU5ICAAAAAAAAAABA1jF27FjlyZPHahs7dqxTYm/ZskVjxozRV199pYiICC1btkyrV69O19khbe6gu3XrlgzDkGEYun37try9vS37EhIStGbNGhUqVChVkgQAAAAAAAAAAIBrSLC//+sffTh8uEJDQ63G/t49J0m+vr5yd3fX5cuXrcYvX76swoULJxv7gw8+UOfOndWzZ09JUqVKlXT37l299dZbev/99+Xm5vz7+Sc2F+jy5s0rk8kkk8mkZ555Jsl+k8mkjz/+2KnJAQAAAAAAAAAAIPNLbjrL5Hh6eqp69eratGmTWrVqJUkym83atGmT+vfvn+w59+7dS1KEc3d3lyQZhpGyxB1kc4Fu8+bNMgxDTZo00dKlS5U/f37LPk9PT5UoUUJFihRJlSQBAAAAAAAAAADgGlJjDTp7hIaGqmvXrqpRo4Zq1aqlSZMm6e7du+revbskqUuXLipatKhliszmzZtrwoQJCgoKUu3atXXq1Cl98MEHat68uaVQl9ZsLtA1atRIkhQZGanixYvLZErfNx8AAAAAAAAAAABpz5wKU1zao3379rpy5Yo+/PBDRUdHq2rVqlq3bp38/PwkSVFRUVYdcyNHjpTJZNLIkSN14cIFFSxYUM2bN9fo0aPT6xZkMhzo3du+fbv++9//6syZM1qyZImKFi2qb775RoGBgWrQoEFq5AkAAAAAAAAAAAAX8O6B9k6P+XmVRU6P6crsLnEuXbpUISEh8vHxUUREhOLi4iRJN2/e1JgxY5yeIAAAAAAAAAAAAFxHgmFy+pbV2F2g++STTzRt2jTNmDFDHh4elvH69esrIiLCqckBAAAAAAAAAADAtZgNk9O3rMbuAt2JEyfUsGHDJON58uRRbGysM3ICAAAAAAAAAAAAMq1s9p5QuHBhnTp1SgEBAVbjO3bsUMmSJZ2VFwAAAAAAAAAAAFyQ2bC7/wt/Y/c72KtXLw0aNEi7du2SyWTSxYsX9e233+rdd99V3759UyNHAAAAAAAAAAAAuIgEmZy+ZTV2d9ANGzZMZrNZTZs21b1799SwYUN5eXnp3Xff1YABA1IjRwAAAAAAAAAAACDTMBmGYThyYnx8vE6dOqU7d+6ofPnyypkzp7NzAwAAAAAAAAAAgIvps7ez02NOq/6N02O6Mrs76BJ5enqqfPnyzswFAAAAAAAAAAAAyPRsKtC1adPG5oDLli1zOBkAAAAAAAAAAAC4NrPhlt4pZHg2Fejy5MmT2nkAAAAAAAAAAAAgAzDLlN4pZHg2FejCw8NTOw8AAAAAAAAAAAAgS3B4DbqYmBidOHFCklSmTBkVKlTIaUkBAAAAAAAAAADANSUYdNCllN0Fulu3bqlfv35auHChEhISJEnu7u5q3769pk6dynSYAAAAAAAAAAAAmRhr0KWc3e9gr169tGvXLq1atUqxsbGKjY3VqlWrtGfPHvXu3Ts1cgQAAAAAAAAAAAAyDbs76FatWqX169erQYMGlrGQkBDNmDFDL774olOTAwAAAAAAAAAAgGsxM8VlitldoCtQoECy01jmyZNH+fLlc0pSAAAAAAAAAAAAcE1mUaBLKbunuBw5cqRCQ0MVHR1tGYuOjtZ7772nDz74wKnJAQAAAAAAAAAAAJmNyTAMw54TgoKCdOrUKcXFxal48eKSpKioKHl5eal06dJWx0ZERDgvUwAAAAAAAAAAAKS7Dr++5fSY39WZ7vSYrszuKS5btWqVCmkAAAAAAAAAAAAAWYPdBbqwsLDUyAMAAAAAAAAAAAAZgNmwewU1/I3dBbq/unPnjsxms9VY7ty5U5QQAAAAAAAAAAAAXJfZMKV3Chme3SXOyMhIvfzyy8qRI4fy5MmjfPnyKV++fMqbN6/y5cuXGjkCAAAAAAAAAAAAmYbdHXSdOnWSYRiaPXu2/Pz8ZDJRJQUAAAAAAAAAAMgqzKI2lFJ2F+gOHDigvXv3qkyZMqmRDwAAAAAAAAAAAFwYU1ymnN1TXNasWVPnz59PjVwAAAAAAAAAAACATM/uDrqZM2eqT58+unDhgipWrCgPDw+r/ZUrV3ZacgAAAAAAAAAAAHAtdNClnN0FuitXruj06dPq3r27ZcxkMskwDJlMJiUkJDg1QQAAAAAAAAAAALgOCnQpZ3eBrkePHgoKCtJ3330nPz8/mUx8CAAAAAAAAAAAAICt7C7QnTt3TitXrlSpUqVSIx8AAAAAAAAAAAC4MDroUs7N3hOaNGmiAwcOpEYuAAAAAAAAAAAAQKZndwdd8+bNNXjwYB06dEiVKlWSh4eH1f4WLVo4LTkAAAAAAAAAAAC4FrPooEspk2EYhj0nuLk9vunOZDIpISEhxUkBAAAAAAAAAADANYVsfdvpMdc3muT0mK7M7g46s9mcGnkAAAAAAAAAAAAAWYLdBToAAAAAAAAAAABkXWaDKS5T6vHzVT7B1q1b1bx5c5UqVUqlSpVSixYttH37dmfnBgAAAAAAAAAAABdjNkxO37Iauwt08+fPV3BwsLJnz66BAwdq4MCB8vHxUdOmTbVgwYLUyBEAAAAAAAAAAADINEyGYRj2nFCuXDm99dZbGjx4sNX4hAkTNGPGDB07dsypCQIAAAAAAAAAAMB1NP7pHafH3NzkP06P6crs7qA7c+aMmjdvnmS8RYsWioyMdEpSAAAAAAAAAAAAcE2GYXL6ltXYXaDz9/fXpk2bkoxv3LhR/v7+TkkKAAAAAAAAAAAAyKyy2XvCO++8o4EDB2r//v2qV6+eJOnnn3/WnDlzNHnyZKcnCAAAAAAAAAAAANdhVtbreHM2uwt0ffv2VeHChfWf//xHixcvlvTnunSLFi1Sy5YtnZ4gAAAAAAAAAAAAkJnYXaCTpNatW6t169bOzgUAAAAAAAAAAAAuzpwF14xzNpvXoLtx44a+/PJL3bp1K8m+mzdvPnYfAAAAAAAAAAAAMg/DMDl9y2psLtBNmTJF27ZtU+7cuZPsy5Mnj7Zv364vv/zSqckBAAAAAAAAAAAAmY3NBbqlS5eqT58+j93fu3dvff/9905JCgAAAAAAAAAAAK7JbJicvmU1Nq9Bd/r0aZUuXfqx+0uXLq3Tp087JSkAAAAAAAAAAAC4pqw4JaWz2dxB5+7urosXLz52/8WLF+XmZnM4AAAAAAAAAAAAIEuyuaIWFBSkFStWPHb/8uXLFRQU5IycAAAAAAAAAAAA4KKY4jLlbJ7isn///nr99ddVrFgx9e3bV+7u7pKkhIQEffXVV5o4caIWLFiQaokCAAAAAAAAAAAg/RlGemeQ8dlcoGvbtq2GDBmigQMH6v3331fJkiUlSWfOnNGdO3f03nvv6dVXX021RAEAAAAAAAAAAIDMwGQY9tU5d+/erW+//VanTp2SYRh65pln1LFjR9WqVSu1cgQAAAAAAAAAAICLqL72fafH3PvSaKfHdGU2d9AlqlWrFsU4AAAAAAAAAAAAZAkBAQHq0aOHunXrpuLFizslpptTogAAAAAAAAAAACBLMAyT0zdX9vbbb2vZsmUqWbKknn/+eS1cuFBxcXEpikmBDgAAAAAAAAAAADYzGyanb67s7bff1v79+7V7926VK1dOAwYM0FNPPaX+/fsrIiLCoZgU6AAAAAAAAAAAAIB/UK1aNX3xxRe6ePGiwsLCNHPmTNWsWVNVq1bV7NmzZRiGzbHsXoMOAAAAAAAAAAAAWZcddahM5eHDh1q+fLnCw8O1YcMG1alTR2+++ab++OMPjRgxQhs3btSCBQtsimVzge7o0aMqX778E4+ZP3++OnXqZGtIAAAAAAAAAAAAZDCuvmacs0VERCg8PFzfffed3Nzc1KVLF02cOFFly5a1HNO6dWvVrFnT5pg2T3FZvXp1ff7558m2512+fFktWrRQ3759bb4wAAAAAAAAAAAA4Opq1qyp33//XV9//bUuXLigzz//3Ko4J0mBgYF6/fXXbY5pc4Fu/vz5Gj9+vBo2bKjTp09bjZcvX16xsbHat2+fzRcGAAAAAAAAAABAxmMYJqdvruzMmTNat26d2rVrJw8Pj2SPyZEjh8LDw22OaXOBrm3btjp8+LB8fX1VpUoVff7552rZsqXeeustvf/++9q6datKlSpl84UBAAAAAAAAAACQ8ZgNk9M3VxYTE6Ndu3YlGd+1a5f27NnjUEybC3SSVKhQIS1fvlwtW7bUkCFD9NNPP2nXrl0KDQ2VyeTabx4AAAAAAAAAAABgr379+un8+fNJxi9cuKB+/fo5FNOuAt2NGzfUsWNHrVixQsOGDVOhQoXUoUMHRUREOHRxAAAAAAAAAAAAZCyG4fzNlR09elTVqlVLMh4UFKSjR486FNPmAt2qVatUvnx5nT59Wnv37tWYMWN08OBBPfvss6pbt64++OADPXr0yKEkAAAAAAAAAAAAAFfk5eWly5cvJxm/dOmSsmXL5lBMu9agGzBggHbu3KmyZctK+nPBu6+//lqrVq3SvHnzVKNGDYeSAAAAAAAAAAAAQMZgGCanb67shRde0PDhw3Xz5k3LWGxsrEaMGKHnn3/eoZg2l/V+++03Va5cOdl9zz//vA4dOqTBgwc7lAQAAAAAAAAAAAAyBlcvqDnb559/roYNG6pEiRIKCgqSJO3fv19+fn765ptvHIppMgxXn9kTAAAAAAAAAAAArqLsslFOj3m8zYdOj+lMd+/e1bfffqsDBw7Ix8dHlStXVocOHeTh4eFQPMcmxgQAAAAAAAAAAECWlBU7v3LkyKG33nrLafEo0AEAAAAAAAAAAMBmWW2Ky0RHjx5VVFSU4uPjrcZbtGhhdywKdAAAAAAAAAAAAMBjnDlzRq1bt9ahQ4dkMpmUuHqcyfRnoTIhIcHumG7OTJDl7AAAAAAAAAAAADI5IxU2FzZo0CAFBgYqJiZG2bNn15EjR7Rt2zbVqFFDW7ZscSim3QW6zz77LNnxhIQEdezY0aEkAAAAAAAAAAAAkDEYhsnpm72mTp2qgIAAeXt7q3bt2tq9e/cTj4+NjVW/fv301FNPycvLS88884zWrFlj07V27typUaNGydfXV25ubnJzc1ODBg00duxYDRw40O7cJQcLdLNmzbIaS0hI0Ouvv679+/c7lAQAAAAAAAAAAABgi0WLFik0NFRhYWGKiIhQlSpVFBISopiYmGSPj4+P1/PPP6+zZ8/q+++/14kTJzRjxgwVLVrUpuslJCQoV65ckiRfX19dvHhRklSiRAmdOHHCoXuwew261atX64UXXlCePHn06quv6tGjR3rttdd0/Phxbd682aEkAAAAAAAAAAAAkDGk94pnEyZMUK9evdS9e3dJ0rRp07R69WrNnj1bw4YNS3L87Nmzdf36df3yyy/y8PCQJAUEBNh8vYoVK+rAgQMKDAxU7dq1NX78eHl6emr69OkqWbKkQ/dgdwddzZo1tXTpUvXo0UMrV65U27ZtdeLECW3evFmFCxd2KAkAAAAAAAAAAABkXXFxcbp165bVFhcXl+S4+Ph47d27V8HBwZYxNzc3BQcHa+fOncnGXrlyperWrat+/frJz89PFStW1JgxY5SQkGBTbiNHjpTZbJYkjRo1SpGRkXr22We1Zs0affHFFw7crQMFOklq0qSJ5s2bp7Zt2yoyMlJbt26Vn5+fQwkAAAAAAAAAAAAg40iNNejGjh2rPHnyWG1jx45Ncu2rV68qISEhSV3Kz89P0dHRyeZ75swZff/990pISNCaNWv0wQcf6D//+Y8++eQTm+43JCREbdq0kSSVKlVKx48f19WrVxUTE6MmTZrY+e79yaYpLhMv+ncFCxZU3rx59dZbb1nGli1b5lAiAAAAAAAAAAAAyAAMk9NDDh8+XKGhoVZjXl5eToltNptVqFAhTZ8+Xe7u7qpevbouXLigzz77TGFhYU889+HDh/Lx8dH+/ftVsWJFy3j+/PlTlJNNBbo8efIkOx4SEpKiiwMAAAAAAAAAAABeXl42FeR8fX3l7u6uy5cvW41fvnz5sUuxPfXUU/Lw8JC7u7tlrFy5coqOjlZ8fLw8PT0fez0PDw8VL17c5ukwbWVTgS48PNypFwUAAAAAAAAAAEDGZBjpd21PT09Vr15dmzZtUqtWrST92SG3adMm9e/fP9lz6tevrwULFshsNsvN7c/V306ePKmnnnrqicW5RO+//75GjBihb775JsWdc4lsKtD91f3792UYhrJnzy5JOnfunJYvX67y5cvrhRdecEpSAAAAAAAAAAAAcFHpWKCTpNDQUHXt2lU1atRQrVq1NGnSJN29e1fdu3eXJHXp0kVFixa1rGHXt29fTZkyRYMGDdKAAQP0+++/a8yYMRo4cKBN15syZYpOnTqlIkWKqESJEsqRI4fV/oiICLvvwe4CXcuWLdWmTRv16dNHsbGxqlWrljw9PXX16lVNmDBBffv2tTsJAAAAAAAAAAAAwBbt27fXlStX9OGHHyo6OlpVq1bVunXr5OfnJ0mKioqydMpJkr+/v9avX6/BgwercuXKKlq0qAYNGqShQ4fadL3ETj1nMhmGfY2Ivr6+2rp1qypUqKCZM2fqyy+/1L59+7R06VJ9+OGHOnbsmNOTBAAAAAAAAAAAgGsI/Has02NGvjHc6TFdmd0ddPfu3VOuXLkkST/++KPatGkjNzc31alTR+fOnXN6ggAAAAAAAAAAAHAh6TzFZWbg9s+HWCtVqpRWrFih8+fPa/369ZZ152JiYpQ7d26nJwgAAAAAAAAAAACkFzc3N7m7uz92c4TdHXQffvihOnbsqMGDB6tp06aqW7eupD+76YKCghxKAgAAAAAAAAAAABmDYZjSO4U0tXz5cqvXDx8+1L59+zR37lx9/PHHDsW0ew06SYqOjtalS5dUpUoVyyJ7u3fvVu7cuVW2bFmHEgEAAAAAAAAAAIDrC/hmnNNjnu08zOkxU9uCBQu0aNEi/e9//7P7XIcKdAAAAAAAAAAAAMiaAualQoGuS8Yr0J05c0aVK1fWnTt37D7X7ikuJWnPnj1avHixoqKiFB8fb7Vv2bJljoQEAAAAAAAAAABAhpC1prhMzv379/XFF1+oaNGiDp1vd4Fu4cKF6tKli0JCQvTjjz/qhRde0MmTJ3X58mW1bt3aoSQAAAAAAAAAAAAAV5QvXz6ZTP9flDQMQ7dv31b27Nk1f/58h2LaXaAbM2aMJk6cqH79+ilXrlyaPHmyAgMD1bt3bz311FMOJQEAAAAAAAAAAIAMIostnjZx4kSrAp2bm5sKFiyo2rVrK1++fA7FtHsNuhw5cujIkSMKCAhQgQIFtGXLFlWqVEnHjh1TkyZNdOnSJYcSAQAAAAAAAAAAgOsLmPOp02Oe7TbU6TFdmZu9J+TLl0+3b9+WJBUtWlSHDx+WJMXGxurevXvOzQ4AAAAAAAAAAABIR+Hh4VqyZEmS8SVLlmju3LkOxbS5QNejRw/dvn1bDRs21IYNGyRJ7dq106BBg9SrVy916NBBTZs2dSgJAAAAAAAAAAAAZBCGyfmbCxs7dqx8fX2TjBcqVEhjxoxxKKbNU1y6u7vr0qVLypYtmx48eKAiRYrIbDZr/Pjx+uWXX1S6dGmNHDnS4bk2AQAAAAAAAAAA4PpKzB7v9Jjnegxxekxn8fb21vHjxxUQEGA1fvbsWZUrV07379+3O2Y2Ww9MrOPlz5/fMubm5qZhw4bZfVEAAAAAAAAAAAAgIyhUqJAOHjyYpEB34MABFShQwKGYNhfoJOn27dvy9vZ+4jG5c+d2KBEAAAAAAAAAAABkADbNzZh5dOjQQQMHDlSuXLnUsGFDSdLWrVs1aNAgvf766w7FtKtA98wzzzx2n2EYMplMSkhIcCgRAAAAAAAAAAAAwNX8+9//1tmzZ9W0aVNly/Znac1sNqtLly4Or0FnV4Hu+++/t5riEgAAAAAAAAAAAFmMYUrvDNKUp6enFi1apE8++UT79++Xj4+PKlWqpBIlSjgc064CXf369VWoUCGHLwYAAAAAAAAAAICMzZTFprhMVLp0aZUuXdopsdycEgUAAAAAAAAAAADIhNq2batPP/00yfj48ePVrl07h2LaXKArUaKE3N3dHboIAAAAAAAAAAAAMgkjFTYXtm3bNjVr1izJ+EsvvaRt27Y5FNPmKS4jIyMdugAAAAAAAAAAAAAykSy2Bt2dO3fk6emZZNzDw0O3bt1yKCZTXAIAAAAAAAAAAACPUalSJS1atCjJ+MKFC1W+fHmHYtrcQQcAAAAAAAAAAAC4+pSUzvbBBx+oTZs2On36tJo0aSJJ2rRpk7777jstWbLEoZgU6AAAAAAAAAAAAGC7LFaga968uVasWKExY8bo+++/l4+PjypXrqyNGzeqUaNGDsW0a4rLhw8fqmnTpvr9998duhgAAAAAAAAAAACQ0bz88sv6+eefdffuXV29elU//fSTGjVqpMOHDzsUz64CnYeHhw4ePOjQhQAAAAAAAAAAAJAJGKmwZSC3b9/W9OnTVatWLVWpUsWhGHYV6CSpU6dOmjVrlkMXAwAAAAAAAAAAADKibdu2qUuXLnrqqaf0+eefq0mTJvr1118dimX3GnSPHj3S7NmztXHjRlWvXl05cuSw2j9hwgSHEgEAAAAAAAAAAEAGYJjSO4M0Ex0drTlz5mjWrFm6deuWXnvtNcXFxWnFihUqX768w3HtLtAdPnxY1apVkySdPHnSap/JlHU+EAAAAAAAAAAAgKzIlMGmpHRU8+bNtW3bNr388suaNGmSXnzxRbm7u2vatGkpjm13gW7z5s0pvigAAAAAAAAAAADgytauXauBAweqb9++Kl26tFNj270GXaJTp05p/fr1un//viTJMLJIuRQAAAAAAAAAACArM1Jhc0E7duzQ7du3Vb16ddWuXVtTpkzR1atXnRLb7gLdtWvX1LRpUz3zzDNq1qyZLl26JEl688039c477zglKQAAAAAAAAAAACA91alTRzNmzNClS5fUu3dvLVy4UEWKFJHZbNaGDRt0+/Zth2PbXaAbPHiwPDw8FBUVpezZs1vG27dvr3Xr1jmcCAAAAAAAAAAAAOBqcuTIoR49emjHjh06dOiQ3nnnHY0bN06FChVSixYtHIppd4Huxx9/1KeffqpixYpZjZcuXVrnzp1zKAkAAAAAAAAAAABkDCbD+VtGUaZMGY0fP15//PGHvvvuO4fjZLP3hLt371p1ziW6fv26vLy8HE4EAAAAAAAAAAAAGYBhSu8M0p27u7tatWqlVq1aOXS+3R10zz77rObNm2d5bTKZZDabNX78eDVu3NihJAAAAAAAAAAAAICswu4OuvHjx6tp06bas2eP4uPjNWTIEB05ckTXr1/Xzz//nBo5AgAAAAAAAAAAwFVkoCkpXZXdHXQVK1bUyZMn1aBBA7Vs2VJ3795VmzZttG/fPj399NOpkSMAAAAAAAAAAACQadjdQRcVFSV/f3+9//77ye4rXry4UxIDAAAAAAAAAACAC6KDLsXs7qALDAzUlStXkoxfu3ZNgYGBTkkKAAAAAAAAAAAArslkOH9zZXPnztXq1astr4cMGaK8efOqXr16OnfunEMx7S7QGYYhk8mUZPzOnTvy9vZ2KAkAAAAAAAAAAADAFY0ZM0Y+Pj6SpJ07d2rq1KkaP368fH19NXjwYIdi2jzFZWhoqCTJZDLpgw8+UPbs2S37EhIStGvXLlWtWtWhJAAAAAAAAAAAAJBBuHjHm7OdP39epUqVkiStWLFCbdu21VtvvaX69evrueeecyimzQW6ffv2Sfqzg+7QoUPy9PS07PP09FSVKlX07rvvOpQEAAAAAAAAAAAAMogsVqDLmTOnrl27puLFi+vHH3+0NLV5e3vr/v37DsW0qUD3xRdfaM2aNfLx8VH37t01efJk5c6d26ELAgAAAAAAAAAAABnF888/r549eyooKEgnT55Us2bNJElHjhxRQECAQzFtWoMuNDRUt2/fliTNmzdPDx48cOhiAAAAAAAAAAAAyNhMhvM3VzZ16lTVrVtXV65c0dKlS1WgQAFJ0t69e9WhQweHYtrUQVekSBEtXbpUzZo1k2EY+uOPPx5bpCtevLhDiQAAAAAAAAAAACADMEzpnUGayps3r6ZMmZJk/OOPP3Y4pk0ddCNHjtTbb7+tkiVLymQyqWbNmgoMDLTaAgICFBgY6HAiAAAAAAAAAAAAgKtZt26dduzYYXk9depUVa1aVR07dtSNGzccimkyDMOmxsHbt2/r3Llzqly5sjZu3Ghp3/u7KlWqOJQIAAAAAAAAAAAAXF+pTyc6PeapoYOdHtNZKlWqpE8//VTNmjXToUOHVLNmTYWGhmrz5s0qW7aswsPD7Y5p0xSXkpQrVy5VrFhR4eHhql+/vry8vKz2x8bGav78+RToAAAAAAAAAAAAkGlERkaqfPnykqSlS5fqlVde0ZgxYxQREaFmzZo5FNOmKS7/qmvXrlbFuU2bNqljx4566qmnFBYW5lASAAAAAAAAAAAAyBhMhvM3V+bp6al79+5JkjZu3KgXXnhBkpQ/f37dunXLoZh2F+gk6fz58xo1apQCAwP1wgsvyGQyafny5YqOjnYoCQAAAAAAAAAAAGQQRipsLqxBgwYKDQ3Vv//9b+3evVsvv/yyJOnkyZMqVqyYQzFtLtA9fPhQS5YsUUhIiMqUKaP9+/frs88+k5ubm95//329+OKL8vDwcCgJAAAAAAAAAAAAwBVNmTJF2bJl0/fff6+vv/5aRYsWlSStXbtWL774okMxTYZh2FSXLFSokMqWLatOnTqpXbt2ypcvnyTJw8NDBw4csMy9CQAAAAAAAAAAgMzrmTETnR7z5IjBTo/pyrLZeuCjR49kMplkMpnk7u6emjkBAAAAAAAAAADAVbn4lJSp6cGDB4qPj7cay507t91xbJ7i8uLFi3rrrbf03XffqXDhwmrbtq2WL18uk8lk90UBAAAAAAAAAACAjODu3bvq37+/ChUqpBw5cihfvnxWmyNsLtB5e3vrjTfe0E8//aRDhw6pXLlyGjhwoB49eqTRo0drw4YNSkhIcCgJAAAAAAAAAAAAZBBGKmwubMiQIfrpp5/09ddfy8vLSzNnztTHH3+sIkWKaN68eQ7FtHkNuuSYzWatX79es2bN0g8//KBcuXLp6tWrjoYDAAAAAAAAAACAiyvzb+evQXfiA9ddg6548eKaN2+ennvuOeXOnVsREREqVaqUvvnmG3333Xdas2aN3TFtXoMuOW5ubnrppZf00ksv6cqVK/rmm29SEg4AAAAAAAAAAABwKdevX1fJkiUl/bne3PXr1yVJDRo0UN++fR2KadMUl7Y02RUsWFChoaEOJQEAAAAAAAAAAAC4opIlSyoyMlKSVLZsWS1evFiS9MMPPyhv3rwOxbSpQFehQgUtXLhQ8fHxTzzu999/V9++fTVu3DiHkgEAAAAAAAAAAABcSffu3XXgwAFJ0rBhwzR16lR5e3tr8ODBeu+99xyKadMadJs2bdLQoUN15swZPf/886pRo4aKFCkib29v3bhxQ0ePHtWOHTt05MgR9e/fXyNGjFCePHkcSggAAAAAAAAAAACuq8yoVFiD7kPXXYPu786dO6e9e/eqVKlSqly5skMxbCrQJdqxY4cWLVqk7du369y5c7p//758fX0VFBSkkJAQvfHGG8qXL59DiQAAAAAAAAAAAMD1lf3Y+QW642EZp0DnDNnsObhBgwZq0KBBauUCAAAAAAAAAAAApLsvvvjC5mMHDhxod3y7CnQAAAAAAAAAAADI4myemzHjmjjRti5Bk8lEgQ4AAAAAAAAAAACpLAsU6CIjI1M1vluqRgcAAAAAAAAAAAAyqFu3bslsNicZN5vNunXrlsNxKdABAAAAAAAAAADAZibD+ZsrWr58uWrUqKEHDx4k2Xf//n3VrFlTP/zwg0OxKdABAAAAAAAAAADAdkYqbC7o66+/1pAhQ5Q9e/Yk+3LkyKGhQ4dqypQpDsW2u0Dn7u6umJiYJOPXrl2Tu7u7Q0kAAAAAAAAAAAAAruTw4cN67rnnHru/YcOGOnTokEOxs9l7gmEkX8aMi4uTp6enQ0kAAAAAAAAAAAAgY3DVKSmd7caNG3r06NFj9z98+FA3btxwKLbNBbovvvhCkmQymTRz5kzlzJnTsi8hIUHbtm1T2bJlHUoCAAAAAAAAAAAAsNXUqVP12WefKTo6WlWqVNGXX36pWrVq/eN5CxcuVIcOHdSyZUutWLHiiccGBARoz549j61/7dmzRyVKlHAkfdsLdBMnTpT0ZwfdtGnTrKaz9PT0VEBAgKZNm+ZQEgAAAAAAAAAAAMgg0rmDbtGiRQoNDdW0adNUu3ZtTZo0SSEhITpx4oQKFSr02PPOnj2rd999V88++6xN12nTpo3ef/99Pf/88/Lz87PaFx0drZEjR6pTp04O3YPJeNyclY/RuHFjLVu2TPny5XPoggAAAAAAAAAAAMi4yo+Y6PSYR8cMtvnY2rVrq2bNmpoyZYokyWw2y9/fXwMGDNCwYcOSPSchIUENGzZUjx49tH37dsXGxv5jB93t27dVt25dRUVFqVOnTipTpowk6fjx4/r222/l7++vX3/9Vbly5bI590R2r0G3efNmuy8CAAAAAAAAAAAApFR8fLz27t2r4cOHW8bc3NwUHBysnTt3Pva8UaNGqVChQnrzzTe1fft2m66VK1cu/fzzzxo+fLgWLVpkWW8ub9686tSpk0aPHu1QcU5yoECXkJCgOXPmaNOmTYqJiZHZbLba/9NPPzmUCAAAAAAAAAAAAFyfKRWmuIyLi1NcXJzVmJeXl7y8vKzGrl69qoSEhCRTTvr5+en48ePJxt6xY4dmzZql/fv3251Xnjx59NVXX2nq1Km6evWqDMNQwYIFZTKZ7I71V272njBo0CANGjRICQkJqlixoqpUqWK1AQAAAAAAAAAAIBMznL+NHTtWefLksdrGjh2b4lRv376tzp07a8aMGfL19XU4jslkUsGCBTV79mzdvHkzxXnZ3UG3cOFCLV68WM2aNUvxxQEAAAAAAAAAAIDhw4crNDTUauzv3XOS5OvrK3d3d12+fNlq/PLlyypcuHCS40+fPq2zZ8+qefPmlrHE2SGzZcumEydO6Omnn7Y5zzFjxui1115T3rx5bT4nOXYX6Dw9PVWqVKkUXRQAAAAAAAAAAAAZVCpMcZncdJbJ8fT0VPXq1bVp0ya1atVK0p8Ft02bNql///5Jji9btqwOHTpkNTZy5Ejdvn1bkydPlr+/v115GoZzbt7uAt0777yjyZMna8qUKSmeXxMAAAAAAAAAAAAZS2qsQWeP0NBQde3aVTVq1FCtWrU0adIk3b17V927d5ckdenSRUWLFtXYsWPl7e2tihUrWp2f2P329/HkGIah8+fPq1ChQvL29nbaPdhdoNuxY4c2b96stWvXqkKFCvLw8LDav2zZMqclBwAAAAAAAAAAAPxV+/btdeXKFX344YeKjo5W1apVtW7dOvn5+UmSoqKi5Obm5pRrGYahUqVK6ciRIypdurSOHj2qIkWKpDiuybCzFy+x+vg44eHhKUoIAAAAAAAAAAAArqviexOdHvPwZ4OdHtNZKlSooFmzZqlOnTpOi2l3Bx0FOAAAAAAAAAAAAGQV48aN03vvvaevv/7apmkxbWF3gQ4AAAAAAAAAAABZV3qvQZfWunTponv37qlKlSry9PSUj4+P1f7r16/bHdOmAl21atW0adMm5cuXT0FBQTKZTI89NiIiwu4kAAAAAAAAAAAAkEFksQLdpEmTnB7TpgJdy5Yt5eXlJUlq1aqV05MAAAAAAAAAAAAAXFHXrl2dHtNkGEYWq3MCAAAAAAAAAADAUZVCJzo95qEJg50e05lOnz6t8PBwnT59WpMnT1ahQoW0du1aFS9eXBUqVLA7npujiezdu1fz58/X/PnztW/fPkfDAAAAAAAAAAAAIAMxpcLmyrZu3apKlSpp165dWrZsme7cuSNJOnDggMLCwhyKadMUl38VExOj119/XVu2bFHevHklSbGxsWrcuLEWLlyoggULOpQIAAAAAAAAAAAA4GqGDRumTz75RKGhocqVK5dlvEmTJpoyZYpDMe3uoBswYIBu376tI0eO6Pr167p+/boOHz6sW7duaeDAgQ4lAQAAAAAAAAAAgAzCSIXNhR06dEitW7dOMl6oUCFdvXrVoZh2d9CtW7dOGzduVLly5Sxj5cuX19SpU/XCCy84lAQAAAAAAAAAAAAyBpOLF9ScLW/evLp06ZICAwOtxvft26eiRYs6FNPuDjqz2SwPD48k4x4eHjKbzQ4lAQAAAAAAAAAAALii119/XUOHDlV0dLRMJpPMZrN+/vlnvfvuu+rSpYtDMe0u0DVp0kSDBg3SxYsXLWMXLlzQ4MGD1bRpU4eSAAAAAAAAAAAAQAaRxaa4HDNmjMqWLSt/f3/duXNH5cuXV8OGDVWvXj2NHDnSoZgmwzDsuu3z58+rRYsWOnLkiPz9/S1jFStW1MqVK1WsWDGHEgEAAAAAAAAAAIDrqzJootNjHpg82Okxne38+fM6dOiQ7ty5o6CgIJUuXdrhWHavQefv76+IiAht2rRJx44dkySVK1dOwcHBDicBAAAAAAAAAACADMLFO96cxWw267PPPtPKlSsVHx+vpk2bKiwsTD4+PimObVeBbtGiRVZJDBgwIMUJAAAAAAAAAAAAIOMwZZEC3ejRo/XRRx8pODhYPj4+mjx5smJiYjR79uwUx7Z5Dbqvv/5aHTp00J49e/T777+rX79+eu+991KcAAAAAAAAAAAAAOBq5s2bp6+++krr16/XihUr9MMPP+jbb7+V2WxOcWybC3RTpkxRWFiYTpw4of3792vu3Ln66quvUpwAAAAAAAAAAAAAMhAjFTYXFBUVpWbNmlleBwcHy2Qy6eLFiymObXOB7syZM+ratavldceOHfXo0SNdunQpxUkAAAAAAAAAAAAgYzAZzt9c0aNHj+Tt7W015uHhoYcPH6Y4ts1r0MXFxSlHjhyW125ubvL09NT9+/dTnAQAAAAAAAAAAADgSgzDULdu3eTl5WUZe/Dggfr06WNVM1u2bJndsW0u0EnSBx98oOzZs1tex8fHa/To0cqTJ49lbMKECXYnAQAAAAAAAAAAgAzCRTvenO2vM0sm6tSpk1Ni21yga9iwoU6cOGE1Vq9ePZ05c8by2mQyOSUpAAAAAAAAAAAAuCZXnZLS2cLDw1Mtts0Fui1btqRaEgAAAAAAAAAAAEBWYdcUlwAAAAAAAAAAAMjiskgHXWpyS+8EAAAAAAAAAAAAgKyEDjoAAAAAAAAAAADYjg66FKNABwAAAAAAAAAAAJuZKNClGFNcAgAAAAAAAAAAAGnIoQ662NhY7d69WzExMTKbzVb7unTp4pTEAAAAAAAAAAAA4ILooEsxuwt0P/zwg9544w3duXNHuXPnlslksuwzmUwU6AAAAAAAAAAAADIxk0GFLqXsnuLynXfeUY8ePXTnzh3Fxsbqxo0blu369eupkSMAAAAAAAAAAACQadjdQXfhwgUNHDhQ2bNnT418AAAAAAAAAAAA4MpooEsxuzvoQkJCtGfPntTIBQAAAAAAAAAAAC7OZDh/y2rs7qB7+eWX9d577+no0aOqVKmSPDw8rPa3aNHCackBAAAAAAAAAAAAmY3JMOxbyc/N7fFNdyaTSQkJCSlOCgAAAAAAAAAAAK6pZvcJTo/5W3io02O6Mrs76Mxmc2rkAQAAAAAAAAAAAGQJdhfoAAAAAAAAAAAAkHVlxTXjnO3x81U+wdatW9W8eXOVKlVKpUqVUosWLbR9+3Zn5wYAAAAAAAAAAABXY6TClsXYXaCbP3++goODlT17dg0cOFADBw6Uj4+PmjZtqgULFqRGjgAAAAAAAAAAAECmYTIMw666ZLly5fTWW29p8ODBVuMTJkzQjBkzdOzYMacmCAAAAAAAAAAAANdRu8sEp8fcNS/U6TFdmd0ddGfOnFHz5s2TjLdo0UKRkZFOSQoAAAAAAAAAAAAuiikuU8zuAp2/v782bdqUZHzjxo3y9/d3SlIAAAAAAAAAAABAZpXN3hPeeecdDRw4UPv371e9evUkST///LPmzJmjyZMnOz1BAAAAAAAAAAAAuA5TFux4cza7C3R9+/ZV4cKF9Z///EeLFy+W9Oe6dIsWLVLLli2dniAAAAAAAAAAAABciEGFLqXsLtBJUuvWrdW6dWtn5wIAAAAAAAAAAABkeg4V6AAAAAAAAAAAAJA1McVlytlUoMufP79OnjwpX19f5cuXTyaT6bHHXr9+3WnJAQAAAAAAAAAAAJmNTQW6iRMnKleuXJY/P6lABwAAAAAAAAAAgEyMDroUMxkGK/kBAAAAAAAAAADANvXa/8fpMX9Z9I7TY7oyN3tPcHd3V0xMTJLxa9euyd3d3SlJAQAAAAAAAAAAAJmVTVNc/tXjGu7i4uLk6emZ4oQAAAAAAAAAAADgwpibMcVsLtB98cUXkiSTyaSZM2cqZ86cln0JCQnatm2bypYt6/wMAQAAAAAAAAAA4DJMFOhSzOYC3cSJEyX92UE3bdo0q+ksPT09FRAQoGnTpjk/QwAAAAAAAAAAACATsblAFxkZKUlq3Lixli1bpnz58qVaUgAAAAAAAAAAAHBRj1kODbazew26zZs3p0YeAAAAAAAAAAAAyACY4jLl7C7QSdIff/yhlStXKioqSvHx8Vb7JkyY4JTEAAAAAAAAAAAAgMzI7gLdpk2b1KJFC5UsWVLHjx9XxYoVdfbsWRmGoWrVqqVGjgAAAAAAAAAAAHAVdNClmJu9JwwfPlzvvvuuDh06JG9vby1dulTnz59Xo0aN1K5du9TIEQAAAAAAAAAAAMg07C7QHTt2TF26dJEkZcuWTffv31fOnDk1atQoffrpp05PEAAAAAAAAAAAAK7DZDh/y2rsLtDlyJHDsu7cU089pdOnT1v2Xb161XmZAQAAAAAAAAAAwPUYhvO3LMbuNejq1KmjHTt2qFy5cmrWrJneeecdHTp0SMuWLVOdOnVSI0cAAAAAAAAAAAAg07C7QDdhwgTduXNHkvTxxx/rzp07WrRokUqXLq0JEyY4PUEAAAAAAAAAAAC4jqw4JaWz2V2gK1mypOXPOXLk0LRp05yaEAAAAAAAAAAAAFwYBboUs3sNOgAAAAAAAAAAAACOs7uDzs3NTSaT6bH7ExISUpQQAAAAAAAAAAAAXBdTXKac3QW65cuXW71++PCh9u3bp7lz5+rjjz92WmIAAAAAAAAAAABwQWYqdClld4GuZcuWScZeffVVVahQQYsWLdKbb77plMQAAAAAAAAAAACAzMhpa9DVqVNHmzZtclY4AAAAAAAAAAAAuCIjFbYsxikFuvv37+uLL75Q0aJFnREOAAAAAAAAAAAAyLTsnuIyX758MplMlteGYej27dvKnj275s+f79TkAAAAAAAAAAAA4FpMWbDjzdnsLtBNnDjRqkDn5uamggULqnbt2sqXL59TkwMAAAAAAAAAAICLMajQpZTdBbpu3bqlQhoAAAAAAAAAAABA1mBTge7gwYM2B6xcubLDyQAAAAAAAAAAAMC1ucIUl1OnTtVnn32m6OhoValSRV9++aVq1aqV7LEzZszQvHnzdPjwYUlS9erVNWbMmMcenxZsKtBVrVpVJpNJxj+0LJpMJiUkJDglMQAAAAAAAAAAALigdC7QLVq0SKGhoZo2bZpq166tSZMmKSQkRCdOnFChQoWSHL9lyxZ16NBB9erVk7e3tz799FO98MILOnLkiIoWLZoOdyCZjH+qukk6d+6czQFLlCiRooQAAAAAAAAAAADguhq/8KnTY27+cajNx9auXVs1a9bUlClTJElms1n+/v4aMGCAhg0b9o/nJyQkKF++fJoyZYq6dOnicM4pYVMHHUU3AAAAAAAAAAAASJLpn3u/7BYXF6e4uDirMS8vL3l5eVmNxcfHa+/evRo+fLhlzM3NTcHBwdq5c6dN17p3754ePnyo/PnzpzxxB9lUoEvO0aNHFRUVpfj4eKvxFi1apDgpAAAAAAAAAAAAuCiz80OOHTtWH3/8sdVYWFiYPvroI6uxq1evKiEhQX5+flbjfn5+On78uE3XGjp0qIoUKaLg4OAU5ZwSdhfozpw5o9atW+vQoUNW69KZTCZJYg06AAAAAAAAAAAA2GX48OEKDQ21Gvt795wzjBs3TgsXLtSWLVvk7e3t9Pi2crP3hEGDBikwMFAxMTHKnj27jhw5om3btqlGjRrasmVLKqQIAAAAAAAAAAAAV2EyDKdvXl5eyp07t9WWXIHO19dX7u7uunz5stX45cuXVbhw4Sfm/fnnn2vcuHH68ccfVblyZae+J/ayu0C3c+dOjRo1Sr6+vnJzc5Obm5saNGigsWPHauDAgamRIwAAAAAAAAAAACBPT09Vr15dmzZtsoyZzWZt2rRJdevWfex548eP17///W+tW7dONWrUSItUn8juAl1CQoJy5col6c8q5cWLFyVJJUqU0IkTJ5ybHQAAAAAAAAAAAFyLkQqbHUJDQzVjxgzNnTtXx44dU9++fXX37l11795dktSlSxcNHz7ccvynn36qDz74QLNnz1ZAQICio6MVHR2tO3fuOPoOpJjda9BVrFhRBw4cUGBgoGrXrq3x48fL09NT06dPV8mSJVMjRwAAAAAAAAAAALgKw86KmpO1b99eV65c0Ycffqjo6GhVrVpV69atk5+fnyQpKipKbm7/36P29ddfKz4+Xq+++qpVnLCwMH300UdpmbqFyTDsexfXr1+vu3fvqk2bNjp16pReeeUVnTx5UgUKFNCiRYvUpEmT1MoVAAAAAAAAAAAA6azpc2OcHnPTlhFOj+nK7O6gCwkJsfy5VKlSOn78uK5fv658+fLJZDI5NTkAAAAAAAAAAAC4FlP6NtBlCnavQTd//nzdvXvXaix//vwU5wAAAAAAAAAAALICw3D+lsXYXaAbPHiw/Pz81LFjR61Zs0YJCQmpkRcAAAAAAAAAAACQKdldoLt06ZIWLlwok8mk1157TU899ZT69eunX375JTXyAwAAAAAAAAAAgAsxmZ2/ZTV2F+iyZcumV155Rd9++61iYmI0ceJEnT17Vo0bN9bTTz+dGjkCAAAAAAAAAADAVTDFZYplS8nJ2bNnV0hIiG7cuKFz587p2LFjzsoLAAAAAAAAAAAAyJTs7qCTpHv37unbb79Vs2bNVLRoUU2aNEmtW7fWkSNHnJ0fAAAAAAAAAAAAXImRClsWY3cH3euvv65Vq1Ype/bseu211/TBBx+obt26qZEbAAAAAAAAAAAAkOnYXaBzd3fX4sWLFRISInd399TICQAAAAAAAAAAAC7KlAXXjHM2uwt03377bWrkAQAAAAAAAAAAgIyAAl2K2bwGXbNmzXTz5k3L63Hjxik2Ntby+tq1aypfvrxTkwMAAAAAAAAAAAAyG5sLdOvXr1dcXJzl9ZgxY3T9+nXL60ePHunEiRPOzQ4AAAAAAAAAAACuxZwKWxZj8xSXxt/aFf/+GgAAAAAAAAAAAJkfa9ClnM0ddAAAAAAAAAAAAABSzuYOOpPJJJPJlGQMAAAAAAAAAAAAWQgddClm1xSX3bp1k5eXlyTpwYMH6tOnj3LkyCFJVuvTAQAAAAAAAAAAIJOiQJdiNhfounbtavW6U6dOSY7p0qVLyjMCAAAAAAAAAAAAMjGbC3Th4eGpmQcAAAAAAAAAAAAyAnN6J5DxuaV3AgAAAAAAAAAAAEBWYnMHHQAAAAAAAAAAAGBiDboUo0AHAAAAAAAAAAAA21GgSzGmuAQAAAAAAAAAAADSEB10AAAAAAAAAAAAsB0ddClGgQ4AAAAAAAAAAAC2o0CXYkxxCQAAAAAAAAAAAKQhOugAAAAAAAAAAABgO3N6J5DxUaADAAAAAAAAAACAzUxMcZliTHEJAAAAAAAAAAAApCE66AAAAAAAAAAAAGA7OuhSjA46AAAAAAAAAAAAIA3RQQcAAAAAAAAAAADbmemgSykKdAAAAAAAAAAAALAdU1ymGFNcAgAAAAAAAAAAAGmIDjoAAAAAAAAAAADYjg66FKNABwAAAAAAAAAAANtRoEsxprgEAAAAAAAAAAAA0hAddAAAAAAAAAAAALCdmQ66lKJABwAAAAAAAAAAANsZ5vTOIMNjiksAAAAAAAAAAAAgDdFBBwAAAAAAAAAAANsZTHGZUnTQAQAAAAAAAAAAAGmIDjoAAAAAAAAAAADYzkwHXUpRoAMAAAAAAAAAAIDtmOIyxZjiEgAAAAAAAAAAAEhDdNABAAAAAAAAAADAdnTQpRgFOgAAAAAAAAAAANiOAl2KMcUlAAAAAAAAAAAAkIbooAMAAAAAAAAAAIDtzOb0ziDDo0AHAAAAAAAAAAAA2zHFZYoxxSUAAAAAAAAAAACQhuigAwAAAAAAAAAAgO3ooEsxOugAAAAAAAAAAACANEQHHQAAAAAAAAAAAGxnpoMupSjQAQAAAAAAAAAAwGaGYU7vFDI8prgEAAAAAAAAAAAA0hAddAAAAAAAAAAAALAdU1ymGAU6AAAAAAAAAAAA2M6gQJdSTHEJAAAAAAAAAAAApCE66AAAAAAAAAAAAGA7szm9M8jwKNABAAAAAAAAAADAdkxxmWJMcQkAAAAAAAAAAACkITroAAAAAAAAAAAAYDODKS5TjA46AAAAAAAAAAAAIA3RQQcAAAAAAAAAAADbsQZdilGgAwAAAAAAAAAAgO3MFOhSiikuAQAAAAAAAAAAgDREBx0AAAAAAAAAAABsZ5jTO4MMjwIdAAAAAAAAAAAAbGYwxWWKMcUlAAAAAAAAAAAAkIYo0AEAAAAAAAAAAMB2htn5m52mTp2qgIAAeXt7q3bt2tq9e/cTj1+yZInKli0rb29vVapUSWvWrHH07p2CAh0AAAAAAAAAAABsZpgNp2/2WLRokUJDQxUWFqaIiAhVqVJFISEhiomJSfb4X375RR06dNCbb76pffv2qVWrVmrVqpUOHz7sjLfDISbDMJgoFAAAAAAAAAAAADZ53r2902NuSFhk87G1a9dWzZo1NWXKFEmS2WyWv7+/BgwYoGHDhiU5vn379rp7965WrVplGatTp46qVq2qadOmpTx5B9BBBwAAAAAAAAAAANul4xSX8fHx2rt3r4KDgy1jbm5uCg4O1s6dO5M9Z+fOnVbHS1JISMhjj08L2dLtygAAAAAAAAAAAICkuLg4xcXFWY15eXnJy8vLauzq1atKSEiQn5+f1bifn5+OHz+ebOzo6Ohkj4+OjnZC5o7JcB10cXFx+uijj5J8SEBq4HlDWuJ5Q1rieUNa4nlDWuJ5Q1rieUNa4nlDWuJ5Q1rieQMypg3mJU7fxo4dqzx58lhtY8eOTe9bTTUZbg26W7duKU+ePLp586Zy586d3ukgk+N5Q1rieUNa4nlDWuJ5Q1rieUNa4nlDWuJ5Q1rieUNa4nkDkMjWDrr4+Hhlz55d33//vVq1amUZ79q1q2JjY/W///0vSezixYsrNDRUb7/9tmUsLCxMK1as0IEDB5x6H7bKcB10AAAAAAAAAAAAyFy8vLyUO3duq+3vxTlJ8vT0VPXq1bVp0ybLmNls1qZNm1S3bt1kY9etW9fqeEnasGHDY49PC6xBBwAAAAAAAAAAgAwjNDRUXbt2VY0aNVSrVi1NmjRJd+/eVffu3SVJXbp0UdGiRS1TZA4aNEiNGjXSf/7zH7388stauHCh9uzZo+nTp6fbPVCgAwAAAAAAAAAAQIbRvn17XblyRR9++KGio6NVtWpVrVu3Tn5+fpKkqKgoubn9/ySS9erV04IFCzRy5EiNGDFCpUuX1ooVK1SxYsX0uoWMV6Dz8vJSWFhYsm2NgLPxvCEt8bwhLfG8IS3xvCEt8bwhLfG8IS3xvCEt8bwhLfG8AXBU//791b9//2T3bdmyJclYu3bt1K5du1TOynYmwzCM9E4CAAAAAAAAAAAAyCrc/vkQAAAAAAAAAAAAAM5CgQ4AAAAAAAAAAABIQxToAAAAAAAAAAAAgDSULb0TsNWZM2cUFRUlSSpevLhKliyZzhkBAAAAAAAAAAAA9nP5At2xY8fUtWtXnT9/XsWLF5ckRUVFyd/fX+Hh4apQoUI6Z4jMZMmSJWrXrp0k6erVq+ratat27NihoKAgzZs3z/IMAgCAJ0tISNDWrVutfsGqUaNGcnd3T+fMkBXcuHFD+fLlS+80kInxC6QAMiN+fkN64uc3AFmRy09x2a1bNw0dOlSXLl3Srl27tGvXLl26dElDhgxR9+7d0zs9ZDJjx461/Hn48OGqVKmSTpw4oRYtWmjQoEHpmBkyszNnzmjLli3asmWLzpw5k97pAECKbd++XQEBARoxYoTWrl2rtWvXavjw4QoICNC2bdvSOz1kMpMnT7b8OTIyUhUqVFCRIkUUGBioQ4cOpWNmyIyOHTumWrVqqX79+ho6dKiGDh2q+vXrq1atWjpy5Eh6p4dMZsmSJZY/X716VS+//LLy5Mmj5557zlJAAZyFn9+Qlvj5DQD+ZDIMw0jvJJ6kTJkyOnHihN37AEcEBQVp3759kqQqVaooIiLC8ptiVapU0YEDB9IzPWQydAgjLdEhjLRUuXJlzZ49WzVq1LAa/+2339SjRw/+oxtOVa1aNUVEREiSOnTooAYNGqhfv35aunSppk2bpg0bNqRzhshMateurSFDhqht27ZW499//73Gjx+v3bt3p1NmyIz++vdbr169VKBAAb399ttasGCBtm/fruXLl6dzhshM+PkNaYmf3wDgTy7fQefr66tvvvlGZrPZMmY2mzV37lwVKFAgHTNDZvTgwQMdOnRIBw8elMlksprGwWQypWNmyIzoEEZaokMYaenBgwdJ/nFHkmrWrKm4uLh0yAhZxdGjR9WvXz9JUtu2bXXlypV0zgiZTWxsbJLinCS9+uqrunnzZjpkhMzsr79PvXv3bo0ePVqFCxdWaGgoM2/A6fj5DemFn98AZGUuX6CbO3eu5syZo/z586tcuXIqV66c8ufPbxkHnOn+/ftq2bKlWrZsqZs3b+qPP/6QJN28eVNubi7/dUEGwz/wIC3xDzxIS08//bRGjRqlmJgYy1hMTIw+/vhjBQYGpmNmyIxiY2P1ww8/aOXKlXr48KHVPhefLAQZEL9AirTEL5AiLfHzG9ISP78BwJ+ypXcC/6RUqVLatGmTrly5ovPnz0uS/P39VbBgwXTODJnR2bNnkx338PDQ0qVL0zYZZHqJ/8DzxhtvWArAZrNZ33zzDf/AA6dL/AcewzD4Bx6kunnz5mno0KF6+umn9ejRI0lStmzZ1K5dO33zzTfpnB0ym+LFi2vChAmSJD8/P124cEFFixZVTEyMPD090zk7ZDZz585V79691b9/fxUpUkSGYejSpUuqXr06v0AKp7t//75atGhhef3HH3+oWLFi/AIpUsW8efM0bNgwfn5DmuDnNwD4k8uvQQcAmdWpU6fUu3dv7d27V0899ZQk6dKlS6pWrZqmTZumZ555Jp0zRGYSEBAgNzc3y28jbt++3fIPPI0bN7bM/w842/Xr1yVJ+fPnT+dMkNUkJCQoLi5O2bNnT+9UkAnxC6RILzdu3JC3t7eio6PpakKqSfz5bfHixerTp086Z4Os4r///a969eqlBw8e8PMbgCyDAh0ApDP+gQfp6d69e4qJiVFAQEB6p4JM5PTp0+rZs6fOnTunVq1aacyYMfL29pYk1a1bVzt37kznDJGZnDlzRj179tTZs2d53pDq9u/fr27dusnNzU3ffPONhgwZos2bN8vX11erVq1S5cqV0ztFZCIHDhxQ165d5e7urnnz5lk9b6tXr1alSpXSO0VkIitXrkwy9tZbb2nGjBkyDMOqmxNIqcc9b9OnT5cknjcAWQYFOgBwQc8884xOnjyZ3mkgi+B5g7OFhISoRYsWqlOnjiZPnqzTp09r3bp1ypUrl4KCgrRv3770ThGZCM8b0lKjRo00ePBgxcbGKiwsTJ988ok6d+6sFStW6KuvvtKPP/6Y3ikiE+F5Q1pyc3NT3bp1raYX/PXXX1WnTh2ZTCb99NNP6ZgdMhueNwD4EwU6AEgnBw8efOy+kJAQXbp0KQ2zQWbH84a09PeiyJgxY7RixQpt2LCBKVXhdDxvSEt/fd6KFy+uqKgoy76qVatq//796ZQZMiOeN6Sl8PBwzZw5U1OmTFFQUJAkKTAwUJGRkemcGTIjnjcA+FO29E4AALKqqlWrKiAgQMn9nsS1a9fSISNkZjxvSEv379+3ej1ixAh5enqqadOmun37djplhcyK5w1p6a//P9q4cePH7gOcgecNaal79+5q0qSJevbsqWeffVbvv/++TCZTeqeFTIrnDQD+5JbeCQBAVlWiRAnt2LFDkZGRSTY/P7/0Tg+ZDM8b0lK5cuW0bt06q7F3331XHTt21OnTp9MpK2RWPG9IS35+frp165Ykae7cuZbxS5cuWdY+BJyF5w1prUSJEvrxxx+VI0cOPfvss4qLi0vvlJCJ8bwBAFNcAkC6GTRokNq1a6cGDRok2denTx9NmzYtHbJCZsXzhrSU+B/XXl5eSfZduHBBRYsWTeuUkInxvMEV3Lx5Uzdv3lTx4sXTOxVkATxvSAtHjhzR9u3b1adPn/ROBVkAzxuArIoCHQAAAAAAAAAAAJCGmOISwP+1dz+hWdB/HMDfj0sF56Q/BsMc6WAjNzrERBQvDQaFMiF3EYZ2UbG2Yjr/HJy4QMHoEChDZAf15g7ODiEWOiPwDxWmjkpYKzeE6SHzkqIh6/CD8fuh4ebkWT96vU7Pw+f7+fL5fq9vnu8DAAAAAAAUkYAOAAAAAAAAikhABwAAAAAAAEUkoAMAAAAAAIAiEtABAADPVKFQyGeffTbVYwAAAMA/loAOAAAYt5s3b+aDDz5IZWVlZs6cmYqKijQ2NubMmTNTPVqS5M0330xbW9v/fC8UCikUCpk5c2ZeeeWVNDY2pre3d+qGBAAA4F9PQAcAAIzL9evXU1dXl76+vnzyySfp7+/PqVOnUl9fn5aWlqke729t2LAhIyMjGRwczPHjx1NTU5M1a9Zk48aNUz0aAAAA/1ICOgAAYFzef//9FAqFfPPNN2lqakp1dXVqa2uzZcuWXLx48W/7duzYkerq6syaNSuVlZXZtWtX/vzzz7H6lStXUl9fn7KyssyZMyd1dXX57rvvkiRDQ0NpbGzMCy+8kNLS0tTW1ubkyZMTmnvWrFkpLy/P/Pnzs3Tp0nz88cc5dOhQuru7c/r06ae7DAAAAJiE56Z6AAAA4J/v9u3bOXXqVPbu3ZvS0tJH6s8///zf9paVleXIkSOZN29e+vv7s2HDhpSVlWX79u1Jkubm5rzxxhs5ePBgSkpKcvny5UyfPj1J0tLSkgcPHuTrr79OaWlpfvzxx8yePXvS53n33XfT3t6e3t7eNDQ0THo/AAAAmAgBHQAA8EQ///xzRkdH89prr024t6OjY+zzggULsnXr1hw7dmwsoBseHs62bdvG9q6qqhpbPzw8nKamprz++utJksrKyskcY8y0adNSXV2d69evP5P9AAAAYCI8cQkAADzR6OjoU/f29PRk+fLlKS8vz+zZs9PR0ZHh4eGx+pYtW7J+/fo0NDRk3759GRwcHKt9+OGH2bNnT5YvX57du3fn6tWrkzrHfxsdHU2hUHhm+wEAAMB4CegAAIAnqqqqSqFQyLVr1ybUd+HChTQ3N2fFihX5/PPP8/3332fnzp158ODB2JrOzs788MMPWblyZfr6+lJTU5MTJ04kSdavX59ffvkla9euTX9/fxYvXpwDBw5M+jwPHz7MwMBAFi5cOOm9AAAAYKIEdAAAwBO9+OKLeeutt9LV1ZU//vjjkfqdO3ce23f+/Pm8+uqr2blzZxYvXpyqqqoMDQ09sq66ujqbN2/Ol19+mdWrV+fw4cNjtYqKimzatCm9vb1pb29Pd3f3pM9z9OjR/P7772lqapr0XgAAADBRAjoAAGBcurq68vDhwyxZsiTHjx/PwMBAfvrpp+zfvz/Lli17bE9VVVWGh4dz7NixDA4OZv/+/WO/jkuSe/fupbW1NV999VWGhoZy7ty5fPvtt1m0aFGSpK2tLV988UV+/fXXXLp0KWfPnh2rjdfdu3dz8+bN3LhxIxcvXsyOHTuyadOmvPfee6mvr3/6CwEAAICn9NxUDwAAAPx/qKyszKVLl7J37960t7dnZGQkL7/8curq6nLw4MHH9qxatSqbN29Oa2tr7t+/n5UrV2bXrl3p7OxMkpSUlOS3337LunXrcuvWrcydOzerV6/ORx99lOQ/T1G2tLTkxo0bmTNnTt5+++18+umnE5q7u7s73d3dmTFjRl566aXU1dWlp6cn77zzzqTuAwAAAJ5WYXQy//YOAAAAAAAATIgnLgEAAAAAAKCIBHQAAAAAAABQRAI6AAAAAAAAKCIBHQAAAAAAABSRgA4AAAAAAACKSEAHAAAAAAAARSSgAwAAAAAAgCIS0AEAAAAAAEARCegAAAAAAACgiAR0AAAAAAAAUEQCOgAAAAAAACgiAR0AAAAAAAAU0V9HOViBXRFNPAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTVYL_F8Ez1l"
      },
      "id": "PTVYL_F8Ez1l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}