{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10a005b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook contains the replay+ewc approach for training coarse-grained and fine-grained datasets in a continual learning classification setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67295c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds for reproducibility\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# seeds\n",
    "seed = 88\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb8a2b",
   "metadata": {},
   "source": [
    "## Data Loading and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# remove copyright banner\n",
    "class RemoveCopyrightBanner(object):\n",
    "    def __call__(self, img):\n",
    "        width, height = img.size\n",
    "        return img.crop((0, 0, width, height - 20))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    RemoveCopyrightBanner(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# granularity = 'variant'\n",
    "\n",
    "# # Create the FGVC Aircraft dataset instance\n",
    "# train_dataset = FGVCAircraft(\n",
    "#     root='./data',\n",
    "#     split='trainval',              # Options: 'train', 'val', 'trainval', 'test'\n",
    "#     annotation_level=granularity,    # Options: 'variant', 'family', 'manufacturer'\n",
    "#     transform=transform,\n",
    "#     download=True\n",
    "# )\n",
    "\n",
    "# val_dataset = FGVCAircraft(\n",
    "#     root='./data',\n",
    "#     split='val',\n",
    "#     annotation_level='variant',\n",
    "#     transform=transform,\n",
    "#     download=True\n",
    "# )\n",
    "\n",
    "# test_dataset = FGVCAircraft(\n",
    "#     root='./data',\n",
    "#     split='test',\n",
    "#     annotation_level=granularity,\n",
    "#     transform=transform,\n",
    "#     download=True\n",
    "# )\n",
    "\n",
    "data_root = './data'\n",
    "\n",
    "train_dataset = datasets.DTD(\n",
    "    root=data_root,\n",
    "    split='train',\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = datasets.DTD(\n",
    "    root=data_root,\n",
    "    split='val',\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = datasets.DTD(\n",
    "    root=data_root,\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "trainval_dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [0.8, 0.2], generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a50ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show images\n",
    "def show_images(train_dataset, num_images=5):\n",
    "  #shuffle the dataset\n",
    "  train_dataset = torch.utils.data.Subset(train_dataset, torch.randperm(len(train_dataset)))\n",
    "  fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "  for i in range(num_images):\n",
    "      image, label = train_dataset[i]\n",
    "      image = image.permute(1, 2, 0)  # convert from CxHxW to HxWxC\n",
    "      axes[i].imshow(image)\n",
    "      axes[i].set_title(f'Label: {label}')\n",
    "      axes[i].axis('off')\n",
    "  plt.show()\n",
    "\n",
    "show_images(train_dataset, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85998420",
   "metadata": {},
   "source": [
    "## Create the Dataset\n",
    "In a continual learning setting, each task contains a new set of classes to train the model on. The validation and test datasets should be cumulative (to evalute the performance of the model on all classes seen by the model so far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def group_task_indices(dataset, cumulative=False, max_per_class=1000, classes_per_task=10):\n",
    "    \"\"\"\n",
    "    Task 0: 0-9, Task 1: 10-19, ..., Task 9: 90-99 for train\n",
    "    Output a dictionary where keys are task indices and values are lists of image indices.\n",
    "    For example, task_dict[0] will contain indices of images with labels 0-9.\n",
    "    \"\"\"\n",
    "    per_class_counts = defaultdict(int)\n",
    "    task_dict = defaultdict(list)\n",
    "    for idx, (_, label) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        # for test and val, should have cumulative indices (all classes seen so far)\n",
    "        if per_class_counts[label] >= max_per_class:\n",
    "          continue\n",
    "        per_class_counts[label] += 1\n",
    "        if cumulative:\n",
    "          for i in range((label // classes_per_task), classes_per_task):\n",
    "            task_dict[i].append(idx)\n",
    "        else:\n",
    "          task_dict[label // classes_per_task].append(idx)\n",
    "    return task_dict\n",
    "\n",
    "train_task_idxs = group_task_indices(train_dataset, cumulative=False, max_per_class=60)\n",
    "val_task_idxs = group_task_indices(val_dataset, cumulative=True)\n",
    "test_task_idxs = group_task_indices(test_dataset, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b183930",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_net(net_to_val, val_loader):\n",
    "    net_to_val.eval()\n",
    "    loss = 0\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(val_loader, desc=\"Validating\"):\n",
    "\n",
    "            # Get the input images and their corresponding labels\n",
    "            img, label = img.cuda(), label.cuda()\n",
    "\n",
    "            # Forward pass: Get predictions from the model\n",
    "            outputs = net_to_val(img)\n",
    "            loss += criterion(outputs, label)\n",
    "\n",
    "        return loss / len(val_loader)\n",
    "\n",
    "def train_net_ewc_replay(max_epochs, freeze_epochs, patience, ewc, net_to_train, opt, train_loader, val_loader, task, save_file=None, save_path=None):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    net_to_train.cuda()\n",
    "\n",
    "    initial_freeze = (task == 0)\n",
    "\n",
    "    for name, param in net_to_train.named_parameters():\n",
    "        if initial_freeze and 'fc' not in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    optimizer = opt\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    print(f\"Starting training for Task {task}. Trainable parameters:\")\n",
    "    for name, param in net_to_train.named_parameters():\n",
    "        if param.requires_grad:\n",
    "             print(f\"  - {name}\")\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        net_to_train.train()\n",
    "        running_loss = 0.0\n",
    "        running_ewc = 0.0\n",
    "\n",
    "        if epoch == freeze_epochs and task > 0:\n",
    "            print(f\"Unfreezing backbone at epoch {epoch} for task {task}\")\n",
    "            for name, param in net_to_train.named_parameters():\n",
    "                if not param.requires_grad and 'fc' not in name:\n",
    "                    # check if the parameter was frozen by EWC\n",
    "                    # if it was frozen by EWC, we should not unfreeze it\n",
    "                    was_frozen_by_importance = False\n",
    "                    for n, imp in getattr(ewc, 'important_params', {}).items():\n",
    "                        if n == name:\n",
    "                            was_frozen_by_importance = True\n",
    "                            break\n",
    "\n",
    "                    if not was_frozen_by_importance:\n",
    "                        param.requires_grad = True\n",
    "\n",
    "            # adjust LR for the existing optimizer\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            new_lr = 1e-4\n",
    "            if current_lr != new_lr:\n",
    "                 print(f\"Setting LR to {new_lr}\")\n",
    "                 for g in optimizer.param_groups:\n",
    "                     g['lr'] = new_lr\n",
    "\n",
    "\n",
    "        for imgs, labels in tqdm(train_loader, unit='batch', desc=f\"Task {task} Epoch {epoch+1}\"):\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net_to_train(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            ewc_loss = ewc.ewc_loss(task)\n",
    "            running_ewc += ewc_loss.item()\n",
    "            loss += ewc_loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net_to_train.parameters(), max_norm=1.0) # grad clipping\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_ewc_loss = running_ewc / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        # validation\n",
    "        current_val_loss = val_net(net_to_train, val_loader)\n",
    "        val_losses.append(current_val_loss)\n",
    "        print(f\"Task {task}, Epoch {epoch + 1}, EWC Loss: {avg_ewc_loss:.4f}, Total Loss: {avg_loss:.4f}, Val Loss (Cumulative): {current_val_loss:.4f}\")\n",
    "\n",
    "        # logging\n",
    "        if save_file:\n",
    "             with open(save_file, 'a') as f:\n",
    "                  f.write(f\"{task},{epoch + 1},{avg_loss},{current_val_loss}\\n\") \n",
    "\n",
    "        # early stopping\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            if save_path:\n",
    "               torch.save(net_to_train.state_dict(), os.path.join(save_path, f\"model_task{task}_best.pth\"))\n",
    "               print(f\"  New best validation loss: {best_val_loss:.4f}. Saved best model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1} for task {task}. Best Val Loss: {best_val_loss:.4f}\")\n",
    "            if save_path and os.path.exists(os.path.join(save_path, f\"model_task{task}_best.pth\")):\n",
    "               print(\"Loading best model weights before exiting.\")\n",
    "               net_to_train.load_state_dict(torch.load(os.path.join(save_path, f\"model_task{task}_best.pth\")))\n",
    "            break\n",
    "\n",
    "    print(f\"Finished training task {task}\")\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b168310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def modify_resnet_head(model, num_classes):\n",
    "  \"\"\"\n",
    "  Modify the last fully connected layer of the ResNet model to match the number of classes.\n",
    "  \"\"\"\n",
    "\n",
    "  old_fc = model.fc\n",
    "  old_num_classes = old_fc.out_features\n",
    "  num_ftrs = old_fc.in_features\n",
    "\n",
    "  # Create the new head\n",
    "  new_fc = nn.Linear(num_ftrs, num_classes).cuda()\n",
    "\n",
    "  # Copy weights and biases from the old head\n",
    "  if old_num_classes < num_classes:\n",
    "    new_fc.weight.data[:old_num_classes, :] = old_fc.weight.data.clone().cuda()\n",
    "    new_fc.bias.data[:old_num_classes] = old_fc.bias.data.clone().cuda()\n",
    "\n",
    "  model.fc = new_fc\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca192ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_test_accuracy(model, test_loader, num_classes):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total = 0\n",
    "    correct_per_class = [0] * num_classes\n",
    "    total_per_class = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            output = model(imgs)\n",
    "            preds = output.argmax(dim=1)\n",
    "\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Per-class stats\n",
    "            for c in range(num_classes):\n",
    "                correct_per_class[c] += ((preds == c) & (labels == c)).sum().item()\n",
    "                total_per_class[c] += (labels == c).sum().item()\n",
    "\n",
    "    overall_acc = correct_preds / total\n",
    "    per_class_acc = [correct_per_class[c] / total_per_class[c] if total_per_class[c] > 0 else 0.0\n",
    "                     for c in range(num_classes)]\n",
    "    return overall_acc, per_class_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd9fd5",
   "metadata": {},
   "source": [
    "## EWC+Replay Classes and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_memory_buffer(buffer, max_size, new_samples):\n",
    "    \"\"\"Adds new samples to the buffer and trims it if it exceeds max_size.\"\"\"\n",
    "    buffer.extend(new_samples)\n",
    "    # If buffer exceeds max size, remove samples randomly\n",
    "    overflow = len(buffer) - max_size\n",
    "    if overflow > 0:\n",
    "        indices_to_remove = random.sample(range(len(buffer)), overflow)\n",
    "        for index in sorted(indices_to_remove, reverse=True):\n",
    "            del buffer[index]\n",
    "    print(f\"Memory buffer size: {len(buffer)} / {max_size}\")\n",
    "\n",
    "class MemoryDataset(Dataset):\n",
    "    \"\"\"Dataset class for the memory buffer.\"\"\"\n",
    "    def __init__(self, buffer_list):\n",
    "        self.buffer = buffer_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # buffer contains (image_tensor, label)\n",
    "        return self.buffer[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce15ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "class EWC:\n",
    "    def __init__(self, model, device='cuda', lambda_ewc=5000):\n",
    "        \"\"\"\n",
    "        Create EWC object to manage EWC regularization.\n",
    "        lambda_ewc is the regularization strength for EWC penalty.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.lambda_ewc = lambda_ewc\n",
    "\n",
    "        # fisher information for each task\n",
    "        self.fisher_dict = {}\n",
    "        # optimal parameters for each task\n",
    "        self.optpar_dict = {}\n",
    "        # output layer sizes for each task\n",
    "        self.output_sizes = {}\n",
    "        # track important parameters\n",
    "        self.important_params = {}\n",
    "\n",
    "    def compute_fisher(self, data_loader, samples=500):\n",
    "        \"\"\"\n",
    "        Compute the diagonal fisher matrix. Samples is the number of samples to use for Fisher computation.\n",
    "        \"\"\"\n",
    "        fisher = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self.model.eval()\n",
    "\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.Subset(data_loader.dataset,\n",
    "                                  torch.randperm(len(data_loader.dataset))[:samples].tolist()),\n",
    "            batch_size=1, shuffle=True\n",
    "        )\n",
    "\n",
    "        for input_data, _ in sample_loader:\n",
    "            input_data = input_data.to(self.device)\n",
    "            output = self.model(input_data)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "\n",
    "            num_classes = probs.size(1)\n",
    "            for c in range(num_classes):\n",
    "                self.model.zero_grad()\n",
    "                class_prob = probs[0, c]\n",
    "                log_class_prob = torch.log(class_prob)\n",
    "                log_class_prob.backward(retain_graph=(c < num_classes-1))\n",
    "\n",
    "                prob_value = class_prob.item()\n",
    "                for n, p in self.model.named_parameters():\n",
    "                    if p.grad is not None and p.requires_grad:\n",
    "                        fisher[n] += prob_value * p.grad.data.pow(2) / samples\n",
    "\n",
    "        return fisher\n",
    "\n",
    "    def store_task_parameters(self, task_id, data_loader):\n",
    "        \"\"\"\n",
    "        Store the optimal parameters and compute fisher after training on a task.\n",
    "        \"\"\"\n",
    "        print(f\"Storing parameters for task {task_id}...\")\n",
    "\n",
    "        # Store current parameter values\n",
    "        self.optpar_dict[task_id] = {}\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.optpar_dict[task_id][n] = p.data.clone()\n",
    "                if 'fc' in n or 'layer4' in n:\n",
    "                    print(f\"Stored parameter {n}: min={p.min().item():.6f}, max={p.max().item():.6f}, mean={p.mean().item():.6f}\")\n",
    "\n",
    "        # compute fisher matrix\n",
    "        self.fisher_dict[task_id] = self.compute_fisher(data_loader)\n",
    "\n",
    "        # store output layer size\n",
    "        if hasattr(self.model, 'fc'):\n",
    "            self.output_sizes[task_id] = self.model.fc.weight.size(0)\n",
    "            print(f\"Stored output size for task {task_id}: {self.output_sizes[task_id]}\")\n",
    "        elif hasattr(self.model, 'classifier'):\n",
    "            self.output_sizes[task_id] = self.model.classifier.weight.size(0)\n",
    "            print(f\"Stored output size for task {task_id}: {self.output_sizes[task_id]}\")\n",
    "\n",
    "    def ewc_loss(self, current_task_id):\n",
    "        \"\"\"\n",
    "        Calculate the EWC penalty\n",
    "        \"\"\"\n",
    "        if current_task_id == 0:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        total_loss = 0\n",
    "        param_count = 0\n",
    "\n",
    "        # calculate EWC loss for all previous tasks\n",
    "        for task_id in range(current_task_id):\n",
    "            task_loss = 0\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.requires_grad and n in self.fisher_dict[task_id] and n in self.optpar_dict[task_id]:\n",
    "                    if \"fc.weight\" in n:\n",
    "                        prev_size = self.output_sizes[task_id]\n",
    "                        fisher_term = self.fisher_dict[task_id][n][:prev_size, :]\n",
    "                        param_diff = (p[:prev_size, :] - self.optpar_dict[task_id][n][:prev_size, :]).pow(2)\n",
    "                        task_loss += (fisher_term * param_diff).sum()\n",
    "                        param_count += fisher_term.numel()\n",
    "                    elif \"fc.bias\" in n:\n",
    "                        prev_size = self.output_sizes[task_id]\n",
    "                        fisher_term = self.fisher_dict[task_id][n][:prev_size]\n",
    "                        param_diff = (p[:prev_size] - self.optpar_dict[task_id][n][:prev_size]).pow(2)\n",
    "                        task_loss += (fisher_term * param_diff).sum()\n",
    "                        param_count += fisher_term.numel()\n",
    "                    else:\n",
    "                        fisher_term = self.fisher_dict[task_id][n]\n",
    "                        param_diff = (p - self.optpar_dict[task_id][n]).pow(2)\n",
    "                        task_loss += (fisher_term * param_diff).sum()\n",
    "                        param_count += fisher_term.numel()\n",
    "\n",
    "            total_loss += task_loss\n",
    "\n",
    "        # lambda scaling\n",
    "        ewc_penalty = self.lambda_ewc * total_loss / 2\n",
    "        return ewc_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1befc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846160b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "LAMBDA_EWC = 10e5\n",
    "save_dir = 'replay-ewc-coarse-grained-1M'\n",
    "\n",
    "# init model and ewc object\n",
    "model = models.resnet18(pretrained=True)\n",
    "ewc = EWC(model, device='cuda', lambda_ewc=LAMBDA_EWC)\n",
    "\n",
    "# freeze all parameters except the last fc layer\n",
    "for name, param in model.named_parameters():\n",
    "    if name != 'fc.weight' and name != 'fc.bias':\n",
    "        param.requires_grad = False\n",
    "\n",
    "# replay init\n",
    "memory_buffer = []\n",
    "memory_size = 1000 \n",
    "samples_per_task_in_memory = 20\n",
    "\n",
    "\n",
    "# init log files\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "open(os.path.join(save_dir, 'train_val_losses.txt'), 'w').close()\n",
    "open(os.path.join(save_dir, 'accuracies.txt'), 'w').write(\"Task,Overall Accuracy,Per-Class Accuracy\\n\")\n",
    "\n",
    "\n",
    "for task in range(5):\n",
    "    print(f\"Training on task {task}...\")\n",
    "\n",
    "    model = modify_resnet_head(model, (task+1) * 10)\n",
    "    model = model.cuda()\n",
    "\n",
    "    # get current task data\n",
    "    current_task_train_subset = Subset(train_dataset, train_task_idxs[task])\n",
    "\n",
    "    # combine with memory buffer if task > 0\n",
    "    if task > 0 and len(memory_buffer) > 0:\n",
    "        replay_dataset = MemoryDataset(memory_buffer)\n",
    "        combined_train_dataset = ConcatDataset([current_task_train_subset, replay_dataset])\n",
    "        print(f\"Task {task}: Training with {len(current_task_train_subset)} current samples and {len(replay_dataset)} replay samples.\")\n",
    "    else:\n",
    "        # task 0 or empty buffer: train only on current task data\n",
    "        combined_train_dataset = current_task_train_subset\n",
    "        print(f\"Task {task}: Training only with {len(current_task_train_subset)} current samples.\")\n",
    "\n",
    "    # dataloader for current task\n",
    "    train_loader_combined = DataLoader(\n",
    "        combined_train_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    train_loader_not_combined = DataLoader(\n",
    "        current_task_train_subset,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "    # validation and test loaders for the current task\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        Subset(val_dataset, val_task_idxs[task]),\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Subset(test_dataset, test_task_idxs[task]),\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "    # optimizer initialization\n",
    "    if task == 0:\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0015)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4) # Lower LR for full network\n",
    "\n",
    "\n",
    "    # train the model\n",
    "    train_losses, val_losses = train_net_ewc_replay(\n",
    "        max_epochs=15,\n",
    "        freeze_epochs=5,\n",
    "        patience=5,\n",
    "        net_to_train=model,\n",
    "        opt=optimizer,\n",
    "        train_loader=train_loader_combined,\n",
    "        val_loader=val_loader,\n",
    "        task=task,\n",
    "        save_file=os.path.join(save_dir, 'train_val_losses.txt')\n",
    "    )\n",
    "\n",
    "    # update ewc after training\n",
    "    ewc.store_task_parameters(task, train_loader_not_combined)\n",
    "\n",
    "    # update memory buffer with samples from current task\n",
    "    num_to_sample = min(samples_per_task_in_memory, len(current_task_train_subset))\n",
    "    if num_to_sample > 0:\n",
    "        indices_to_sample = random.sample(range(len(current_task_train_subset)), num_to_sample)\n",
    "        new_memory_samples = []\n",
    "        print(f\"Sampling {num_to_sample} examples from task {task} for memory buffer...\")\n",
    "        for idx in indices_to_sample:\n",
    "            img_tensor, label = current_task_train_subset[idx]\n",
    "            new_memory_samples.append((img_tensor, label)) # Append as tuple\n",
    "        update_memory_buffer(memory_buffer, memory_size, new_memory_samples)\n",
    "    else:\n",
    "        print(f\"Not enough samples in task {task} subset to add to memory.\")\n",
    "\n",
    "\n",
    "    # evaluate and save the model\n",
    "    overall_acc, per_class_acc = get_test_accuracy(model, test_loader, (task+1) * 10)\n",
    "    print(f\"Overall accuracy for task {task} (on classes 0-{(task+1)*10 - 1}): {overall_acc:.4f}\")\n",
    "\n",
    "    with open(os.path.join(save_dir, 'accuracies.txt'), 'a') as f:\n",
    "        f.write(f\"{task},{overall_acc:.4f},{per_class_acc}\\n\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"model_task_{task}.pth\"))\n",
    "    print(f\"Model for task {task} saved as model_task_{task}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
